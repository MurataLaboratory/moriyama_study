{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 971,
     "status": "ok",
     "timestamp": 1604609107806,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "7Z8LGX2980EX",
    "outputId": "c4279f8a-f58a-43bc-8232-12af6c607ca3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print('hello world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 2600,
     "status": "ok",
     "timestamp": 1604609109447,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "wij1JxmL9GPC"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.encoder = nn.Embedding(ntoken, ninp)\n",
    "        self.ninp = ninp\n",
    "        self.decoder = nn.Linear(ninp, ntoken)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src, src_mask):\n",
    "        src = self.encoder(src) * math.sqrt(self.ninp)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src, src_mask)\n",
    "        output = self.decoder(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 2596,
     "status": "ok",
     "timestamp": 1604609109448,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "KdR2x3-I9Mwj"
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5207,
     "status": "ok",
     "timestamp": 1604609112064,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "GIlU3Pq_9PTH",
    "outputId": "a74538fe-2a97-4b8b-d5e7-757ecaf01d1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: janome in c:\\users\\kei\\anaconda3\\envs\\school\\lib\\site-packages (0.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install janome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 5203,
     "status": "ok",
     "timestamp": 1604609112065,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "NaLzDlDO9WVO"
   },
   "outputs": [],
   "source": [
    "import janome\n",
    "from janome.tokenizer import Tokenizer\n",
    "from torchtext import data\n",
    "from torchtext import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 5200,
     "status": "ok",
     "timestamp": 1604609112066,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "Yw4rgSs_9YNf"
   },
   "outputs": [],
   "source": [
    "j_t = Tokenizer()\n",
    "def tokenizer(text): \n",
    "    return [tok for tok in j_t.tokenize(text, wakati=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 5197,
     "status": "ok",
     "timestamp": 1604609112066,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "xVD8nOgH9Z92"
   },
   "outputs": [],
   "source": [
    "SRC = data.Field(sequential=True, tokenize=tokenizer,init_token='<sos>',\n",
    "                            eos_token='<eos>', lower=True, fix_length = 100)\n",
    "TRG = data.Field(sequential=True, tokenize=tokenizer,init_token='<sos>',\n",
    "                            eos_token='<eos>', lower=True, fix_length = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 50651,
     "status": "ok",
     "timestamp": 1604609157523,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "z_W9CJc_9bl5"
   },
   "outputs": [],
   "source": [
    "train, val, test = data.TabularDataset.splits(\n",
    "        path=\"./\", train='train.tsv',\n",
    "        validation='val.tsv', test='test.tsv', format='tsv',\n",
    "        fields=[('SRC', SRC), ('TRG', TRG)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 50649,
     "status": "ok",
     "timestamp": 1604609157525,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "OC130WaB9ixV"
   },
   "outputs": [],
   "source": [
    "SRC.build_vocab(train, min_freq=1)\n",
    "TRG.build_vocab(train, min_freq=1)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 50647,
     "status": "ok",
     "timestamp": 1604609157526,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "_7082vlFHIR8"
   },
   "outputs": [],
   "source": [
    "train_batch_size = 100\n",
    "test_batch_size = 10\n",
    "eval_batch_size = 50\n",
    "train_iter, val_iter, test_iter = data.BucketIterator.splits((train, val, test), sort = False,  batch_sizes = (train_batch_size,eval_batch_size, test_batch_size), device= device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 50642,
     "status": "ok",
     "timestamp": 1604609157526,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "lbMYa-elbFVl",
    "outputId": "c54bf51e-7167-4eeb-ff4c-bf4e2d39ff4a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_iter.data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 50638,
     "status": "ok",
     "timestamp": 1604609157527,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "c3Khrj4y95-F"
   },
   "outputs": [],
   "source": [
    "ntokens = len(SRC.vocab.stoi) # the size of vocabulary\n",
    "emsize = 200 # embedding dimension\n",
    "nhid = 200 # the dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 2 # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 2 # the number of heads in the multiheadattention models\n",
    "dropout = 0.5 # the dropout value\n",
    "model = TransformerModel(ntokens, emsize, nhead, nhid, nlayers, dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 50635,
     "status": "ok",
     "timestamp": 1604609157527,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "xKasgK4M98rJ"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 5 # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
    "\n",
    "import time\n",
    "def train(iterator):\n",
    "    model.train() # Turn on the train mode\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    ntokens = len(SRC.vocab.stoi)\n",
    "    #src_mask = model.generate_square_subsequent_mask(data.shape[0]).to(device)\n",
    "    for i, batch in enumerate(iterator):\n",
    "        data = batch.SRC\n",
    "        targets = batch.TRG\n",
    "        optimizer.zero_grad()\n",
    "        src_mask = model.generate_square_subsequent_mask(data.shape[0]).to(device)\n",
    "        output = model(data, src_mask)\n",
    "        output = output[1:].view(-1, output.shape[-1])\n",
    "        targets = targets[1:].view(-1)\n",
    "        loss = criterion(output.view(-1, output.shape[-1]), targets)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "\n",
    "def evaluate(eval_model, data_source):\n",
    "    eval_model.eval() # Turn on the evaluation mode\n",
    "    total_loss = 0.\n",
    "    ntokens = len(SRC.vocab.stoi)\n",
    "    #src_mask = model.generate_square_subsequent_mask(bptt).to(device)\n",
    "    with torch.no_grad():\n",
    "      for i, batch in enumerate(data_source):\n",
    "        data = batch.SRC\n",
    "        targets = batch.TRG\n",
    "        src_mask = model.generate_square_subsequent_mask(data.shape[0]).to(device)\n",
    "        output = eval_model(data, src_mask)\n",
    "        output_flat = output[1:].view(-1, output.shape[-1])\n",
    "        targets = targets[1:].view(-1)\n",
    "        total_loss += len(data) * criterion(output_flat.view(-1, output.shape[-1]), targets).item()\n",
    "    return total_loss / (len(data_source) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BH0OwGrB-N81",
    "outputId": "c41bea40-8c7b-48cd-9033-a3e212dc6952"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 22.97s | valid loss 25.26 | valid ppl 92931421749.54\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 22.48s | valid loss 24.01 | valid ppl 26863316243.53\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float(\"inf\")\n",
    "epochs = 50 # The number of epochs\n",
    "best_model = None\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(train_iter)\n",
    "    val_loss = evaluate(model, val_iter)\n",
    "    print('-' * 89)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n",
    "          'valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n",
    "                                     val_loss, math.exp(val_loss)))\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = model\n",
    "\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6andFXy1or7x"
   },
   "outputs": [],
   "source": [
    "test_loss = evaluate(best_model, test_iter)\n",
    "print('=' * 89)\n",
    "print('| End of training | test loss {:5.2f} | test ppl {:8.2f}'.format(\n",
    "    test_loss, math.exp(test_loss)))\n",
    "print('=' * 89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vOLgVcFE_n15"
   },
   "outputs": [],
   "source": [
    "torch.save(best_model.state_dict(), \"/content/dirve/My Drive/Colab Notebooks/model/transformer.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m9G-YLtje1TX"
   },
   "outputs": [],
   "source": [
    "model.state_dict(torch.load(\"/content/dirve/My Drive/Colab Notebooks/model/transformer.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FBZa649k2P36"
   },
   "outputs": [],
   "source": [
    "def gen_sentence(sentence, src_field, trg_field, model, batch_size):\n",
    "  model.eval()\n",
    "  in_str, out_str, pred, tmp = [], [], [], []\n",
    "  length = len(sentence)\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for _, batch in enumerate(sentence):\n",
    "      src = batch.SRC\n",
    "      trg = batch.TRG\n",
    "      src_mask = model.generate_square_subsequent_mask(src.shape[0]).to(device)\n",
    "      output = model(src, src_mask)\n",
    "          \n",
    "      for j in range(min(length, batch_size)):\n",
    "        _, topi = output.data.topk(1)\n",
    "        _, topi_s = output.data.topk(2) \n",
    "        for k in range(topi.size()[1]):\n",
    "          if topi[:, k][0] == trg_field.vocab.stoi[\"<eos>\"]:\n",
    "            for m in range(topi_s.size()[0]):\n",
    "              for l in range(topi_s.size()[1]):\n",
    "                topi[m][l][0] = topi_s[m][l][1]\n",
    "          for i in range(topi.size()[0]):\n",
    "            if trg_field.vocab.itos[topi[:, k][i]] == \"<eos>\":\n",
    "              break\n",
    "            tmp.append(trg_field.vocab.itos[topi[:, k][i]])\n",
    "          pred.append(tmp)\n",
    "          print(tmp)\n",
    "          tmp = []\n",
    "        in_str.append([src_field.vocab.itos[i.item()] for i in src[:,j] if src_field.vocab.itos[i.item()] != \"<eos>\"])\n",
    "        out_str.append([trg_field.vocab.itos[i.item()] for i in trg[:,j] if trg_field.vocab.itos[i.item()] != \"<eos>\"])\n",
    "      \n",
    "  return in_str, out_str, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wo5jiKDXR1cJ"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for _, batch in enumerate(test_iter):\n",
    "      src = batch.SRC\n",
    "      trg = batch.TRG\n",
    "      src_mask = model.generate_square_subsequent_mask(src.shape[0]).to(device)\n",
    "      output = model(src, src_mask)\n",
    "      _, topi = output.data.topk(1)\n",
    "      for k in range(topi.size()[1]):\n",
    "        print(topi[:, k][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1RIlFI5G5JzZ"
   },
   "outputs": [],
   "source": [
    "# 中間発表時にはテストデータは用いない\n",
    "test_in, test_out, test_pred = [],[],[]\n",
    "test_in, test_out, test_pred = gen_sentence(test_iter, SRC, TRG, best_model, test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BG29LUs-IeWT"
   },
   "outputs": [],
   "source": [
    "val_in, val_out, val_pred = [],[],[]\n",
    "val_in, val_out, val_pred = gen_sentence(val_iter, SRC, TRG, best_model, eval_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r2Us-WpbIewl"
   },
   "outputs": [],
   "source": [
    "train_in, train_out, train_pred = [],[],[]\n",
    "train_in, train_out, train_pred = gen_sentence(train_iter, SRC, TRG, best_model, train_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mlA-NqUEIjck"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wBlexgq5IlSW"
   },
   "outputs": [],
   "source": [
    "def convert_list_to_df(in_list, out_list, pred_list):\n",
    "  row = []\n",
    "  for i in range(len(in_list)):\n",
    "    batch_input = in_list[i]\n",
    "    batch_output = out_list[i]\n",
    "    batch_pred = pred_list[i]\n",
    "    input = [j for j in batch_input if j != \"<pad>\" and j != \"<sos>\" and j != \"<eos>\" and j != \"<unk>\"]\n",
    "    output = [j for j in batch_output if j != \"<pad>\" and j != \"<sos>\" and j != \"<eos>\" and j != \"<unk>\"]\n",
    "    predict = [j for j in batch_pred if j != \"<pad>\" and j != \"<sos>\" and j != \"<eos>\" and j != \"<unk>\"]\n",
    "    input_str = \"\".join(input)\n",
    "    output_str =\"\".join(output)\n",
    "    predict_str = \"\".join(predict)\n",
    "    row.append([input_str, output_str, predict_str])\n",
    "\n",
    "  df = pd.DataFrame(row, columns=[\"input\",\"answer\",\"predict\"])\n",
    "  df = df.sort_values('input')\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6pVoCwc_Inol"
   },
   "outputs": [],
   "source": [
    "train_df = convert_list_to_df(train_in, train_out, train_pred)\n",
    "val_df = convert_list_to_df(val_in, val_out, val_pred)\n",
    "test_df = convert_list_to_df(test_in, test_out, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ptcsBPKZi-0t"
   },
   "outputs": [],
   "source": [
    "df_s = pd.concat([train_df, test_df]).sort_values('input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Yd2nXK5jJKT"
   },
   "outputs": [],
   "source": [
    "df_s.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8870OnPUjK13"
   },
   "outputs": [],
   "source": [
    "df_s.to_csv(\"./csv/result_transformer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mDs4JDh-qAf0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNZ+e/Ia2ukWcxfBj2V0XcK",
   "collapsed_sections": [],
   "name": "transformers.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
