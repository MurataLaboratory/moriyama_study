{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"transformers.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMGH7v4KBfkMcuwE/8UW3iK"},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"pjiEJUtUM34r"},"source":["[code of transformer from pytorch](https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/transformer.py)\n","\n"]},{"cell_type":"code","metadata":{"id":"7Z8LGX2980EX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605749064499,"user_tz":-540,"elapsed":1798,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}},"outputId":"41ab081b-a197-4f04-a188-9dd5372cdd8f"},"source":["print('hello world')\n","import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""],"execution_count":1,"outputs":[{"output_type":"stream","text":["hello world\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kM_JvL1h9DDi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605749085879,"user_tz":-540,"elapsed":23170,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}},"outputId":"f686e234-d6d1-4e47-efb3-82c2e5188795"},"source":["from google.colab import drive\n","drive.mount('/content/dirve', force_remount=True)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/dirve\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wij1JxmL9GPC","executionInfo":{"status":"ok","timestamp":1605749089378,"user_tz":-540,"elapsed":26666,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}}},"source":["import math\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.nn import TransformerEncoder, TransformerEncoderLayer, TransformerDecoder, TransformerDecoderLayer\n","\n","class TransformerModel(nn.Module):\n","\n","    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n","        super(TransformerModel, self).__init__()\n","        self.model_type = 'Transformer'\n","        self.pos_encoder = PositionalEncoding(ninp, dropout)\n","        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n","        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n","        self.encoder = nn.Embedding(ntoken, ninp)\n","        self.decoder = nn.Embedding(ntoken, ninp)\n","        self.ninp = ninp\n","        decoder_layers = TransformerDecoderLayer(ninp, nhead, nhid, dropout)\n","        self.transformer_decoder = TransformerDecoder(decoder_layers, nlayers)\n","\n","        self.init_weights()\n","\n","    def generate_square_subsequent_mask(self, sz):\n","        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n","        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n","        return mask\n","\n","    def init_weights(self):\n","        initrange = 0.1\n","        self.encoder.weight.data.uniform_(-initrange, initrange)\n","        # self.decoder.bias.data.zero_()\n","        self.decoder.weight.data.uniform_(-initrange, initrange)\n","\n","    def forward(self, src, trg):\n","        trg_mask = model.generate_square_subsequent_mask(trg.size()[0]).to(device)\n","        # 分散表現に変換\n","        src = self.encoder(src) #* math.sqrt(self.ninp)\n","        trg = self.decoder(trg)\n","        # 位置情報を入れる\n","        src = self.pos_encoder(src)\n","        trg = self.pos_encoder(trg)\n","        # モデルにデータを入れる\n","        output = self.transformer_encoder(src)\n","        # デコーダにエンコーダの出力を入れる（ここがおかしい）\n","        output = self.transformer_decoder(trg, output,tgt_mask = trg_mask)\n","        return output"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"KdR2x3-I9Mwj","executionInfo":{"status":"ok","timestamp":1605749089379,"user_tz":-540,"elapsed":26665,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}}},"source":["class PositionalEncoding(nn.Module):\n","\n","    def __init__(self, d_model, dropout=0.1, max_len=5000):\n","        super(PositionalEncoding, self).__init__()\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","        pe = torch.zeros(max_len, d_model)\n","        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","        pe = pe.unsqueeze(0).transpose(0, 1)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        x = x + self.pe[:x.size(0), :]\n","        return self.dropout(x)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"GIlU3Pq_9PTH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605749108960,"user_tz":-540,"elapsed":46240,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}},"outputId":"006af42b-e3b0-4c3b-a628-f7ad822e15eb"},"source":["!pip install janome"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Collecting janome\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/63/98858cbead27df7536c7e300c169da0999e9704d02220dc6700b804eeff0/Janome-0.4.1-py2.py3-none-any.whl (19.7MB)\n","\u001b[K     |████████████████████████████████| 19.7MB 1.3MB/s \n","\u001b[?25hInstalling collected packages: janome\n","Successfully installed janome-0.4.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NaLzDlDO9WVO","executionInfo":{"status":"ok","timestamp":1605749108962,"user_tz":-540,"elapsed":46239,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}}},"source":["import janome\n","from janome.tokenizer import Tokenizer\n","from torchtext import data\n","from torchtext import datasets\n","import random\n","import numpy as np"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"CSloFuafEOB2","executionInfo":{"status":"ok","timestamp":1605749108964,"user_tz":-540,"elapsed":46239,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}}},"source":["SEED = 1234\n","\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yw4rgSs_9YNf","executionInfo":{"status":"ok","timestamp":1605749109181,"user_tz":-540,"elapsed":46454,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}}},"source":["j_t = Tokenizer()\n","def tokenizer(text): \n","    return [tok for tok in j_t.tokenize(text, wakati=True)]"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"z_W9CJc_9bl5","executionInfo":{"status":"ok","timestamp":1605749141609,"user_tz":-540,"elapsed":78880,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}}},"source":["SRC = data.Field(sequential=True, \n","                 tokenize=tokenizer,\n","                 init_token='<sos>',\n","                 eos_token='<eos>', \n","                 lower=True)\n","train, val, test = data.TabularDataset.splits(\n","        path=\"/content/dirve/My Drive/Colab Notebooks/data/\", \n","        train='train.tsv',\n","        validation='val.tsv', \n","        test='test.tsv', \n","        format='tsv',\n","        fields=[('src', SRC), ('trg', SRC)])"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"OC130WaB9ixV","executionInfo":{"status":"ok","timestamp":1605749141612,"user_tz":-540,"elapsed":78881,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}}},"source":["SRC.build_vocab(train, min_freq=1)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","train_batch_size = 100\n","test_batch_size = 100\n","eval_batch_size = 100\n","train_iter, val_iter, test_iter = data.BucketIterator.splits((train, val, test), sort = False,  batch_sizes = (train_batch_size,eval_batch_size, test_batch_size), device= device)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"c3Khrj4y95-F","executionInfo":{"status":"ok","timestamp":1605749155956,"user_tz":-540,"elapsed":93223,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}}},"source":["ntokens = len(SRC.vocab.stoi) # the size of vocabulary\n","emsize = len(SRC.vocab.stoi) # embedding dimension\n","nhid = 512 # the dimension of the feedforward network model in nn.TransformerEncoder\n","nlayers = 2 # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n","nhead = 2 # the number of heads in the multiheadattention models\n","dropout = 0.3 # the dropout value\n","model = TransformerModel(ntokens, emsize, nhead, nhid, nlayers, dropout).to(device)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"i4RvbEEFv7Bs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605749155957,"user_tz":-540,"elapsed":93218,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}},"outputId":"48bce378-2e65-4917-e780-b3893463daf8"},"source":["model"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TransformerModel(\n","  (pos_encoder): PositionalEncoding(\n","    (dropout): Dropout(p=0.3, inplace=False)\n","  )\n","  (transformer_encoder): TransformerEncoder(\n","    (layers): ModuleList(\n","      (0): TransformerEncoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (out_proj): _LinearWithBias(in_features=4336, out_features=4336, bias=True)\n","        )\n","        (linear1): Linear(in_features=4336, out_features=512, bias=True)\n","        (dropout): Dropout(p=0.3, inplace=False)\n","        (linear2): Linear(in_features=512, out_features=4336, bias=True)\n","        (norm1): LayerNorm((4336,), eps=1e-05, elementwise_affine=True)\n","        (norm2): LayerNorm((4336,), eps=1e-05, elementwise_affine=True)\n","        (dropout1): Dropout(p=0.3, inplace=False)\n","        (dropout2): Dropout(p=0.3, inplace=False)\n","      )\n","      (1): TransformerEncoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (out_proj): _LinearWithBias(in_features=4336, out_features=4336, bias=True)\n","        )\n","        (linear1): Linear(in_features=4336, out_features=512, bias=True)\n","        (dropout): Dropout(p=0.3, inplace=False)\n","        (linear2): Linear(in_features=512, out_features=4336, bias=True)\n","        (norm1): LayerNorm((4336,), eps=1e-05, elementwise_affine=True)\n","        (norm2): LayerNorm((4336,), eps=1e-05, elementwise_affine=True)\n","        (dropout1): Dropout(p=0.3, inplace=False)\n","        (dropout2): Dropout(p=0.3, inplace=False)\n","      )\n","    )\n","  )\n","  (encoder): Embedding(4336, 4336)\n","  (decoder): Embedding(4336, 4336)\n","  (transformer_decoder): TransformerDecoder(\n","    (layers): ModuleList(\n","      (0): TransformerDecoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (out_proj): _LinearWithBias(in_features=4336, out_features=4336, bias=True)\n","        )\n","        (multihead_attn): MultiheadAttention(\n","          (out_proj): _LinearWithBias(in_features=4336, out_features=4336, bias=True)\n","        )\n","        (linear1): Linear(in_features=4336, out_features=512, bias=True)\n","        (dropout): Dropout(p=0.3, inplace=False)\n","        (linear2): Linear(in_features=512, out_features=4336, bias=True)\n","        (norm1): LayerNorm((4336,), eps=1e-05, elementwise_affine=True)\n","        (norm2): LayerNorm((4336,), eps=1e-05, elementwise_affine=True)\n","        (norm3): LayerNorm((4336,), eps=1e-05, elementwise_affine=True)\n","        (dropout1): Dropout(p=0.3, inplace=False)\n","        (dropout2): Dropout(p=0.3, inplace=False)\n","        (dropout3): Dropout(p=0.3, inplace=False)\n","      )\n","      (1): TransformerDecoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (out_proj): _LinearWithBias(in_features=4336, out_features=4336, bias=True)\n","        )\n","        (multihead_attn): MultiheadAttention(\n","          (out_proj): _LinearWithBias(in_features=4336, out_features=4336, bias=True)\n","        )\n","        (linear1): Linear(in_features=4336, out_features=512, bias=True)\n","        (dropout): Dropout(p=0.3, inplace=False)\n","        (linear2): Linear(in_features=512, out_features=4336, bias=True)\n","        (norm1): LayerNorm((4336,), eps=1e-05, elementwise_affine=True)\n","        (norm2): LayerNorm((4336,), eps=1e-05, elementwise_affine=True)\n","        (norm3): LayerNorm((4336,), eps=1e-05, elementwise_affine=True)\n","        (dropout1): Dropout(p=0.3, inplace=False)\n","        (dropout2): Dropout(p=0.3, inplace=False)\n","        (dropout3): Dropout(p=0.3, inplace=False)\n","      )\n","    )\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"xKasgK4M98rJ","executionInfo":{"status":"ok","timestamp":1605749155957,"user_tz":-540,"elapsed":93215,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}}},"source":["criterion = nn.CrossEntropyLoss(ignore_index=SRC.vocab.stoi[\"<pad>\"])\n","lr = 5 # learning rate\n","optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n","\n","import time\n","def train(iterator):\n","    model.train() # Turn on the train mode\n","    total_loss = 0.\n","    start_time = time.time()\n","    for i, batch in enumerate(iterator):\n","        #print(i)\n","        src = batch.src\n","        trg = batch.trg\n","        optimizer.zero_grad()\n","        output = model(src, trg)\n","        output = output[:].view(-1, output.shape[-1])\n","        trg = trg[:].view(-1)\n","        loss = criterion(output, trg)\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","        \n","\n","def evaluate(eval_model, data_source):\n","    eval_model.eval() # Turn on the evaluation mode\n","    total_loss = 0.\n","    with torch.no_grad():\n","      for i, batch in enumerate(data_source):\n","        data = batch.src\n","        targets = batch.trg\n","        #src_mask = model.generate_square_subsequent_mask(data.shape[0]).to(device)\n","        output = eval_model(data, targets)\n","        output_flat = output[:].view(-1, output.shape[-1])\n","        targets = targets[:].view(-1)\n","        total_loss += len(data) * criterion(output_flat, targets).item()\n","    return total_loss / (len(data_source) - 1)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"BH0OwGrB-N81","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605760592122,"user_tz":-540,"elapsed":11529373,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}},"outputId":"9769ea8e-0605-4970-a46d-b9fac3df9342"},"source":["best_val_loss = float(\"inf\")\n","epochs = 20 # The number of epochs\n","best_model = None\n","model.init_weights()\n","\n","for epoch in range(1, epochs + 1):\n","    epoch_start_time = time.time()\n","    train(train_iter)\n","    val_loss = evaluate(model, val_iter)\n","    print('-' * 89)\n","    print('| epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n","          .format(epoch, (time.time() - epoch_start_time), val_loss))\n","\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        best_model = model\n","\n","    scheduler.step()"],"execution_count":14,"outputs":[{"output_type":"stream","text":["-----------------------------------------------------------------------------------------\n","| epoch   1 | time: 555.86s | valid loss 199.56 | \n","-----------------------------------------------------------------------------------------\n","| epoch   2 | time: 574.11s | valid loss 192.27 | \n","-----------------------------------------------------------------------------------------\n","| epoch   3 | time: 578.14s | valid loss 220.51 | \n","-----------------------------------------------------------------------------------------\n","| epoch   4 | time: 575.09s | valid loss 173.53 | \n","-----------------------------------------------------------------------------------------\n","| epoch   5 | time: 579.52s | valid loss 157.72 | \n","-----------------------------------------------------------------------------------------\n","| epoch   6 | time: 575.98s | valid loss 197.76 | \n","-----------------------------------------------------------------------------------------\n","| epoch   7 | time: 574.73s | valid loss 148.03 | \n","-----------------------------------------------------------------------------------------\n","| epoch   8 | time: 573.51s | valid loss 135.58 | \n","-----------------------------------------------------------------------------------------\n","| epoch   9 | time: 574.89s | valid loss 124.23 | \n","-----------------------------------------------------------------------------------------\n","| epoch  10 | time: 578.21s | valid loss 119.59 | \n","-----------------------------------------------------------------------------------------\n","| epoch  11 | time: 568.22s | valid loss 108.26 | \n","-----------------------------------------------------------------------------------------\n","| epoch  12 | time: 577.17s | valid loss 112.91 | \n","-----------------------------------------------------------------------------------------\n","| epoch  13 | time: 569.06s | valid loss 92.43 | \n","-----------------------------------------------------------------------------------------\n","| epoch  14 | time: 568.74s | valid loss 83.13 | \n","-----------------------------------------------------------------------------------------\n","| epoch  15 | time: 567.45s | valid loss 76.98 | \n","-----------------------------------------------------------------------------------------\n","| epoch  16 | time: 569.81s | valid loss 78.47 | \n","-----------------------------------------------------------------------------------------\n","| epoch  17 | time: 567.92s | valid loss 80.63 | \n","-----------------------------------------------------------------------------------------\n","| epoch  18 | time: 567.90s | valid loss 69.67 | \n","-----------------------------------------------------------------------------------------\n","| epoch  19 | time: 572.12s | valid loss 63.81 | \n","-----------------------------------------------------------------------------------------\n","| epoch  20 | time: 567.97s | valid loss 64.43 | \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6andFXy1or7x","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605760602725,"user_tz":-540,"elapsed":11539974,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}},"outputId":"97bd8eb6-9823-4a59-e12d-37e2c42bef9f"},"source":["test_loss = evaluate(best_model, test_iter)\n","print('=' * 89)\n","print('| End of training | test loss {:5.2f} | test ppl {:8.2f}'.format(\n","    test_loss, math.exp(test_loss)))\n","print('=' * 89)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["=========================================================================================\n","| End of training | test loss 63.54 | test ppl 3927295755273278620350545920.00\n","=========================================================================================\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vOLgVcFE_n15","executionInfo":{"status":"ok","timestamp":1605760626357,"user_tz":-540,"elapsed":11563604,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}}},"source":["torch.save(best_model.state_dict(), \"/content/dirve/My Drive/Colab Notebooks/model/transformer.pth\")"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"m9G-YLtje1TX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605760633416,"user_tz":-540,"elapsed":11570661,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}},"outputId":"3b71103e-6499-4fa1-c0d7-1a55abcd0734"},"source":["model.state_dict(torch.load(\"/content/dirve/My Drive/Colab Notebooks/model/transformer.pth\"))"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["OrderedDict([('pos_encoder.pe',\n","              tensor([[[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n","                         0.0000e+00,  1.0000e+00]],\n","              \n","                      [[ 8.4147e-01,  5.4030e-01,  8.3917e-01,  ...,  1.0000e+00,\n","                         1.0043e-04,  1.0000e+00]],\n","              \n","                      [[ 9.0930e-01, -4.1615e-01,  9.1279e-01,  ...,  1.0000e+00,\n","                         2.0085e-04,  1.0000e+00]],\n","              \n","                      ...,\n","              \n","                      [[ 9.5625e-01, -2.9254e-01, -4.5007e-01,  ...,  8.7568e-01,\n","                         4.8103e-01,  8.7671e-01]],\n","              \n","                      [[ 2.7050e-01, -9.6272e-01,  5.0488e-01,  ...,  8.7563e-01,\n","                         4.8112e-01,  8.7666e-01]],\n","              \n","                      [[-6.6395e-01, -7.4778e-01,  9.9894e-01,  ...,  8.7558e-01,\n","                         4.8120e-01,  8.7661e-01]]], device='cuda:0')),\n","             ('transformer_encoder.layers.0.self_attn.in_proj_weight',\n","              tensor([[-1.7478e-02, -1.4320e-02, -6.7060e-03,  ...,  1.4053e-02,\n","                       -7.9402e-03,  9.7918e-03],\n","                      [ 4.2027e-03, -1.8704e-02, -1.3468e-02,  ...,  7.3452e-03,\n","                        1.0668e-02,  3.4901e-03],\n","                      [ 1.9171e-02, -8.1359e-03, -1.6953e-02,  ..., -8.2706e-03,\n","                        1.1598e-02, -1.5069e-03],\n","                      ...,\n","                      [-1.7137e-02,  5.0771e-03,  9.5509e-03,  ...,  1.6503e-02,\n","                        1.6679e-02, -6.3064e-03],\n","                      [-1.0474e-02, -1.5046e-02, -7.4261e-03,  ..., -8.7687e-05,\n","                       -8.1540e-03,  8.4271e-03],\n","                      [ 5.8026e-04, -1.1202e-02, -3.7210e-03,  ..., -1.1001e-02,\n","                        1.5034e-02, -1.4637e-02]], device='cuda:0')),\n","             ('transformer_encoder.layers.0.self_attn.in_proj_bias',\n","              tensor([-1.4257e-03, -1.8019e-03,  4.8486e-04,  ..., -9.2147e-04,\n","                       7.7973e-05,  1.5137e-03], device='cuda:0')),\n","             ('transformer_encoder.layers.0.self_attn.out_proj.weight',\n","              tensor([[-0.0149, -0.0029, -0.0072,  ..., -0.0045,  0.0083,  0.0080],\n","                      [ 0.0011,  0.0118, -0.0119,  ..., -0.0067,  0.0063,  0.0109],\n","                      [-0.0021, -0.0003,  0.0029,  ...,  0.0131,  0.0053, -0.0034],\n","                      ...,\n","                      [ 0.0064,  0.0011, -0.0040,  ..., -0.0013,  0.0104, -0.0091],\n","                      [-0.0035,  0.0104, -0.0055,  ..., -0.0078, -0.0024,  0.0155],\n","                      [ 0.0047,  0.0134,  0.0002,  ..., -0.0028,  0.0137,  0.0132]],\n","                     device='cuda:0')),\n","             ('transformer_encoder.layers.0.self_attn.out_proj.bias',\n","              tensor([ 1.9483e-03, -8.0108e-06,  3.2969e-04,  ..., -2.9685e-03,\n","                       3.5198e-03, -3.8064e-03], device='cuda:0')),\n","             ('transformer_encoder.layers.0.linear1.weight',\n","              tensor([[-0.0037,  0.0046, -0.0102,  ...,  0.0103,  0.0151, -0.0017],\n","                      [-0.0122,  0.0152, -0.0118,  ..., -0.0132, -0.0070,  0.0003],\n","                      [ 0.0158, -0.0092,  0.0034,  ..., -0.0129, -0.0015, -0.0022],\n","                      ...,\n","                      [ 0.0086,  0.0117,  0.0057,  ..., -0.0076, -0.0015,  0.0090],\n","                      [ 0.0105,  0.0082,  0.0007,  ..., -0.0107, -0.0051,  0.0019],\n","                      [-0.0055, -0.0115,  0.0041,  ..., -0.0036, -0.0049,  0.0105]],\n","                     device='cuda:0')),\n","             ('transformer_encoder.layers.0.linear1.bias',\n","              tensor([-1.5117e-02, -1.4767e-03, -5.4936e-03, -7.1516e-03,  9.5190e-03,\n","                       8.4889e-03,  8.2813e-03,  4.9169e-03, -1.4827e-02, -1.3384e-02,\n","                      -5.3534e-03,  9.7076e-03,  9.7056e-03,  1.9908e-02,  4.1203e-03,\n","                      -3.7419e-03,  4.3630e-03, -1.4339e-02, -1.0011e-02, -6.8384e-03,\n","                      -8.5973e-03,  1.1948e-02, -8.7848e-03, -7.1178e-03,  1.2914e-03,\n","                       1.3523e-02,  1.1210e-02, -4.3574e-03,  6.1182e-03, -2.4541e-03,\n","                      -1.5688e-02,  1.0834e-03, -3.7253e-03,  5.4492e-03, -9.1469e-03,\n","                       5.5259e-03, -8.9462e-03, -5.7569e-04,  2.2283e-03,  7.9121e-05,\n","                      -1.2406e-02,  1.1797e-02,  1.0101e-02,  1.5247e-02,  6.0365e-03,\n","                       1.0707e-02, -1.0164e-02, -1.2547e-02,  5.1110e-03, -1.4020e-02,\n","                      -3.7420e-03, -5.1307e-03, -8.2431e-03,  7.1053e-03, -7.4831e-03,\n","                      -9.1856e-03,  3.5331e-03,  1.4581e-02, -1.5897e-02,  1.2615e-02,\n","                       6.5995e-03, -4.3647e-03, -1.4581e-02,  8.7463e-03,  1.6740e-03,\n","                      -6.4202e-03,  6.5051e-04, -4.0786e-03, -1.4770e-02,  1.3512e-03,\n","                       1.2349e-02, -2.7898e-03, -1.2690e-02,  1.0855e-02, -8.4823e-03,\n","                       1.3418e-02,  6.1233e-03,  4.0722e-05,  1.0379e-02, -1.4657e-02,\n","                      -5.4451e-03, -7.4690e-03, -3.8203e-03,  1.3549e-02, -1.3140e-03,\n","                       2.3223e-03, -7.0683e-03, -1.3640e-02, -9.1587e-03, -5.5159e-04,\n","                      -6.1685e-03, -4.9003e-03,  1.1092e-02, -4.7355e-03,  2.0032e-03,\n","                       7.6465e-03, -5.2506e-03,  1.3338e-02, -8.3194e-03,  1.1677e-02,\n","                      -1.0769e-02, -1.5662e-02,  1.3067e-02, -9.0968e-03,  2.9311e-02,\n","                       4.4743e-03,  1.3509e-02,  6.6865e-03,  4.1717e-03, -2.2158e-03,\n","                      -7.8415e-03, -1.5555e-02,  1.1440e-02,  1.2076e-02, -1.5040e-02,\n","                       5.7005e-03, -1.3710e-02,  1.0952e-02,  5.4687e-03, -1.5835e-02,\n","                       5.0847e-03, -5.4488e-03, -1.2635e-02,  6.0849e-03, -1.0402e-02,\n","                       6.4133e-03, -6.2298e-03,  5.6332e-03, -7.8363e-03,  1.4003e-02,\n","                      -1.1610e-02, -1.4206e-02,  2.7777e-03, -4.4346e-03, -1.5869e-02,\n","                       1.0956e-02,  7.2877e-03,  3.7243e-03,  7.3998e-05,  7.4321e-03,\n","                      -2.1013e-03, -5.8940e-03, -1.7349e-03,  6.0474e-03,  9.2798e-03,\n","                       2.7604e-03, -4.7052e-03,  3.5507e-03, -9.5845e-03,  1.0273e-02,\n","                       3.2928e-03, -3.1376e-03,  8.5890e-03, -7.1756e-03,  1.2445e-02,\n","                      -2.6538e-03, -1.4824e-02, -4.7895e-03,  1.0905e-02,  3.8018e-03,\n","                       1.5426e-02, -1.3250e-02,  1.4513e-03, -1.1273e-02,  1.0656e-02,\n","                       8.2648e-03, -9.4446e-03, -1.0698e-02,  7.1494e-03, -1.0790e-02,\n","                      -1.2351e-02, -4.3555e-03, -4.2663e-03,  1.4022e-02,  1.9664e-03,\n","                      -1.0284e-02,  3.8528e-03, -1.0590e-02, -1.0510e-02,  2.6498e-03,\n","                      -8.3917e-03, -1.2069e-02, -5.0879e-04,  1.8465e-03,  7.6385e-03,\n","                       1.2942e-03,  9.8582e-03,  8.2908e-03,  3.2241e-04,  1.4017e-02,\n","                       3.1913e-03, -7.6930e-03, -1.2213e-02,  1.2114e-02, -1.6013e-02,\n","                      -7.2951e-03, -1.4367e-02, -1.0518e-03, -7.6484e-04,  2.5541e-03,\n","                      -5.8681e-03,  1.2787e-02, -3.7726e-03, -3.4417e-03,  1.1190e-02,\n","                       1.1272e-03,  1.3494e-02, -1.1520e-02, -1.3936e-02, -1.0698e-02,\n","                      -6.0918e-03, -6.6016e-03,  1.3323e-02, -1.2306e-02,  8.6299e-03,\n","                       1.3748e-02, -1.5508e-02, -4.0799e-03,  7.9559e-03,  1.2873e-02,\n","                       6.0215e-04,  1.0885e-02, -3.7570e-03,  2.9452e-03,  2.9672e-03,\n","                       2.0440e-04,  1.0159e-02, -4.7379e-03, -1.2701e-02,  1.2410e-02,\n","                       6.8091e-03,  1.1466e-02,  7.8486e-03, -7.7949e-03, -1.4191e-02,\n","                       5.8216e-03,  2.0225e-03,  1.1194e-02,  6.3596e-05,  4.1373e-03,\n","                       9.8081e-03,  7.7371e-03, -5.7755e-03, -1.2067e-03, -2.8754e-03,\n","                       1.1952e-02,  7.3881e-03, -9.3525e-03,  8.1727e-03,  5.3722e-03,\n","                      -2.5300e-03, -9.8452e-04,  1.0250e-02,  1.4790e-02,  1.3094e-02,\n","                       4.8203e-03, -1.4919e-02, -8.5204e-03, -4.9195e-03, -1.2589e-02,\n","                      -1.0298e-02, -9.6343e-03,  3.2736e-03, -3.2393e-03, -4.2758e-03,\n","                      -5.2127e-03, -1.2505e-03, -1.1025e-02,  6.8217e-03, -1.6775e-03,\n","                      -1.5146e-02, -1.0177e-02,  7.5279e-03, -1.7935e-03,  7.5625e-03,\n","                       8.2183e-04, -1.1234e-02, -1.2258e-02,  1.9241e-03,  6.4805e-03,\n","                      -9.8955e-03,  6.0610e-03,  6.3593e-03, -4.0843e-03, -1.5249e-02,\n","                      -8.1532e-03,  1.3536e-03,  1.4639e-02, -1.2045e-02,  9.0773e-03,\n","                       1.9524e-03,  3.3041e-03, -8.2835e-04, -9.8890e-03, -8.0197e-03,\n","                       1.0319e-02, -6.9868e-03, -1.4068e-02, -1.4171e-02, -3.8812e-03,\n","                      -9.4232e-03,  3.1149e-03,  1.1357e-03, -4.1720e-03,  7.3730e-03,\n","                       2.6346e-03, -8.9634e-05, -1.4046e-02,  1.3402e-03,  1.3711e-02,\n","                       1.3093e-03, -1.0231e-02, -2.6796e-03, -1.1787e-02,  1.5059e-02,\n","                       1.6297e-03, -7.8367e-03,  6.4803e-05,  1.0367e-02,  1.2304e-02,\n","                       4.0435e-03, -7.2012e-03, -9.3045e-03, -6.9105e-03,  1.1147e-02,\n","                      -2.5162e-03,  3.4047e-03, -2.5134e-03, -8.8965e-03,  1.1701e-02,\n","                       1.0265e-02, -5.2976e-03,  9.0744e-03, -6.7156e-03, -4.3718e-03,\n","                      -8.3433e-04,  6.3355e-03, -1.2081e-02, -4.8547e-03,  5.0040e-03,\n","                      -9.0053e-03,  5.6488e-03,  3.7340e-03,  1.0701e-02,  3.0228e-03,\n","                       7.7759e-03,  4.8720e-03,  1.1364e-02,  7.3836e-03,  1.1860e-02,\n","                       8.6670e-02, -9.2468e-03,  5.2142e-03,  1.1203e-02, -1.6298e-02,\n","                       3.9723e-03, -6.7389e-03,  1.4430e-02, -5.8135e-03,  1.4372e-03,\n","                      -9.2695e-04,  2.9168e-03,  4.3960e-03,  9.4293e-03, -3.4131e-03,\n","                      -7.4098e-03,  2.1504e-03, -3.4748e-04, -5.8597e-03,  5.7247e-02,\n","                       5.4245e-03, -1.3703e-02, -8.3634e-04, -5.4263e-03, -9.7142e-04,\n","                      -1.5426e-02, -1.6574e-04,  5.0372e-03,  1.1811e-02, -4.1097e-03,\n","                      -1.1118e-03,  1.8402e-03,  1.4166e-02,  1.2182e-02,  1.0572e-02,\n","                      -9.4940e-03, -1.2249e-02,  5.1929e-06, -1.5568e-02,  1.9439e-03,\n","                      -1.1212e-03,  3.2639e-03,  1.4107e-03, -8.9929e-03, -2.9567e-03,\n","                       1.1446e-02, -6.8693e-03,  7.1161e-03,  8.1830e-03, -9.0326e-03,\n","                       1.0641e-03,  1.2825e-03,  2.0359e-03, -2.4341e-03, -3.0764e-03,\n","                       1.4783e-02, -6.6200e-03, -1.4586e-02,  1.0085e-02, -3.7458e-03,\n","                      -1.1004e-02,  5.0106e-03, -8.9931e-03, -1.4692e-02,  6.5313e-03,\n","                      -1.3289e-02, -2.1594e-03,  1.1709e-02,  6.2684e-03,  1.1059e-02,\n","                      -7.7747e-03, -1.7129e-02, -1.2577e-02,  3.8571e-03,  1.3449e-02,\n","                       1.1963e-02,  9.0424e-03, -8.5991e-03,  1.1722e-02, -8.1355e-03,\n","                       9.9745e-03,  1.1778e-02, -9.9615e-03, -2.0122e-03, -4.4762e-03,\n","                       1.1442e-03,  2.8116e-03,  1.3690e-02, -1.0191e-02, -1.3368e-02,\n","                      -1.6985e-02,  1.1965e-02, -1.0116e-03,  5.2771e-04, -5.0393e-04,\n","                       1.2416e-02, -1.1012e-02, -1.5369e-02,  4.2156e-03,  3.3837e-03,\n","                      -1.8835e-05, -6.2347e-04,  1.3849e-02, -1.3362e-02,  5.2301e-03,\n","                       7.0190e-03, -1.2057e-02,  5.5464e-03, -3.8417e-04, -4.7679e-03,\n","                       5.0916e-03, -1.1093e-02, -7.9866e-03,  4.3092e-02,  5.7099e-03,\n","                      -6.5898e-03, -4.0341e-03, -9.5473e-03, -9.4218e-03, -2.7655e-03,\n","                       9.8224e-03, -8.0874e-03,  7.7234e-03, -5.8826e-03,  1.6257e-02,\n","                      -1.5672e-02,  4.5733e-03, -7.1235e-03,  1.8036e-02,  2.0253e-03,\n","                       1.4349e-02, -1.4493e-02, -7.8592e-04,  3.4932e-03,  1.2998e-02,\n","                      -1.1122e-02, -1.5623e-03, -1.5977e-02, -3.1348e-03, -1.3684e-02,\n","                       1.1685e-03,  7.1280e-03,  2.1965e-03,  1.4244e-02,  7.1971e-04,\n","                      -6.7613e-03,  2.3517e-03, -5.0653e-03,  6.5524e-03,  2.7549e-03,\n","                       3.5960e-03,  7.1001e-03, -8.5339e-03, -1.6844e-03,  1.3296e-03,\n","                       1.2944e-02, -4.6185e-04, -1.1642e-02, -1.2155e-02,  6.0113e-03,\n","                      -4.8521e-03,  9.5228e-03], device='cuda:0')),\n","             ('transformer_encoder.layers.0.linear2.weight',\n","              tensor([[ 4.6397e-05,  3.1618e-02,  1.2775e-02,  ...,  1.9742e-02,\n","                       -5.8010e-03, -3.0863e-02],\n","                      [-1.3003e-02, -3.7167e-02,  1.8382e-02,  ..., -2.0491e-02,\n","                       -6.9035e-04, -2.9544e-02],\n","                      [ 1.5181e-02,  9.5175e-03, -4.4088e-02,  ..., -7.4081e-03,\n","                        1.4666e-02,  1.5393e-02],\n","                      ...,\n","                      [-3.9194e-02,  7.0001e-03, -3.0304e-02,  ..., -3.9097e-02,\n","                       -2.4536e-02,  3.2578e-03],\n","                      [ 2.1298e-02,  2.6714e-02,  7.8009e-03,  ...,  2.7897e-02,\n","                       -2.5681e-02, -1.7906e-02],\n","                      [ 2.7904e-02, -2.9997e-02,  1.5360e-02,  ...,  3.5499e-02,\n","                        9.3265e-03,  6.9064e-03]], device='cuda:0')),\n","             ('transformer_encoder.layers.0.linear2.bias',\n","              tensor([-0.0008,  0.0166,  0.0313,  ...,  0.0351, -0.0343,  0.0107],\n","                     device='cuda:0')),\n","             ('transformer_encoder.layers.0.norm1.weight',\n","              tensor([0.9965, 0.9995, 0.9974,  ..., 0.9972, 0.9978, 0.9970], device='cuda:0')),\n","             ('transformer_encoder.layers.0.norm1.bias',\n","              tensor([ 0.0008,  0.0019,  0.0011,  ..., -0.0004,  0.0024, -0.0022],\n","                     device='cuda:0')),\n","             ('transformer_encoder.layers.0.norm2.weight',\n","              tensor([0.9932, 1.0244, 0.9967,  ..., 1.0009, 0.9969, 0.9996], device='cuda:0')),\n","             ('transformer_encoder.layers.0.norm2.bias',\n","              tensor([-0.0019, -0.0040, -0.0004,  ..., -0.0009, -0.0039, -0.0065],\n","                     device='cuda:0')),\n","             ('transformer_encoder.layers.1.self_attn.in_proj_weight',\n","              tensor([[-0.0185, -0.0091, -0.0063,  ...,  0.0140, -0.0077,  0.0087],\n","                      [ 0.0012, -0.0153, -0.0157,  ...,  0.0089,  0.0105,  0.0024],\n","                      [ 0.0178, -0.0102, -0.0185,  ..., -0.0069,  0.0121, -0.0056],\n","                      ...,\n","                      [-0.0179,  0.0077,  0.0094,  ...,  0.0175,  0.0174, -0.0045],\n","                      [-0.0109, -0.0157, -0.0078,  ...,  0.0003, -0.0083,  0.0083],\n","                      [ 0.0008, -0.0137, -0.0023,  ..., -0.0124,  0.0137, -0.0164]],\n","                     device='cuda:0')),\n","             ('transformer_encoder.layers.1.self_attn.in_proj_bias',\n","              tensor([-0.0018, -0.0003, -0.0011,  ..., -0.0018,  0.0003,  0.0022],\n","                     device='cuda:0')),\n","             ('transformer_encoder.layers.1.self_attn.out_proj.weight',\n","              tensor([[-1.5338e-02, -2.3759e-03, -7.6535e-03,  ..., -2.1964e-03,\n","                        7.4127e-03,  6.7623e-03],\n","                      [ 2.2255e-03,  1.1891e-02, -1.1679e-02,  ..., -4.7608e-03,\n","                        4.6493e-03,  8.7352e-03],\n","                      [-2.0548e-03, -6.8155e-04,  5.3319e-04,  ...,  1.2125e-02,\n","                        5.0915e-03, -2.9266e-03],\n","                      ...,\n","                      [ 7.1288e-03,  1.5488e-05, -2.2625e-03,  ..., -1.3082e-03,\n","                        1.1066e-02, -8.0110e-03],\n","                      [-2.0307e-03,  1.0086e-02, -5.6379e-03,  ..., -8.2192e-03,\n","                       -2.1978e-03,  1.5819e-02],\n","                      [ 4.4258e-03,  1.2680e-02,  1.7944e-03,  ...,  8.9466e-04,\n","                        1.2935e-02,  1.1942e-02]], device='cuda:0')),\n","             ('transformer_encoder.layers.1.self_attn.out_proj.bias',\n","              tensor([-0.0014, -0.0020, -0.0003,  ...,  0.0018, -0.0028, -0.0055],\n","                     device='cuda:0')),\n","             ('transformer_encoder.layers.1.linear1.weight',\n","              tensor([[-0.0082, -0.0246, -0.0056,  ...,  0.0185,  0.0153, -0.0028],\n","                      [-0.0106,  0.0150, -0.0126,  ..., -0.0094, -0.0071,  0.0009],\n","                      [ 0.0147, -0.0072,  0.0034,  ..., -0.0107, -0.0012, -0.0007],\n","                      ...,\n","                      [ 0.0079,  0.0121,  0.0038,  ..., -0.0086, -0.0082,  0.0036],\n","                      [ 0.0075,  0.0073, -0.0003,  ..., -0.0127, -0.0069,  0.0057],\n","                      [-0.0041, -0.0072,  0.0045,  ..., -0.0023, -0.0040,  0.0179]],\n","                     device='cuda:0')),\n","             ('transformer_encoder.layers.1.linear1.bias',\n","              tensor([-1.5628e-03, -1.4721e-03, -7.1996e-03, -8.8482e-03,  8.9600e-03,\n","                       7.4644e-03,  1.3461e-02,  4.5554e-03, -1.4170e-02, -8.7748e-03,\n","                      -4.5694e-03,  9.0459e-03,  1.0159e-02,  1.1494e-02,  9.0429e-03,\n","                      -4.0326e-03,  1.4345e-02, -1.4292e-02, -1.1703e-02, -6.7250e-03,\n","                      -9.2839e-03,  1.1684e-02, -9.8358e-03, -7.3673e-03,  3.6952e-04,\n","                       1.2024e-02,  1.1229e-02, -2.9208e-03,  9.7258e-03, -5.8387e-04,\n","                      -1.3527e-02, -2.0695e-04, -2.8238e-03,  5.9184e-03, -7.1563e-03,\n","                       8.2325e-03, -1.1614e-02, -1.2948e-03,  3.2835e-03, -5.0033e-03,\n","                      -1.2907e-02,  8.9993e-03,  9.6017e-03,  1.2556e-02,  6.0964e-03,\n","                       1.4119e-02, -1.0473e-02, -1.3176e-02,  1.0259e-02, -5.7905e-03,\n","                      -3.7565e-03, -5.4409e-03, -7.7597e-03,  7.7487e-03, -7.8992e-03,\n","                      -1.1737e-02,  4.3058e-03,  9.5810e-03, -1.4700e-02,  1.2294e-02,\n","                       5.8845e-03, -4.1926e-03, -1.4453e-02,  8.9723e-03,  1.2323e-03,\n","                      -1.1443e-02,  3.7238e-04, -2.6936e-03, -1.5838e-02,  7.0074e-04,\n","                       1.1617e-02, -2.0206e-03, -1.4035e-02,  1.0893e-02, -8.8472e-03,\n","                       3.0843e-02,  5.7973e-03,  1.9966e-03,  1.0457e-02, -1.5095e-02,\n","                      -6.8196e-03, -6.8364e-03, -3.7482e-03,  1.5935e-02, -3.2287e-03,\n","                       3.4459e-03,  1.0233e-02, -1.5216e-02, -9.2909e-03, -3.9557e-03,\n","                      -8.0787e-03, -5.0040e-03,  1.0026e-02, -4.4170e-03,  1.1639e-02,\n","                       1.0407e-02, -6.4560e-03,  1.3334e-02, -8.1454e-03,  1.1815e-02,\n","                      -1.0955e-02, -1.5638e-02,  1.2096e-02, -9.0055e-03,  1.2226e-02,\n","                       3.1708e-03,  1.3145e-02,  6.4678e-03,  3.1158e-03, -9.0528e-04,\n","                      -1.7360e-04, -1.2849e-02,  1.0299e-02,  1.1689e-02, -1.5759e-02,\n","                       6.5990e-03, -1.3528e-02,  1.2902e-02,  1.1862e-02, -1.5650e-02,\n","                       2.7672e-03, -6.4811e-03, -1.2335e-02,  6.3609e-03, -1.0953e-02,\n","                       5.7280e-03, -6.4828e-03,  6.0281e-03, -9.1704e-03,  8.2193e-03,\n","                      -1.4330e-02, -1.0672e-02,  4.2683e-03, -9.9337e-03, -9.6105e-03,\n","                       9.9220e-03,  7.0778e-03,  3.4826e-03,  6.6928e-04,  7.7307e-03,\n","                      -3.6879e-03, -4.6390e-03, -2.2728e-03,  5.6087e-03,  8.8096e-03,\n","                       1.4645e-02, -6.4511e-03,  4.2116e-03, -4.6052e-03,  7.4052e-03,\n","                       5.9509e-03, -3.2875e-03,  7.7518e-03, -7.9331e-03,  1.4357e-02,\n","                      -5.5617e-03, -1.5939e-02, -2.0558e-03,  4.2461e-02,  4.0381e-03,\n","                       1.3566e-02, -1.4334e-02,  5.9114e-03, -9.4212e-03,  1.3997e-02,\n","                       3.7977e-03, -9.6526e-03, -1.1692e-02,  6.5111e-03, -1.0629e-02,\n","                      -1.3120e-02, -3.8414e-03, -4.6407e-03,  1.4423e-02,  2.3586e-03,\n","                      -1.0546e-02,  5.6203e-03, -9.8361e-03, -1.0990e-02,  2.4209e-03,\n","                      -7.7695e-03, -1.2750e-02, -1.2800e-03,  3.0192e-03,  6.9008e-03,\n","                      -3.1648e-04,  9.6965e-03,  9.6960e-03,  7.0030e-04,  1.0308e-02,\n","                       1.2540e-03, -7.0178e-03, -1.2552e-02,  1.1762e-02, -1.5889e-02,\n","                      -9.5863e-03, -1.5215e-02, -1.7887e-03, -2.0122e-03,  3.9180e-03,\n","                      -5.8028e-03,  1.4512e-02, -4.9956e-03, -3.8156e-03,  1.1549e-02,\n","                       1.6305e-03,  1.4136e-02, -6.9365e-03, -1.4327e-02, -1.0430e-02,\n","                      -6.9165e-03, -6.7038e-03,  1.3059e-02,  3.9580e-03,  7.7998e-03,\n","                       1.4628e-02, -1.5011e-02, -4.5790e-03,  7.0058e-03,  9.5451e-03,\n","                      -1.0259e-04,  1.0033e-02, -3.6774e-03,  2.3355e-03,  3.4862e-03,\n","                       4.0755e-04,  1.1376e-02, -5.7148e-03, -1.3802e-02,  1.7327e-02,\n","                       6.2737e-03,  1.0737e-02,  1.2062e-02, -8.9362e-03, -1.1512e-02,\n","                       5.9114e-03,  7.2535e-04,  1.1711e-02, -7.5119e-04,  4.1131e-03,\n","                      -8.3917e-03,  6.9529e-03, -6.0341e-03, -1.2002e-03, -3.1447e-03,\n","                       1.1758e-02,  7.0968e-03, -3.8238e-03,  8.8222e-03,  5.5358e-03,\n","                      -3.0204e-03, -2.2927e-03,  9.5084e-03,  1.1766e-02,  1.3139e-02,\n","                       5.3108e-03, -1.5320e-02, -8.8224e-03, -5.3186e-03, -1.3711e-02,\n","                      -8.6202e-03, -8.9103e-03,  1.2817e-03, -4.2255e-03, -3.4701e-03,\n","                      -5.2291e-03,  5.5481e-03, -1.0411e-02,  5.1346e-03, -1.8143e-03,\n","                      -1.4924e-02, -1.0730e-02,  7.2885e-03, -2.4546e-03,  1.1823e-02,\n","                       1.5018e-04, -1.1719e-02, -1.3832e-02,  4.8445e-03,  9.7006e-03,\n","                      -1.0431e-02,  3.6650e-03,  7.2328e-03, -4.8959e-03, -1.4758e-02,\n","                       6.8198e-02, -8.2686e-04,  1.3904e-02, -1.1724e-02,  9.7023e-03,\n","                       1.5502e-03,  2.7951e-04, -1.0279e-03, -6.0898e-03, -7.2619e-03,\n","                       1.0133e-02, -1.2918e-02, -1.0777e-02, -1.5655e-02, -5.9394e-03,\n","                      -5.0699e-03,  1.9530e-03,  1.5840e-03, -6.5686e-03,  6.8966e-03,\n","                       3.8062e-03, -3.9037e-04, -1.3728e-02, -3.3222e-03,  1.3886e-02,\n","                       1.0728e-03, -9.7962e-03, -4.3945e-03, -1.2208e-02,  1.4487e-02,\n","                       2.2663e-03, -9.0779e-03, -7.6994e-04,  1.0923e-02,  1.1925e-02,\n","                       5.9288e-03, -7.9628e-03, -9.8088e-03, -1.8166e-03,  1.0481e-02,\n","                      -2.2859e-03,  4.1417e-03, -2.6259e-03, -8.7181e-03,  8.9478e-03,\n","                       1.0720e-02, -6.9017e-03,  8.4300e-03, -8.1489e-03, -7.6830e-03,\n","                      -1.2882e-03,  7.0510e-03, -1.2501e-02, -5.7503e-03,  6.0153e-03,\n","                      -7.5242e-03,  5.0979e-03,  4.9527e-03,  1.0601e-02,  2.4834e-03,\n","                      -1.0974e-02,  2.9694e-03,  1.0849e-02,  6.3028e-03,  1.1377e-02,\n","                      -9.5188e-03, -9.2081e-03,  7.5886e-03,  1.0959e-02, -1.6563e-02,\n","                       1.0094e-02, -8.9691e-03,  1.7371e-02, -1.6641e-03,  4.1369e-03,\n","                      -7.0131e-04,  2.4837e-03,  4.9468e-03,  9.4268e-03, -2.7987e-03,\n","                      -9.5889e-03,  8.1737e-04, -1.0718e-03, -6.8496e-03, -1.5502e-02,\n","                       5.8951e-03, -1.4115e-02, -1.6348e-03, -5.2796e-03, -1.1361e-03,\n","                      -1.6626e-02, -9.2783e-04,  5.0193e-03,  9.0266e-03, -4.4436e-03,\n","                       4.1546e-03,  1.7733e-03,  1.3573e-02,  1.4175e-02,  9.8382e-03,\n","                      -1.3532e-02, -1.2583e-02,  7.5970e-04, -1.3714e-02,  2.1338e-03,\n","                      -6.4927e-04,  2.3916e-03,  1.4993e-03, -9.3335e-03,  4.9494e-02,\n","                       1.0792e-02, -8.9149e-03,  5.5450e-03, -7.1596e-03, -9.2036e-03,\n","                       1.6253e-02,  3.4109e-04,  5.4783e-03,  3.3509e-05, -3.9638e-03,\n","                       1.3861e-02, -5.9884e-03, -1.3536e-02,  9.3669e-03, -3.3083e-03,\n","                      -8.9326e-03,  4.4322e-03, -7.0595e-03, -1.4354e-02,  8.4189e-03,\n","                      -1.6087e-02, -2.7733e-03,  1.1361e-02,  7.3917e-03,  9.9573e-03,\n","                      -7.6062e-03, -1.6059e-02, -1.4599e-02,  3.8368e-03,  1.3546e-02,\n","                       1.0249e-02,  1.0525e-02, -9.1417e-03,  1.2772e-02,  8.4819e-03,\n","                       1.4520e-02,  2.1774e-02, -8.7205e-03, -3.1470e-03, -9.4355e-04,\n","                       1.6005e-03,  2.4104e-03,  1.2370e-02, -1.1282e-02, -1.3332e-02,\n","                      -1.5599e-02,  1.3216e-02, -2.2946e-03, -1.2999e-03,  2.3434e-02,\n","                       1.1947e-02, -1.0887e-02, -1.6547e-02,  5.3355e-03,  1.0694e-03,\n","                       8.5541e-03, -1.2920e-03,  1.2792e-02, -1.6372e-02,  4.2320e-03,\n","                       6.9533e-03, -5.8049e-03,  7.9328e-03,  3.6798e-04, -4.5876e-03,\n","                       5.7427e-03, -6.1830e-03, -8.6930e-03,  1.1813e-02,  4.9793e-03,\n","                      -4.6541e-03, -4.8198e-03,  1.6626e-03, -9.3783e-03, -9.5606e-04,\n","                       1.0229e-02, -8.1517e-03,  5.7272e-03, -1.0835e-02,  1.2292e-02,\n","                      -1.5621e-02,  3.2552e-03, -7.5313e-03,  1.4068e-02,  3.5834e-03,\n","                       1.3788e-02, -1.4851e-02, -3.8261e-03,  2.0967e-03,  1.2381e-02,\n","                      -2.2212e-02, -1.3709e-03, -1.5619e-02, -3.8396e-03, -1.5651e-02,\n","                       1.9803e-04,  6.9655e-03,  2.1146e-03,  1.4791e-02,  9.0428e-04,\n","                      -6.3640e-03,  9.1131e-03, -5.3869e-03,  6.2323e-03,  2.2889e-03,\n","                       4.3534e-03,  5.3642e-03, -4.6768e-03, -7.6074e-04,  8.4716e-03,\n","                       1.3951e-02, -2.5467e-03, -1.0237e-03, -1.1973e-02,  6.1884e-03,\n","                      -3.5786e-03,  8.9328e-03], device='cuda:0')),\n","             ('transformer_encoder.layers.1.linear2.weight',\n","              tensor([[-0.0024,  0.0326,  0.0131,  ...,  0.0184, -0.0058, -0.0315],\n","                      [-0.0124, -0.0337,  0.0182,  ..., -0.0219, -0.0029, -0.0291],\n","                      [ 0.0519,  0.0106, -0.0438,  ..., -0.0065,  0.0160,  0.0163],\n","                      ...,\n","                      [-0.0170,  0.0073, -0.0312,  ..., -0.0386, -0.0261,  0.0020],\n","                      [ 0.0272,  0.0249,  0.0077,  ...,  0.0301, -0.0263, -0.0172],\n","                      [ 0.0282, -0.0292,  0.0148,  ...,  0.0349,  0.0048,  0.0070]],\n","                     device='cuda:0')),\n","             ('transformer_encoder.layers.1.linear2.bias',\n","              tensor([-0.0020,  0.0209,  0.0314,  ...,  0.0336, -0.0337,  0.0133],\n","                     device='cuda:0')),\n","             ('transformer_encoder.layers.1.norm1.weight',\n","              tensor([0.9984, 1.0035, 0.9979,  ..., 0.9978, 0.9981, 0.9906], device='cuda:0')),\n","             ('transformer_encoder.layers.1.norm1.bias',\n","              tensor([-3.8880e-03, -6.5696e-03,  7.3127e-06,  ...,  2.7914e-03,\n","                      -3.0154e-03, -1.5226e-03], device='cuda:0')),\n","             ('transformer_encoder.layers.1.norm2.weight',\n","              tensor([0.9571, 0.9472, 0.9351,  ..., 0.9022, 0.9429, 0.9100], device='cuda:0')),\n","             ('transformer_encoder.layers.1.norm2.bias',\n","              tensor([-0.0242, -0.0526, -0.0036,  ...,  0.0064,  0.0051, -0.0060],\n","                     device='cuda:0')),\n","             ('encoder.weight',\n","              tensor([[-0.0746,  0.0633,  0.0088,  ...,  0.0756, -0.0463,  0.0751],\n","                      [ 0.0533, -0.0299,  0.1114,  ..., -0.0760, -0.0476,  0.0124],\n","                      [ 0.0300, -0.0244,  0.0737,  ...,  0.0069, -0.0213,  0.0063],\n","                      ...,\n","                      [ 0.0136,  0.0051,  0.0437,  ...,  0.0466, -0.0726, -0.0225],\n","                      [-0.0423, -0.0435,  0.0770,  ...,  0.0376,  0.0129,  0.0790],\n","                      [ 0.0662,  0.0612, -0.0170,  ..., -0.0624,  0.0853,  0.0804]],\n","                     device='cuda:0')),\n","             ('decoder.weight',\n","              tensor([[-0.0120,  0.0228, -0.0139,  ...,  0.0140, -0.0772, -0.0333],\n","                      [ 0.0287, -0.0463, -0.0334,  ..., -0.0743, -0.0630,  0.0219],\n","                      [-0.5031,  0.3015, -0.7565,  ...,  0.0538,  0.0902, -0.1841],\n","                      ...,\n","                      [ 0.0278,  0.0489,  0.0969,  ...,  0.0585, -0.0651, -0.0569],\n","                      [ 0.0433, -0.0305,  0.0877,  ...,  0.0728, -0.0339,  0.0423],\n","                      [ 0.0250,  0.0548, -0.0722,  ..., -0.0321, -0.0618,  0.0050]],\n","                     device='cuda:0')),\n","             ('transformer_decoder.layers.0.self_attn.in_proj_weight',\n","              tensor([[-0.0084, -0.0049,  0.0194,  ...,  0.0132, -0.0169,  0.0157],\n","                      [-0.0028, -0.0157, -0.0017,  ...,  0.0137,  0.0099,  0.0052],\n","                      [ 0.0106, -0.0078,  0.0021,  ...,  0.0114,  0.0008,  0.0169],\n","                      ...,\n","                      [ 0.0186, -0.0051,  0.0036,  ..., -0.0156,  0.0211,  0.0023],\n","                      [ 0.0441, -0.0147,  0.0006,  ..., -0.0094,  0.0259, -0.0077],\n","                      [ 0.0041, -0.0016,  0.0009,  ...,  0.0055, -0.0171,  0.0092]],\n","                     device='cuda:0')),\n","             ('transformer_decoder.layers.0.self_attn.in_proj_bias',\n","              tensor([ 3.8248e-05, -6.8014e-04, -2.1797e-04,  ..., -6.8691e-04,\n","                      -1.5436e-03,  4.6648e-04], device='cuda:0')),\n","             ('transformer_decoder.layers.0.self_attn.out_proj.weight',\n","              tensor([[ 0.0021,  0.0197,  0.0019,  ..., -0.0003, -0.0065,  0.0028],\n","                      [-0.0127, -0.0055, -0.0141,  ..., -0.0156, -0.0170, -0.0021],\n","                      [ 0.0199,  0.0239, -0.0016,  ..., -0.0090,  0.0114,  0.0072],\n","                      ...,\n","                      [ 0.0132, -0.0081, -0.0036,  ..., -0.0011,  0.0173, -0.0111],\n","                      [ 0.0017,  0.0047, -0.0045,  ..., -0.0068, -0.0078, -0.0159],\n","                      [-0.0116,  0.0052, -0.0019,  ..., -0.0021,  0.0075,  0.0108]],\n","                     device='cuda:0')),\n","             ('transformer_decoder.layers.0.self_attn.out_proj.bias',\n","              tensor([ 0.0061, -0.0140,  0.1248,  ..., -0.0294,  0.0277, -0.0276],\n","                     device='cuda:0')),\n","             ('transformer_decoder.layers.0.multihead_attn.in_proj_weight',\n","              tensor([[-0.0118,  0.0055, -0.0149,  ..., -0.0087,  0.0088,  0.0009],\n","                      [-0.0095,  0.0082,  0.0002,  ...,  0.0148,  0.0153,  0.0027],\n","                      [ 0.0058, -0.0242,  0.0294,  ...,  0.0046,  0.0021,  0.0013],\n","                      ...,\n","                      [-0.0082,  0.0065, -0.0013,  ...,  0.0035, -0.0040,  0.0026],\n","                      [-0.0039,  0.0166, -0.0021,  ...,  0.0155,  0.0014, -0.0055],\n","                      [-0.0100,  0.0186,  0.0031,  ..., -0.0129,  0.0039, -0.0133]],\n","                     device='cuda:0')),\n","             ('transformer_decoder.layers.0.multihead_attn.in_proj_bias',\n","              tensor([-1.7952e-04, -9.2310e-05,  1.0155e-03,  ...,  3.6882e-03,\n","                       9.9778e-05, -6.9018e-04], device='cuda:0')),\n","             ('transformer_decoder.layers.0.multihead_attn.out_proj.weight',\n","              tensor([[-0.0051, -0.0040,  0.0002,  ...,  0.0141, -0.0046, -0.0069],\n","                      [-0.0052, -0.0011,  0.0136,  ...,  0.0104, -0.0189, -0.0119],\n","                      [-0.0176,  0.0179,  0.0116,  ...,  0.0289,  0.0300,  0.0030],\n","                      ...,\n","                      [-0.0093,  0.0047, -0.0070,  ...,  0.0108,  0.0145, -0.0131],\n","                      [ 0.0118,  0.0025,  0.0091,  ...,  0.0111, -0.0125, -0.0043],\n","                      [-0.0144,  0.0041, -0.0065,  ..., -0.0025, -0.0054, -0.0063]],\n","                     device='cuda:0')),\n","             ('transformer_decoder.layers.0.multihead_attn.out_proj.bias',\n","              tensor([ 0.0051,  0.0117,  0.1887,  ..., -0.0132,  0.0084, -0.0193],\n","                     device='cuda:0')),\n","             ('transformer_decoder.layers.0.linear1.weight',\n","              tensor([[ 5.4562e-03, -7.5575e-04, -1.9166e-02,  ..., -2.9582e-03,\n","                       -4.8558e-03, -2.4935e-03],\n","                      [-7.6150e-02,  7.7920e-02, -8.9237e-02,  ..., -2.4113e-02,\n","                        2.0344e-02, -1.2273e-02],\n","                      [-2.7347e-02,  3.2921e-02, -3.7663e-02,  ..., -1.0767e-03,\n","                        4.1532e-03,  3.4989e-04],\n","                      ...,\n","                      [ 3.0987e-05,  1.3765e-02, -2.3465e-02,  ...,  7.7148e-03,\n","                        3.8241e-03, -1.6139e-03],\n","                      [-4.6162e-02,  6.8385e-02,  3.1474e-02,  ..., -2.8576e-02,\n","                        2.5837e-02, -2.7369e-02],\n","                      [-5.7440e-02,  3.5298e-02, -8.3515e-02,  ..., -4.0166e-03,\n","                        1.7335e-02, -5.1407e-03]], device='cuda:0')),\n","             ('transformer_decoder.layers.0.linear1.bias',\n","              tensor([-1.2834e-02, -5.7397e-02, -3.9536e-04,  8.9257e-03, -3.5302e-02,\n","                      -1.1639e-03, -2.3986e-02, -1.7061e-02, -1.4003e-02, -2.6856e-02,\n","                      -1.6120e-02, -1.0032e-02, -4.3692e-03, -2.6664e-02, -3.4743e-02,\n","                       5.3192e-03, -8.7512e-03, -3.6682e-03, -1.6919e-02,  3.5100e-03,\n","                      -2.7473e-03, -1.2298e-02, -5.5460e-02, -2.2837e-02, -3.8743e-03,\n","                      -1.0982e-02, -7.8256e-03, -3.1356e-02, -1.3150e-02,  8.7019e-03,\n","                      -5.8687e-02, -1.6044e-02, -1.8968e-02, -3.8533e-02, -2.3551e-02,\n","                      -2.2580e-02, -3.4642e-02, -1.7902e-02, -2.6177e-02, -7.4182e-03,\n","                      -1.7924e-02, -2.3229e-02,  3.9831e-03,  7.3779e-03, -2.2333e-02,\n","                      -1.3168e-02, -1.5360e-02, -5.2767e-03, -6.8575e-02, -4.7457e-02,\n","                      -3.1526e-02, -1.9128e-02, -5.1077e-02, -1.5692e-02,  4.5014e-03,\n","                      -1.1974e-02, -4.5456e-03, -1.8914e-02, -1.0262e-02, -2.1799e-02,\n","                      -6.5911e-03, -1.0606e-02, -1.0270e-02, -1.5045e-02, -2.6890e-02,\n","                       1.2419e-03, -1.1982e-02, -2.1378e-02, -1.5518e-02, -7.9557e-03,\n","                      -4.6947e-03, -1.2207e-02, -1.5733e-02, -3.0381e-02, -2.0817e-02,\n","                      -4.8858e-03, -1.4210e-02, -1.0203e-02, -1.2585e-02,  6.7253e-03,\n","                       3.6239e-03, -3.8125e-03, -4.4139e-03,  5.5723e-03, -2.0793e-02,\n","                      -9.8458e-04, -1.2629e-02, -2.1431e-02, -1.7781e-02, -3.9965e-02,\n","                      -3.7827e-03, -1.3294e-02, -1.8307e-02, -1.5497e-02, -2.5258e-02,\n","                      -1.1459e-02, -5.1303e-03,  4.3324e-03, -2.7922e-03, -1.3667e-02,\n","                       3.3627e-03, -6.1020e-03, -6.6398e-03,  7.7998e-03, -9.4933e-03,\n","                       5.7055e-03,  4.2545e-04, -3.1111e-04, -7.7101e-03,  3.2431e-04,\n","                      -7.1479e-03, -3.4675e-02, -2.1135e-02, -1.4265e-02, -1.6134e-02,\n","                      -1.3478e-02,  1.8400e-03, -5.2169e-02, -9.8883e-03, -2.8074e-03,\n","                      -1.9432e-02, -1.0012e-02,  8.3227e-03,  2.9624e-03, -7.7538e-03,\n","                      -3.2690e-02, -1.9681e-02, -3.2881e-02, -2.4104e-02, -1.7578e-02,\n","                      -2.8544e-02, -2.0134e-02, -2.4691e-02, -7.6684e-03, -2.1765e-02,\n","                      -1.2460e-02, -1.1363e-02,  1.9720e-03,  5.9607e-03, -3.0660e-02,\n","                      -1.3601e-02, -1.8925e-02, -1.5672e-02,  4.5053e-03, -4.6998e-03,\n","                      -2.0835e-02, -2.2173e-02, -1.0518e-02, -1.1262e-02, -5.7135e-03,\n","                      -5.5943e-03, -9.8291e-03,  1.3495e-04, -1.6066e-02, -6.4092e-03,\n","                      -1.6678e-02,  6.1479e-04, -8.5672e-03, -1.2246e-02, -5.2890e-03,\n","                      -1.4846e-02, -1.6317e-02, -7.3575e-03, -6.7697e-03, -3.1343e-02,\n","                      -2.2718e-02, -1.4243e-03, -4.3487e-03, -2.3344e-03, -1.1648e-02,\n","                      -8.0872e-03, -1.1822e-02, -6.0867e-02, -1.5971e-02, -2.8302e-02,\n","                      -1.0323e-02, -6.3693e-03, -2.0453e-02, -3.4934e-02, -2.9777e-02,\n","                      -2.2851e-02, -3.2057e-02, -1.0183e-02, -2.1292e-02,  5.6563e-03,\n","                      -2.2219e-02, -1.0626e-02, -1.2170e-02, -7.2460e-03, -1.9961e-02,\n","                       4.1566e-03, -6.9243e-03, -1.6542e-02, -1.3689e-02, -1.6181e-02,\n","                      -2.0628e-02, -1.8501e-02, -1.8130e-02, -1.3202e-02, -4.3773e-03,\n","                      -1.9970e-02, -2.7016e-02,  2.2865e-03, -4.3307e-02,  7.2316e-03,\n","                      -1.8372e-02, -1.4295e-02, -2.8588e-02, -3.0216e-02, -2.9340e-02,\n","                      -2.0187e-03, -1.9116e-02, -2.3901e-02, -1.1490e-02, -1.7206e-02,\n","                      -1.2884e-02,  1.6508e-03, -1.1980e-02, -2.6433e-02, -6.3982e-03,\n","                       4.3148e-03, -2.3932e-02, -1.4271e-02, -1.1658e-02, -2.7433e-02,\n","                      -3.2478e-02, -1.9562e-02,  1.9393e-03,  7.9958e-03, -1.7623e-02,\n","                      -3.6236e-02, -3.0015e-02, -4.1556e-03, -2.8476e-02, -1.6348e-02,\n","                      -5.8822e-02, -1.5201e-02, -1.2493e-02, -8.6230e-03, -1.5642e-02,\n","                      -2.5633e-02, -2.5282e-02, -5.2274e-03, -1.8553e-02, -2.0963e-02,\n","                      -2.0139e-02,  5.4038e-03, -8.2971e-03, -3.1277e-02, -1.2440e-02,\n","                      -2.4322e-02,  1.7721e-03, -2.8412e-02, -3.5786e-02, -4.1377e-02,\n","                      -2.1933e-02,  5.4605e-03, -2.2174e-02, -2.5298e-02, -1.7653e-02,\n","                      -1.5133e-02,  1.9064e-03, -2.3761e-02, -1.5050e-02, -3.9819e-03,\n","                      -1.6443e-02, -1.2025e-02, -2.6588e-02,  7.7887e-03, -1.7393e-02,\n","                      -1.5197e-02, -1.2251e-02, -3.1276e-03, -2.2431e-02, -1.1365e-02,\n","                      -1.8696e-02, -1.6223e-02,  1.2308e-02, -5.5345e-02, -4.6240e-02,\n","                       5.8901e-03,  4.0528e-03, -3.2922e-02, -7.5623e-04, -1.4844e-02,\n","                      -1.4427e-02, -6.7029e-03, -2.9860e-03, -1.2414e-02,  1.1226e-02,\n","                      -1.6258e-02, -1.4957e-02, -1.4914e-02, -2.5125e-02, -3.3110e-02,\n","                      -1.9610e-02, -8.5041e-03,  2.0682e-03, -1.9516e-02, -2.7255e-03,\n","                      -4.0516e-02,  3.8976e-03, -1.3124e-02, -1.8850e-02, -3.6495e-02,\n","                      -1.4516e-02, -9.1905e-03, -3.3851e-02, -7.3849e-03, -3.7635e-03,\n","                      -2.7861e-02,  5.1499e-03, -1.6013e-02, -2.4425e-02, -1.0089e-02,\n","                      -5.0820e-03, -3.0386e-03, -1.7672e-02, -2.0395e-02, -1.6822e-02,\n","                      -4.2926e-04, -1.2127e-02, -1.7748e-02, -1.5124e-02, -1.0952e-02,\n","                      -2.8898e-02, -7.9419e-04, -2.6165e-02, -8.2607e-03, -1.6972e-02,\n","                      -2.5413e-02,  3.7168e-03, -1.0627e-02, -9.8103e-03, -1.6456e-02,\n","                      -8.6632e-03, -2.3422e-02, -1.6790e-03, -4.1787e-02, -8.4811e-03,\n","                      -2.3701e-02,  6.2211e-03, -1.3152e-02, -1.9626e-02, -6.3498e-04,\n","                      -7.1239e-03, -3.1660e-02, -7.7835e-03,  2.2571e-03, -3.0072e-02,\n","                      -3.1821e-02, -2.2109e-02, -1.0695e-02,  7.8984e-03, -1.4646e-02,\n","                      -1.4745e-02, -3.6667e-02, -8.4475e-05, -7.6488e-03, -2.3946e-02,\n","                      -4.6820e-03, -2.0769e-02, -2.3335e-02, -2.6789e-02, -2.4362e-02,\n","                      -4.4340e-02, -7.0242e-03, -3.5694e-04, -7.5705e-03, -1.8680e-02,\n","                      -2.7119e-02, -1.8005e-02, -1.4215e-02, -3.7152e-02, -1.6139e-02,\n","                      -1.8489e-02, -3.2644e-02, -4.6667e-03, -6.8999e-03, -5.7773e-03,\n","                      -5.1312e-02,  7.2889e-03, -1.6387e-02,  6.8110e-04, -1.2625e-03,\n","                      -1.0268e-02, -6.5431e-03, -3.3515e-02, -1.8210e-02, -2.9685e-02,\n","                      -1.3890e-02, -2.6374e-02, -1.5851e-02, -3.3910e-02, -2.1127e-02,\n","                      -4.4366e-03, -2.0971e-02, -1.7597e-02, -3.7554e-02, -5.5897e-02,\n","                       6.8706e-03, -1.5768e-02, -1.9337e-02, -1.8094e-02, -1.5131e-02,\n","                      -1.2304e-02, -3.1937e-02, -2.3715e-02, -1.0007e-02, -1.9125e-03,\n","                      -2.3383e-03, -3.9311e-03, -3.5782e-02, -2.2141e-02, -1.7584e-02,\n","                      -1.0924e-02, -4.4385e-02, -3.6874e-02, -9.6544e-03, -2.8583e-02,\n","                      -2.7797e-03, -1.0405e-02,  3.4830e-03, -4.7958e-03, -4.0400e-03,\n","                      -2.3737e-02, -3.6538e-02, -3.1508e-02, -2.1873e-02, -2.5069e-03,\n","                      -2.0035e-02, -3.8158e-02, -6.7695e-03, -1.6086e-02, -1.4688e-02,\n","                       6.8889e-03, -1.5792e-02, -5.7153e-02, -4.5685e-03,  1.3379e-03,\n","                      -1.5629e-02, -2.7989e-02,  6.6921e-03, -5.4760e-03,  3.0143e-03,\n","                      -2.4468e-02, -3.9734e-02, -2.1322e-02, -1.8173e-02, -3.7535e-02,\n","                      -2.0890e-02, -2.9615e-02, -2.7420e-02, -1.0442e-02, -1.5220e-02,\n","                       4.1637e-03,  1.2344e-03, -3.1750e-02, -2.2374e-02, -7.1733e-03,\n","                       5.1017e-03, -1.0016e-02, -2.7126e-04, -1.8982e-02, -1.8054e-03,\n","                      -1.8633e-02, -2.0509e-02, -1.9770e-02, -5.3760e-03,  1.1710e-02,\n","                      -1.8138e-02, -3.5750e-02, -8.5243e-03, -3.9440e-02, -4.9599e-03,\n","                      -6.5606e-03, -1.4115e-02, -1.9836e-03, -2.0032e-02, -1.6497e-02,\n","                      -1.5389e-02, -1.5439e-02, -3.7067e-02, -2.7570e-02, -4.5794e-02,\n","                      -1.5383e-02, -1.3379e-02,  2.4638e-03, -8.1134e-03, -4.8409e-02,\n","                      -2.3132e-04, -1.8759e-02, -1.4461e-02, -2.4002e-02, -6.4284e-03,\n","                      -6.6348e-02,  1.8832e-04, -1.6728e-02, -3.4890e-02, -3.8595e-02,\n","                      -3.5514e-02,  1.0241e-03,  1.7842e-03, -3.3095e-02, -3.5521e-02,\n","                      -4.5200e-03, -2.3720e-02, -3.4560e-02, -4.8407e-03, -5.2037e-03,\n","                      -5.0745e-02, -1.8119e-02], device='cuda:0')),\n","             ('transformer_decoder.layers.0.linear2.weight',\n","              tensor([[ 0.0101, -0.0128,  0.0383,  ...,  0.0041, -0.0464,  0.0070],\n","                      [-0.0341,  0.0044,  0.0160,  ..., -0.0135, -0.0167,  0.0540],\n","                      [-0.0306, -0.3076, -0.0330,  ..., -0.0805,  0.1647,  0.0783],\n","                      ...,\n","                      [-0.0212, -0.0091,  0.0268,  ...,  0.0429, -0.0165,  0.0219],\n","                      [-0.0241,  0.0417, -0.0381,  ..., -0.0302, -0.0245, -0.0401],\n","                      [ 0.0211, -0.0063,  0.0165,  ...,  0.0203,  0.0304, -0.0447]],\n","                     device='cuda:0')),\n","             ('transformer_decoder.layers.0.linear2.bias',\n","              tensor([-9.4554e-02,  6.7774e-02,  4.1773e-01,  ..., -9.6926e-05,\n","                       4.2718e-02, -3.1445e-02], device='cuda:0')),\n","             ('transformer_decoder.layers.0.norm1.weight',\n","              tensor([1.2155, 1.2800, 1.8558,  ..., 1.0390, 1.0354, 1.0095], device='cuda:0')),\n","             ('transformer_decoder.layers.0.norm1.bias',\n","              tensor([ 0.0114,  0.0003,  0.2311,  ..., -0.0205,  0.0072, -0.0162],\n","                     device='cuda:0')),\n","             ('transformer_decoder.layers.0.norm2.weight',\n","              tensor([1.0307, 0.9274, 0.2851,  ..., 1.0053, 1.0019, 0.9916], device='cuda:0')),\n","             ('transformer_decoder.layers.0.norm2.bias',\n","              tensor([ 0.0121,  0.0051,  0.7369,  ..., -0.0217,  0.0065, -0.0197],\n","                     device='cuda:0')),\n","             ('transformer_decoder.layers.0.norm3.weight',\n","              tensor([0.9314, 0.8336, 1.8289,  ..., 0.9875, 0.9750, 0.9989], device='cuda:0')),\n","             ('transformer_decoder.layers.0.norm3.bias',\n","              tensor([-0.0422,  0.0819, -1.6704,  ..., -0.0232,  0.0284, -0.0153],\n","                     device='cuda:0')),\n","             ('transformer_decoder.layers.1.self_attn.in_proj_weight',\n","              tensor([[-0.0078, -0.0017, -0.0068,  ...,  0.0125, -0.0166,  0.0135],\n","                      [-0.0051, -0.0170,  0.0015,  ...,  0.0160,  0.0088,  0.0077],\n","                      [ 0.0143, -0.0123, -0.0015,  ...,  0.0115, -0.0010,  0.0188],\n","                      ...,\n","                      [-0.0102, -0.0019,  0.0046,  ..., -0.0143,  0.0154,  0.0044],\n","                      [-0.0082, -0.0099,  0.0106,  ..., -0.0039,  0.0130, -0.0082],\n","                      [ 0.0205,  0.0076, -0.0136,  ...,  0.0015, -0.0169,  0.0066]],\n","                     device='cuda:0')),\n","             ('transformer_decoder.layers.1.self_attn.in_proj_bias',\n","              tensor([-2.8525e-03,  2.6112e-03,  1.6321e-03,  ...,  9.4126e-05,\n","                       1.9880e-03, -2.7580e-03], device='cuda:0')),\n","             ('transformer_decoder.layers.1.self_attn.out_proj.weight',\n","              tensor([[-1.9715e-03,  1.4431e-02,  9.4528e-04,  ...,  3.4251e-03,\n","                       -6.3562e-03,  4.9213e-03],\n","                      [-4.8655e-03,  4.2138e-03, -1.6914e-03,  ..., -9.3400e-03,\n","                        3.2019e-04, -6.7190e-03],\n","                      [-5.9091e-03,  1.0521e-03,  4.1526e-03,  ..., -1.6704e-02,\n","                       -1.8030e-03,  1.0140e-02],\n","                      ...,\n","                      [ 1.3277e-02, -8.2957e-03, -5.1764e-03,  ..., -3.4728e-03,\n","                        1.0893e-02, -1.2406e-02],\n","                      [ 1.9317e-03,  1.0840e-02, -1.6402e-03,  ..., -5.3366e-03,\n","                       -4.9168e-03, -1.7219e-02],\n","                      [-1.3298e-02,  2.7345e-03, -1.0156e-03,  ...,  1.2871e-05,\n","                        7.5359e-03,  1.1837e-02]], device='cuda:0')),\n","             ('transformer_decoder.layers.1.self_attn.out_proj.bias',\n","              tensor([-0.0080,  0.0072, -0.2314,  ..., -0.0059, -0.0023, -0.0046],\n","                     device='cuda:0')),\n","             ('transformer_decoder.layers.1.multihead_attn.in_proj_weight',\n","              tensor([[-0.0099,  0.0041, -0.0329,  ..., -0.0071,  0.0084,  0.0012],\n","                      [-0.0066,  0.0035,  0.0234,  ...,  0.0161,  0.0151,  0.0011],\n","                      [ 0.0004, -0.0166,  0.0070,  ...,  0.0037,  0.0039,  0.0014],\n","                      ...,\n","                      [-0.0130,  0.0036, -0.0013,  ...,  0.0036, -0.0075,  0.0008],\n","                      [-0.0046,  0.0097, -0.0034,  ...,  0.0167, -0.0006, -0.0093],\n","                      [-0.0114,  0.0179,  0.0081,  ..., -0.0149,  0.0053, -0.0080]],\n","                     device='cuda:0')),\n","             ('transformer_decoder.layers.1.multihead_attn.in_proj_bias',\n","              tensor([ 0.0018,  0.0003, -0.0005,  ..., -0.0002, -0.0023,  0.0087],\n","                     device='cuda:0')),\n","             ('transformer_decoder.layers.1.multihead_attn.out_proj.weight',\n","              tensor([[ 0.0037, -0.0128, -0.0102,  ...,  0.0136, -0.0024, -0.0062],\n","                      [-0.0035, -0.0101,  0.0109,  ...,  0.0047, -0.0122, -0.0145],\n","                      [-0.0035, -0.0002,  0.0098,  ...,  0.0055,  0.0068,  0.0132],\n","                      ...,\n","                      [-0.0062,  0.0059, -0.0047,  ...,  0.0087,  0.0113, -0.0131],\n","                      [ 0.0113,  0.0048,  0.0074,  ...,  0.0109, -0.0136, -0.0037],\n","                      [-0.0146,  0.0019, -0.0074,  ..., -0.0003, -0.0059, -0.0037]],\n","                     device='cuda:0')),\n","             ('transformer_decoder.layers.1.multihead_attn.out_proj.bias',\n","              tensor([-0.0177,  0.0080, -0.0584,  ..., -0.0095, -0.0059, -0.0152],\n","                     device='cuda:0')),\n","             ('transformer_decoder.layers.1.linear1.weight',\n","              tensor([[ 1.0926e-02, -2.0497e-02,  6.3645e-02,  ...,  7.0806e-03,\n","                       -6.7656e-03,  3.9690e-03],\n","                      [-1.2015e-02,  1.4032e-02, -4.6023e-01,  ..., -1.6579e-02,\n","                       -5.7145e-03, -8.2319e-03],\n","                      [-5.0604e-03,  1.0929e-02,  6.4292e-02,  ...,  1.4970e-02,\n","                       -1.7651e-03,  3.0469e-03],\n","                      ...,\n","                      [ 1.3980e-02,  1.8255e-02, -5.1758e-03,  ...,  4.1421e-03,\n","                        9.9875e-03, -2.7983e-04],\n","                      [ 1.5260e-02,  1.5203e-03, -6.1092e-02,  ..., -1.2964e-02,\n","                        1.2208e-02,  4.6230e-03],\n","                      [-6.5243e-03, -2.4565e-02, -6.2318e-02,  ...,  1.5031e-02,\n","                        6.7635e-03,  1.2422e-02]], device='cuda:0')),\n","             ('transformer_decoder.layers.1.linear1.bias',\n","              tensor([-0.0200, -0.0332, -0.0106,  0.0016, -0.0190, -0.0432, -0.0042, -0.0022,\n","                      -0.0209, -0.0116, -0.0025, -0.0150, -0.0121, -0.0288, -0.0671, -0.0025,\n","                      -0.0102, -0.0098, -0.0367, -0.0339,  0.0015, -0.0223, -0.0428, -0.0545,\n","                      -0.0813, -0.0074, -0.0161, -0.0193, -0.0077,  0.0068, -0.0196, -0.0221,\n","                      -0.0203, -0.0127, -0.0326, -0.0129, -0.0245, -0.0207, -0.0234,  0.0057,\n","                      -0.0428, -0.0216,  0.0012,  0.0003, -0.0315, -0.0014, -0.0226, -0.0057,\n","                      -0.0320, -0.0152, -0.0038, -0.0234, -0.0661,  0.0034, -0.0079, -0.0106,\n","                       0.0019, -0.0141, -0.0392, -0.0039, -0.0065, -0.0039, -0.0122, -0.0034,\n","                      -0.0182, -0.0175, -0.0032, -0.0276, -0.0363, -0.0134, -0.0066, -0.0337,\n","                      -0.0196, -0.0208, -0.0083, -0.0450, -0.0249, -0.0183, -0.0200, -0.0009,\n","                      -0.0560, -0.0027, -0.0007,  0.0030, -0.0222, -0.0013, -0.0075, -0.0014,\n","                      -0.0237, -0.0218,  0.0049, -0.0245, -0.0288, -0.0214, -0.0042,  0.0014,\n","                       0.0010,  0.0005, -0.0142, -0.0212, -0.0052, -0.0081, -0.0394,  0.0056,\n","                      -0.0038,  0.0025,  0.0010, -0.0178, -0.0023, -0.0037, -0.0070, -0.0205,\n","                      -0.0177, -0.0186, -0.0025, -0.0121, -0.0007, -0.0392, -0.0283, -0.0069,\n","                      -0.0125, -0.0135, -0.0041, -0.0099, -0.0243, -0.0285, -0.0248, -0.0128,\n","                      -0.0368, -0.0219, -0.0575, -0.0115, -0.0230, -0.0128, -0.0757, -0.0227,\n","                      -0.0112, -0.0055, -0.0016, -0.0193, -0.0177, -0.0130, -0.0209, -0.0075,\n","                      -0.0013, -0.0231, -0.0088, -0.0095, -0.0053, -0.0131, -0.0236,  0.0011,\n","                      -0.0034, -0.0247, -0.0133, -0.0314, -0.0371, -0.0179, -0.0196, -0.0177,\n","                      -0.0082, -0.0156, -0.0097, -0.0068, -0.0432, -0.0483, -0.0056, -0.0075,\n","                      -0.0092, -0.0324, -0.0173, -0.0097, -0.0104, -0.0335, -0.0254, -0.0095,\n","                      -0.1075, -0.0530, -0.0556, -0.0157, -0.0559, -0.0259, -0.0092, -0.0118,\n","                      -0.0050, -0.0048, -0.0173, -0.0159,  0.0019, -0.0259, -0.0018, -0.0073,\n","                      -0.0156,  0.0021, -0.0223, -0.0164, -0.0306,  0.0040, -0.0125,  0.0056,\n","                      -0.0739, -0.0198, -0.0107, -0.0221,  0.0073, -0.0212, -0.0087, -0.0756,\n","                      -0.0175, -0.0271, -0.0067, -0.0048, -0.0122, -0.0203, -0.0185, -0.0136,\n","                       0.0027, -0.0141, -0.0111, -0.0246, -0.0078, -0.0190, -0.0609, -0.0236,\n","                      -0.0180, -0.0152, -0.0137, -0.0118,  0.0043, -0.0296, -0.0249, -0.0104,\n","                      -0.0069, -0.0120, -0.0314, -0.0360, -0.0071, -0.0164, -0.0035, -0.0322,\n","                      -0.0235, -0.0119, -0.0063, -0.0254, -0.0545, -0.0296, -0.0003, -0.0017,\n","                      -0.0001, -0.0102, -0.0251,  0.0019, -0.0259, -0.0158, -0.0308, -0.0191,\n","                      -0.0157, -0.0262, -0.0149, -0.0140, -0.0175, -0.0008, -0.0362, -0.0086,\n","                      -0.0158, -0.0320, -0.0066, -0.0132,  0.0034, -0.0330, -0.0143, -0.0223,\n","                      -0.0195, -0.0212, -0.0122, -0.0069, -0.0174, -0.0047, -0.0730, -0.0339,\n","                       0.0066,  0.0022, -0.0253, -0.0080, -0.0101, -0.0123, -0.0102, -0.0126,\n","                      -0.0105,  0.0053, -0.0074, -0.0616, -0.0121, -0.0306, -0.0713, -0.0175,\n","                      -0.0358, -0.0006, -0.0320,  0.0021, -0.0267,  0.0018, -0.0232, -0.0135,\n","                      -0.0418, -0.0051, -0.0234, -0.0341, -0.0110, -0.0110, -0.0170, -0.0530,\n","                      -0.0248, -0.0149, -0.0008, -0.0077, -0.0009, -0.0229, -0.0224, -0.0105,\n","                       0.0044, -0.0157, -0.0222, -0.0272, -0.0139, -0.0177, -0.0785, -0.0231,\n","                      -0.0470, -0.0465, -0.0309, -0.0027, -0.0179, -0.0228,  0.0017, -0.0115,\n","                      -0.0760, -0.0159, -0.0310, -0.0037, -0.0215,  0.0015, -0.0348, -0.0030,\n","                      -0.0008, -0.0170, -0.0160, -0.0281, -0.0089, -0.0376, -0.0440, -0.0775,\n","                      -0.0138, -0.0324, -0.0099, -0.0261, -0.0198,  0.0014, -0.0138, -0.0266,\n","                      -0.0022, -0.0240, -0.0235, -0.0512, -0.0166, -0.0193, -0.0112, -0.0090,\n","                      -0.0429, -0.0172,  0.0062, -0.0262, -0.0169, -0.0319, -0.0314, -0.0185,\n","                      -0.0085, -0.0414, -0.0160, -0.0362, -0.0339, -0.0018, -0.0154, -0.0138,\n","                      -0.0297,  0.0043, -0.0627, -0.0178, -0.0092, -0.0104, -0.0181, -0.0256,\n","                      -0.0147, -0.0257, -0.0320, -0.0071, -0.0196, -0.0257, -0.0253, -0.0171,\n","                       0.0066, -0.0183, -0.0230, -0.0176, -0.0128, -0.0006, -0.0277, -0.0216,\n","                      -0.0060, -0.0057,  0.0094,  0.0033, -0.0550, -0.0126, -0.0113, -0.0024,\n","                      -0.0353, -0.0218, -0.0177, -0.0295, -0.0051, -0.0424,  0.0023, -0.0173,\n","                       0.0008, -0.0207, -0.0461, -0.0789, -0.0257,  0.0017, -0.0205, -0.0577,\n","                      -0.0089, -0.0105, -0.0324,  0.0039, -0.0185, -0.0430, -0.0134,  0.0030,\n","                      -0.0263, -0.0081, -0.0018,  0.0008,  0.0002, -0.0379, -0.0249, -0.0176,\n","                      -0.0413, -0.0271,  0.0017, -0.0260, -0.0073, -0.0183, -0.0177,  0.0062,\n","                      -0.0036, -0.0291, -0.0180, -0.0100,  0.0053, -0.0077, -0.0056, -0.0146,\n","                      -0.0007, -0.0160, -0.0237, -0.0245, -0.0050, -0.0039, -0.0229, -0.0391,\n","                      -0.1002, -0.0145, -0.0128, -0.0280, -0.0142, -0.0060, -0.0226, -0.0230,\n","                      -0.0181, -0.0093, -0.0222, -0.0228, -0.0388, -0.0155, -0.0635,  0.0047,\n","                      -0.0207, -0.0260,  0.0068, -0.0138, -0.0197, -0.0199, -0.0116, -0.0129,\n","                      -0.0027, -0.0080, -0.0564, -0.0248, -0.0686, -0.0061, -0.0091, -0.0153,\n","                      -0.0252, -0.0129, -0.0246, -0.0171,  0.0047, -0.0206, -0.0194, -0.0242],\n","                     device='cuda:0')),\n","             ('transformer_decoder.layers.1.linear2.weight',\n","              tensor([[ 0.0016, -0.1337,  0.0238,  ..., -0.0040, -0.0199,  0.0003],\n","                      [-0.0331,  0.0097,  0.0314,  ..., -0.0064, -0.0069,  0.0223],\n","                      [ 0.0009, -0.0342,  0.0280,  ..., -0.0166,  0.0207,  0.0527],\n","                      ...,\n","                      [-0.0235,  0.0007,  0.0222,  ...,  0.0424, -0.0313,  0.0157],\n","                      [-0.0258,  0.0437, -0.0386,  ..., -0.0302, -0.0313, -0.0446],\n","                      [ 0.0196,  0.0018,  0.0163,  ...,  0.0179,  0.0332, -0.0411]],\n","                     device='cuda:0')),\n","             ('transformer_decoder.layers.1.linear2.bias',\n","              tensor([-0.0680, -0.0066,  0.1142,  ...,  0.0358,  0.0072, -0.0182],\n","                     device='cuda:0')),\n","             ('transformer_decoder.layers.1.norm1.weight',\n","              tensor([1.0162, 1.0521, 2.5780,  ..., 1.0025, 1.0059, 1.0028], device='cuda:0')),\n","             ('transformer_decoder.layers.1.norm1.bias',\n","              tensor([-0.0183,  0.0048, -1.1648,  ..., -0.0080, -0.0063, -0.0144],\n","                     device='cuda:0')),\n","             ('transformer_decoder.layers.1.norm2.weight',\n","              tensor([1.0113, 1.0338, 0.9659,  ..., 1.0013, 1.0040, 0.9993], device='cuda:0')),\n","             ('transformer_decoder.layers.1.norm2.bias',\n","              tensor([-0.0294,  0.0077, -0.9413,  ..., -0.0121, -0.0077, -0.0228],\n","                     device='cuda:0')),\n","             ('transformer_decoder.layers.1.norm3.weight',\n","              tensor([ 1.0055,  0.8858, -1.9969,  ...,  0.9499,  0.9598,  0.8974],\n","                     device='cuda:0')),\n","             ('transformer_decoder.layers.1.norm3.bias',\n","              tensor([-0.0681, -0.2344,  6.1952,  ..., -0.1365, -0.1396, -0.2300],\n","                     device='cuda:0'))])"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"vfg3UxxTlb2z","executionInfo":{"status":"ok","timestamp":1605760727269,"user_tz":-540,"elapsed":24082,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}}},"source":["model.eval()\n","with torch.no_grad():\n","  word, pred = [], []\n","  for i, batch in enumerate(val_iter):\n","    src = batch.src\n","    trg = batch.trg\n","    src_mask = model.generate_square_subsequent_mask(src.shape[0]).to(device)\n","    output = model(src, trg)\n","    for i in range(train_batch_size):\n","      _, topi = output.data.topk(1)\n","      \n","      for j in range(topi.size()[1]):\n","        for k in range(topi.size()[0]):\n","          tmp = SRC.vocab.itos[topi[:, j][k]]\n","          if tmp == \"<eos>\":\n","            break\n","          word.append(tmp)\n","        #print(word)\n","        pred.append(word)\n","        word = []\n","      #print([SRC.vocab.itos[j.item()] for j in topi])"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"FBZa649k2P36","executionInfo":{"status":"ok","timestamp":1605760746471,"user_tz":-540,"elapsed":581,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}}},"source":["def gen_sentence(sentence, src_field, model, batch_size):\n","  model.eval()\n","  in_str, out_str, pred, tmp = [], [], [], []\n","  length = len(sentence)\n","\n","  with torch.no_grad():\n","    for _, batch in enumerate(sentence):\n","      src = batch.src\n","      trg = batch.trg\n","      # src_mask = model.generate_square_subsequent_mask(src.shape[0]).to(device)\n","      output = model(src, trg)\n","          \n","      for j in range(min(length, batch_size)):\n","        _, topi = output.data.topk(1)\n","        #print(topi.size())\n","        _, topi_s = output.data.topk(2) \n","        for k in range(topi.size()[1]):\n","          \"\"\"\n","          if topi[:, k][0] == src_field.vocab.stoi[\"<eos>\"]:\n","            for m in range(topi_s.size()[0]):\n","              for l in range(topi_s.size()[1]):\n","                topi[m][l][0] = topi_s[m][l][1]\n","          \"\"\"\n","          for i in range(topi.size()[0]):\n","            word = src_field.vocab.itos[topi[:, k][i]]\n","            if word == \"<eos>\":\n","              break\n","            tmp.append(word)\n","          pred.append(tmp)\n","          #print(tmp)\n","          tmp = []\n","        in_str.append([src_field.vocab.itos[i.item()] for i in src[:,j] if src_field.vocab.itos[i.item()] != \"<eos>\"])\n","        out_str.append([src_field.vocab.itos[i.item()] for i in trg[:,j] if src_field.vocab.itos[i.item()] != \"<eos>\"])\n","      \n","  return in_str, out_str, pred"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"1RIlFI5G5JzZ","executionInfo":{"status":"ok","timestamp":1605760758863,"user_tz":-540,"elapsed":12456,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}}},"source":["# 中間発表時にはテストデータは用いない\n","test_in, test_out, test_pred = [],[],[]\n","test_in, test_out, test_pred = gen_sentence(test_iter, SRC, model, test_batch_size)"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"BG29LUs-IeWT","executionInfo":{"status":"ok","timestamp":1605760771729,"user_tz":-540,"elapsed":24131,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}}},"source":["val_in, val_out, val_pred = [],[],[]\n","val_in, val_out, val_pred = gen_sentence(val_iter, SRC, model, eval_batch_size)"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"r2Us-WpbIewl","executionInfo":{"status":"ok","timestamp":1605761212675,"user_tz":-540,"elapsed":464635,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}}},"source":["train_in, train_out, train_pred = [],[],[]\n","train_in, train_out, train_pred = gen_sentence(train_iter, SRC, model, train_batch_size)"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"mlA-NqUEIjck","executionInfo":{"status":"ok","timestamp":1605761212684,"user_tz":-540,"elapsed":464302,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}}},"source":["import pandas as pd"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"wBlexgq5IlSW","executionInfo":{"status":"ok","timestamp":1605761212685,"user_tz":-540,"elapsed":463844,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}}},"source":["def convert_list_to_df(in_list, out_list, pred_list):\n","  row = []\n","  for i in range(len(in_list)):\n","    batch_input = in_list[i]\n","    batch_output = out_list[i]\n","    batch_pred = pred_list[i]\n","    input = [j for j in batch_input if j != \"<pad>\" and j != \"<sos>\" and j != \"<eos>\" and j != \"<unk>\"]\n","    output = [j for j in batch_output if j != \"<pad>\" and j != \"<sos>\" and j != \"<eos>\" and j != \"<unk>\"]\n","    predict = [j for j in batch_pred if j != \"<pad>\" and j != \"<sos>\" and j != \"<eos>\" and j != \"<unk>\"]\n","    input_str = \"\".join(input)\n","    output_str =\"\".join(output)\n","    predict_str = \"\".join(predict)\n","    row.append([input_str, output_str, predict_str])\n","\n","  df = pd.DataFrame(row, columns=[\"input\",\"answer\",\"predict\"])\n","  df = df.sort_values('input')\n","  return df"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"6pVoCwc_Inol","executionInfo":{"status":"ok","timestamp":1605761212686,"user_tz":-540,"elapsed":463264,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}}},"source":["train_df = convert_list_to_df(train_in, train_out, train_pred)\n","val_df = convert_list_to_df(val_in, val_out, val_pred)\n","test_df = convert_list_to_df(test_in, test_out, test_pred)"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"ptcsBPKZi-0t","executionInfo":{"status":"ok","timestamp":1605761212686,"user_tz":-540,"elapsed":462648,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}}},"source":["df_s = pd.concat([train_df, test_df]).sort_values('input')"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Yd2nXK5jJKT","colab":{"base_uri":"https://localhost:8080/","height":359},"executionInfo":{"status":"ok","timestamp":1605761213069,"user_tz":-540,"elapsed":462437,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}},"outputId":"056741de-0f2b-44f5-84c0-bfa88b465a3a"},"source":["df_s.head(10)"],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>input</th>\n","      <th>answer</th>\n","      <th>predict</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>14143</th>\n","      <td>11時半頃</td>\n","      <td>いらっしゃったうーん</td>\n","      <td>うーん</td>\n","    </tr>\n","    <tr>\n","      <th>18359</th>\n","      <td>11時半頃</td>\n","      <td>十一時半に</td>\n","      <td>わ</td>\n","    </tr>\n","    <tr>\n","      <th>19914</th>\n","      <td>15分ぐらいまで</td>\n","      <td>あっ</td>\n","      <td>あー</td>\n","    </tr>\n","    <tr>\n","      <th>3813</th>\n","      <td>15分ぐらいまで</td>\n","      <td>十五分</td>\n","      <td>あそうですねあー</td>\n","    </tr>\n","    <tr>\n","      <th>19074</th>\n","      <td>15分ぐらいまで駅に</td>\n","      <td>15分はい</td>\n","      <td>あーそうなんですね</td>\n","    </tr>\n","    <tr>\n","      <th>1702</th>\n","      <td>15分ぐらいまで駅に</td>\n","      <td>あはい</td>\n","      <td>あはははそうなんですね</td>\n","    </tr>\n","    <tr>\n","      <th>6629</th>\n","      <td>15分ぐらいまで駅に着くまでにかかりました</td>\n","      <td>はいだったんですねありがとう</td>\n","      <td>あーうーんうん</td>\n","    </tr>\n","    <tr>\n","      <th>15389</th>\n","      <td>15分ぐらいまで駅に着くまでにかかりました</td>\n","      <td>はいうーんうん</td>\n","      <td>へーですねうんうんねーうーん</td>\n","    </tr>\n","    <tr>\n","      <th>8474</th>\n","      <td>15分ぐらいまで駅に着くまでにかかりました</td>\n","      <td>あそうですか</td>\n","      <td>そうですねーうんええうんうんなんですね</td>\n","    </tr>\n","    <tr>\n","      <th>4196</th>\n","      <td>15分ぐらいまで駅に着くまでにかかりました</td>\n","      <td>ええあそうですねそうだったんですね</td>\n","      <td>そうですねーそうなんですか</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                       input             answer              predict\n","14143                  11時半頃         いらっしゃったうーん                  うーん\n","18359                  11時半頃              十一時半に                    わ\n","19914               15分ぐらいまで                 あっ                   あー\n","3813                15分ぐらいまで                十五分             あそうですねあー\n","19074             15分ぐらいまで駅に              15分はい            あーそうなんですね\n","1702              15分ぐらいまで駅に                あはい          あはははそうなんですね\n","6629   15分ぐらいまで駅に着くまでにかかりました     はいだったんですねありがとう              あーうーんうん\n","15389  15分ぐらいまで駅に着くまでにかかりました            はいうーんうん       へーですねうんうんねーうーん\n","8474   15分ぐらいまで駅に着くまでにかかりました             あそうですか  そうですねーうんええうんうんなんですね\n","4196   15分ぐらいまで駅に着くまでにかかりました  ええあそうですねそうだったんですね        そうですねーそうなんですか"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"8870OnPUjK13","executionInfo":{"status":"ok","timestamp":1605761287570,"user_tz":-540,"elapsed":591,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}}},"source":["df_s.to_csv(\"/content/dirve/My Drive/Colab Notebooks/csv/result_transformer.csv\")"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"mDs4JDh-qAf0","executionInfo":{"status":"aborted","timestamp":1605760633997,"user_tz":-540,"elapsed":11571216,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}}},"source":[""],"execution_count":null,"outputs":[]}]}