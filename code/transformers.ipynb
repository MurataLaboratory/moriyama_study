{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pjiEJUtUM34r"
   },
   "source": [
    "[code of transformer from pytorch](https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/transformer.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 700,
     "status": "ok",
     "timestamp": 1606363932574,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "7Z8LGX2980EX",
    "outputId": "ed32041c-bd86-4977-c788-4da123b28562"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print('hello world')\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 20062,
     "status": "ok",
     "timestamp": 1606363951957,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "wij1JxmL9GPC"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer, TransformerDecoder, TransformerDecoderLayer\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.encoder = nn.Embedding(ntoken, ninp)\n",
    "        # self.decoder = nn.Embedding(ntoken, ninp)\n",
    "        self.ninp = ninp\n",
    "        decoder_layers = TransformerDecoderLayer(ninp, nhead, nhid, dropout)\n",
    "        self.transformer_decoder = TransformerDecoder(decoder_layers, nlayers)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        # self.decoder.bias.data.zero_()\n",
    "        # self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        trg_mask = model.generate_square_subsequent_mask(trg.size()[0]).to(device)\n",
    "        # 分散表現に変換\n",
    "        src = self.encoder(src)\n",
    "        trg = self.encoder(trg)\n",
    "        # 位置情報を入れる\n",
    "        src = self.pos_encoder(src)\n",
    "        trg = self.pos_encoder(trg)\n",
    "        # モデルにデータを入れる\n",
    "        output = self.transformer_encoder(src)\n",
    "        # デコーダにエンコーダの出力を入れる（ここがおかしい）\n",
    "        output = self.transformer_decoder(trg, output,tgt_mask = trg_mask)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 20057,
     "status": "ok",
     "timestamp": 1606363951958,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "KdR2x3-I9Mwj"
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40137,
     "status": "ok",
     "timestamp": 1606363972044,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "GIlU3Pq_9PTH",
    "outputId": "842ee239-7409-4617-debb-d57ff8c058ae"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: janome in c:\\users\\keisc\\anaconda3\\envs\\study\\lib\\site-packages (0.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install janome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 40130,
     "status": "ok",
     "timestamp": 1606363972045,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "NaLzDlDO9WVO"
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchtext'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-3f170945a6c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjanome\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mjanome\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchtext'"
     ]
    }
   ],
   "source": [
    "import janome\n",
    "from janome.tokenizer import Tokenizer\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 40126,
     "status": "ok",
     "timestamp": 1606363972045,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "CSloFuafEOB2"
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'random' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-305413a2cd90>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mSEED\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1234\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSEED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSEED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSEED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'random' is not defined"
     ]
    }
   ],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 40501,
     "status": "ok",
     "timestamp": 1606363972426,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "Yw4rgSs_9YNf"
   },
   "outputs": [],
   "source": [
    "j_t = Tokenizer()\n",
    "def tokenizer(text): \n",
    "    return [tok for tok in j_t.tokenize(text, wakati=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 40497,
     "status": "ok",
     "timestamp": 1606363972427,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "F57J80U-zcsa"
   },
   "outputs": [],
   "source": [
    "# 重複のないデータセットか重複のあるデータセットを選ぶ\n",
    "# flagがTrueの時重複のないデータを返す\n",
    "def choose_dataset(flag = False):\n",
    "  if flag:\n",
    "    train, val, test = data.TabularDataset.splits(\n",
    "        path=\"../data/\", train='one_train.tsv',\n",
    "        validation='one_val.tsv', test='one_test.tsv', format='tsv',\n",
    "        fields=[('SRC', SRC), ('TRG', SRC)])\n",
    "    filename = \"../csv/one_result_transformer.csv\"\n",
    "  else:\n",
    "    train, val, test = data.TabularDataset.splits(\n",
    "        path=\"../data/\", train='train.tsv',\n",
    "        validation='val.tsv', test='test.tsv', format='tsv',\n",
    "        fields=[('SRC', SRC), ('TRG', SRC)])\n",
    "    filename = \"../csv/result_transformer.csv\"\n",
    "  \n",
    "  return train, val, test, filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 52374,
     "status": "ok",
     "timestamp": 1606363984310,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "z_W9CJc_9bl5"
   },
   "outputs": [],
   "source": [
    "SRC = data.Field(sequential=True, \n",
    "                 tokenize=tokenizer,\n",
    "                 init_token='<sos>',\n",
    "                 eos_token='<eos>', \n",
    "                 lower=True)\n",
    "train, val, test, filename = choose_dataset(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 52370,
     "status": "ok",
     "timestamp": 1606363984311,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "OC130WaB9ixV"
   },
   "outputs": [],
   "source": [
    "SRC.build_vocab(train, min_freq=1)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_batch_size = 16\n",
    "test_batch_size = 32\n",
    "eval_batch_size = 32\n",
    "train_iter, val_iter, test_iter = data.BucketIterator.splits((train, val, test), sort = False,  batch_sizes = (train_batch_size,eval_batch_size, test_batch_size), device= device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 65467,
     "status": "ok",
     "timestamp": 1606363997413,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "c3Khrj4y95-F"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 148.00 MiB (GPU 0; 4.00 GiB total capacity; 2.88 GiB already allocated; 64.61 MiB free; 2.97 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-8a3fdc8b5eeb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnhead\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;31m# the number of heads in the multiheadattention models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdropout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.3\u001b[0m \u001b[1;31m# the dropout value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTransformerModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mntokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0memsize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnhead\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnhid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnlayers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\school\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mto\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    441\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 443\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_backward_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\school\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    201\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\school\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    201\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\school\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    201\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\school\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    201\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\school\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    223\u001b[0m                 \u001b[1;31m# `with torch.no_grad():`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m                     \u001b[0mparam_applied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    226\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\school\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    439\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mconvert_to_format\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 148.00 MiB (GPU 0; 4.00 GiB total capacity; 2.88 GiB already allocated; 64.61 MiB free; 2.97 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "ntokens = len(SRC.vocab.stoi) # the size of vocabulary\n",
    "emsize = len(SRC.vocab.stoi) # embedding dimension\n",
    "nhid = 512 # the dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 2 # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 2 # the number of heads in the multiheadattention models\n",
    "dropout = 0.3 # the dropout value\n",
    "model = TransformerModel(ntokens, emsize, nhead, nhid, nlayers, dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 65463,
     "status": "ok",
     "timestamp": 1606363997417,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "i4RvbEEFv7Bs",
    "outputId": "535004d9-8fce-4d15-dc2c-79231b3a67ca"
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 65454,
     "status": "ok",
     "timestamp": 1606363997417,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "xKasgK4M98rJ"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=SRC.vocab.stoi[\"<pad>\"])\n",
    "lr = 5 # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
    "\n",
    "import time\n",
    "def train(iterator):\n",
    "    model.train() # Turn on the train mode\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    for i, batch in enumerate(iterator):\n",
    "        #print(i)\n",
    "        src = batch.SRC\n",
    "        trg = batch.TRG\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg)\n",
    "        output = output[:].view(-1, output.shape[-1])\n",
    "        trg = trg[:].view(-1)\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += float(loss.item())\n",
    "    \n",
    "    return total_loss / len(iterator)\n",
    "        \n",
    "\n",
    "def evaluate(eval_model, data_source):\n",
    "    eval_model.eval() # Turn on the evaluation mode\n",
    "    total_loss = 0.\n",
    "    with torch.no_grad():\n",
    "      for i, batch in enumerate(data_source):\n",
    "        data = batch.SRC\n",
    "        targets = batch.TRG\n",
    "        #src_mask = model.generate_square_subsequent_mask(data.shape[0]).to(device)\n",
    "        output = eval_model(data, targets)\n",
    "        output_flat = output[:].view(-1, output.shape[-1])\n",
    "        targets = targets[:].view(-1)\n",
    "        total_loss += len(data) * criterion(output_flat, targets).item()\n",
    "    return total_loss / (len(data_source) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2187876,
     "status": "ok",
     "timestamp": 1606366119845,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "BH0OwGrB-N81",
    "outputId": "2d26f4ff-7c74-4b74-91f4-4a181b1864c3"
   },
   "outputs": [],
   "source": [
    "best_val_loss = float(\"inf\")\n",
    "epochs = 50 # The number of epochs\n",
    "best_model = None\n",
    "model.init_weights()\n",
    "train_loss_list, eval_loss_list = [], []\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    t_loss = train(train_iter)\n",
    "    val_loss = evaluate(model, val_iter)\n",
    "    print('-' * 89)\n",
    "    print('| epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n",
    "          .format(epoch, (time.time() - epoch_start_time), val_loss))\n",
    "    \n",
    "    train_loss_list.append(t_loss)\n",
    "    eval_loss_list.append(val_loss)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = model\n",
    "\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "y = list(range(epochs))\n",
    "train_loss = plt.plot(y, train_loss_list)\n",
    "valid_loss = plt.plot(y, eval_loss_list)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"train loss\")\n",
    "plt.legend((train_loss[0], valid_loss[0]), (\"train loss\", \"valid loss\"),)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2191534,
     "status": "ok",
     "timestamp": 1606366123511,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "6andFXy1or7x",
    "outputId": "548bf596-ca5d-474c-c475-50a39ad81415"
   },
   "outputs": [],
   "source": [
    "test_loss = evaluate(best_model, test_iter)\n",
    "print('=' * 89)\n",
    "print('| End of training | test loss {:5.2f} | test ppl {:8.2f}'.format(\n",
    "    test_loss, math.exp(test_loss)))\n",
    "print('=' * 89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2249534,
     "status": "ok",
     "timestamp": 1606366181517,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "vOLgVcFE_n15"
   },
   "outputs": [],
   "source": [
    "torch.save(best_model.state_dict(), \"/content/dirve/My Drive/Colab Notebooks/model/transformer.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2251842,
     "status": "ok",
     "timestamp": 1606366183831,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "m9G-YLtje1TX",
    "outputId": "4ffd8efb-8e71-42ec-ad19-fec8bad4f45a"
   },
   "outputs": [],
   "source": [
    "model.state_dict(torch.load(\"/content/dirve/My Drive/Colab Notebooks/model/transformer.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2251837,
     "status": "ok",
     "timestamp": 1606366183832,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "Up3JnDcPuqAb"
   },
   "outputs": [],
   "source": [
    "def gen_sentence(sentence, src_field, trg_field, model, batch_size):\n",
    "  model.eval()\n",
    "  in_str, out_str, pred, tmp = [], [], [], []\n",
    "  length = len(sentence)\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for _, batch in enumerate(sentence):\n",
    "      src = batch.SRC\n",
    "      trg = batch.TRG\n",
    "      output = model(src, trg)\n",
    "          \n",
    "      for j in range(min(length, batch_size)):\n",
    "        _, topi = output.data.topk(1)\n",
    "        _, topi_s = output.data.topk(2) \n",
    "        for k in range(topi.size()[1]):\n",
    "          if topi[:, k][0] == trg_field.vocab.stoi[\"<eos>\"]:\n",
    "            for m in range(topi_s.size()[0]):\n",
    "              for l in range(topi_s.size()[1]):\n",
    "                topi[m][l][0] = topi_s[m][l][1]\n",
    "          for i in range(topi.size()[0]):\n",
    "            if trg_field.vocab.itos[topi[:, k][i]] == \"<eos>\":\n",
    "              break\n",
    "            tmp.append(trg_field.vocab.itos[topi[:, k][i]])\n",
    "          pred.append(tmp)\n",
    "          tmp = []\n",
    "        #print(src.size())\n",
    "        in_str.append([src_field.vocab.itos[i.item()] for i in src[:,j] if src_field.vocab.itos[i.item()] != \"<eos>\"])\n",
    "        out_str.append([trg_field.vocab.itos[i.item()] for i in trg[:,j] if trg_field.vocab.itos[i.item()] != \"<eos>\"])\n",
    "      \n",
    "  return in_str, out_str, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2372756,
     "status": "ok",
     "timestamp": 1606366304757,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "aoroAe8Uuq6A"
   },
   "outputs": [],
   "source": [
    "# 中間発表時にはテストデータは用いない\n",
    "test_in, test_out, test_pred = [],[],[]\n",
    "test_in, test_out, test_pred = gen_sentence(test_iter, SRC, SRC, best_model, test_batch_size)\n",
    "val_in, val_out, val_pred = [],[],[]\n",
    "val_in, val_out, val_pred = gen_sentence(val_iter, SRC, SRC, model, eval_batch_size)\n",
    "train_in, train_out, train_pred = [],[],[]\n",
    "train_in, train_out, train_pred = gen_sentence(train_iter, SRC, SRC, model, train_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2372755,
     "status": "ok",
     "timestamp": 1606366304762,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "mlA-NqUEIjck"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2372742,
     "status": "ok",
     "timestamp": 1606366304763,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "wBlexgq5IlSW"
   },
   "outputs": [],
   "source": [
    "def convert_list_to_df(in_list, out_list, pred_list):\n",
    "  row = []\n",
    "  for i in range(len(in_list)):\n",
    "    batch_input = in_list[i]\n",
    "    batch_output = out_list[i]\n",
    "    batch_pred = pred_list[i]\n",
    "    input = [j for j in batch_input if j != \"<pad>\" and j != \"<sos>\" and j != \"<eos>\" and j != \"<unk>\"]\n",
    "    output = [j for j in batch_output if j != \"<pad>\" and j != \"<sos>\" and j != \"<eos>\" and j != \"<unk>\"]\n",
    "    predict = [j for j in batch_pred if j != \"<pad>\" and j != \"<sos>\" and j != \"<eos>\" and j != \"<unk>\"]\n",
    "    input_str = \"\".join(input)\n",
    "    output_str =\"\".join(output)\n",
    "    predict_str = \"\".join(predict)\n",
    "    row.append([input_str, output_str, predict_str])\n",
    "\n",
    "  df = pd.DataFrame(row, columns=[\"input\",\"answer\",\"predict\"])\n",
    "  df = df.sort_values('input')\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2372735,
     "status": "ok",
     "timestamp": 1606366304764,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "6pVoCwc_Inol"
   },
   "outputs": [],
   "source": [
    "train_df = convert_list_to_df(train_in, train_out, train_pred)\n",
    "val_df = convert_list_to_df(val_in, val_out, val_pred)\n",
    "test_df = convert_list_to_df(test_in, test_out, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2372725,
     "status": "ok",
     "timestamp": 1606366304765,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "ptcsBPKZi-0t"
   },
   "outputs": [],
   "source": [
    "df_s = pd.concat([train_df, test_df]).sort_values('input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 2372718,
     "status": "ok",
     "timestamp": 1606366304766,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "-Yd2nXK5jJKT",
    "outputId": "2602353e-fe95-43fd-c457-696cf7f8e2bc"
   },
   "outputs": [],
   "source": [
    "df_s.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2373212,
     "status": "ok",
     "timestamp": 1606366305280,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "8870OnPUjK13"
   },
   "outputs": [],
   "source": [
    "df_s.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2373204,
     "status": "ok",
     "timestamp": 1606366305281,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "mDs4JDh-qAf0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMlPD4HsxK8IOTDlshiwOms",
   "collapsed_sections": [],
   "name": "transformers.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}