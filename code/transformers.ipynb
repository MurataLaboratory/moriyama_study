{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"transformers.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMlPD4HsxK8IOTDlshiwOms"},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"pjiEJUtUM34r"},"source":["[code of transformer from pytorch](https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/transformer.py)\n","\n"]},{"cell_type":"code","metadata":{"id":"7Z8LGX2980EX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606363932574,"user_tz":-540,"elapsed":700,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}},"outputId":"ed32041c-bd86-4977-c788-4da123b28562"},"source":["print('hello world')\n","import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""],"execution_count":1,"outputs":[{"output_type":"stream","text":["hello world\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kM_JvL1h9DDi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606363948530,"user_tz":-540,"elapsed":16643,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}},"outputId":"bc7cad6d-35c7-4d9b-e1b5-fc5503b17359"},"source":["from google.colab import drive\n","drive.mount('/content/dirve', force_remount=True)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/dirve\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wij1JxmL9GPC","executionInfo":{"status":"ok","timestamp":1606363951957,"user_tz":-540,"elapsed":20062,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}}},"source":["import math\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.nn import TransformerEncoder, TransformerEncoderLayer, TransformerDecoder, TransformerDecoderLayer\n","\n","class TransformerModel(nn.Module):\n","\n","    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n","        super(TransformerModel, self).__init__()\n","        self.model_type = 'Transformer'\n","        self.pos_encoder = PositionalEncoding(ninp, dropout)\n","        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n","        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n","        self.encoder = nn.Embedding(ntoken, ninp)\n","        self.decoder = nn.Embedding(ntoken, ninp)\n","        self.ninp = ninp\n","        decoder_layers = TransformerDecoderLayer(ninp, nhead, nhid, dropout)\n","        self.transformer_decoder = TransformerDecoder(decoder_layers, nlayers)\n","\n","        self.init_weights()\n","\n","    def generate_square_subsequent_mask(self, sz):\n","        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n","        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n","        return mask\n","\n","    def init_weights(self):\n","        initrange = 0.1\n","        self.encoder.weight.data.uniform_(-initrange, initrange)\n","        # self.decoder.bias.data.zero_()\n","        self.decoder.weight.data.uniform_(-initrange, initrange)\n","\n","    def forward(self, src, trg):\n","        trg_mask = model.generate_square_subsequent_mask(trg.size()[0]).to(device)\n","        # 分散表現に変換\n","        src = self.encoder(src)\n","        trg = self.decoder(trg)\n","        # 位置情報を入れる\n","        src = self.pos_encoder(src)\n","        trg = self.pos_encoder(trg)\n","        # モデルにデータを入れる\n","        output = self.transformer_encoder(src)\n","        # デコーダにエンコーダの出力を入れる（ここがおかしい）\n","        output = self.transformer_decoder(trg, output,tgt_mask = trg_mask)\n","        return output"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"KdR2x3-I9Mwj","executionInfo":{"status":"ok","timestamp":1606363951958,"user_tz":-540,"elapsed":20057,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}}},"source":["class PositionalEncoding(nn.Module):\n","\n","    def __init__(self, d_model, dropout=0.1, max_len=5000):\n","        super(PositionalEncoding, self).__init__()\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","        pe = torch.zeros(max_len, d_model)\n","        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","        pe = pe.unsqueeze(0).transpose(0, 1)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        x = x + self.pe[:x.size(0), :]\n","        return self.dropout(x)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"GIlU3Pq_9PTH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606363972044,"user_tz":-540,"elapsed":40137,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}},"outputId":"842ee239-7409-4617-debb-d57ff8c058ae"},"source":["!pip install janome"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Collecting janome\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/63/98858cbead27df7536c7e300c169da0999e9704d02220dc6700b804eeff0/Janome-0.4.1-py2.py3-none-any.whl (19.7MB)\n","\u001b[K     |████████████████████████████████| 19.7MB 11.7MB/s \n","\u001b[?25hInstalling collected packages: janome\n","Successfully installed janome-0.4.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NaLzDlDO9WVO","executionInfo":{"status":"ok","timestamp":1606363972045,"user_tz":-540,"elapsed":40130,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}}},"source":["import janome\n","from janome.tokenizer import Tokenizer\n","from torchtext import data\n","from torchtext import datasets\n","import random\n","import numpy as np"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"CSloFuafEOB2","executionInfo":{"status":"ok","timestamp":1606363972045,"user_tz":-540,"elapsed":40126,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}}},"source":["SEED = 1234\n","\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yw4rgSs_9YNf","executionInfo":{"status":"ok","timestamp":1606363972426,"user_tz":-540,"elapsed":40501,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}}},"source":["j_t = Tokenizer()\n","def tokenizer(text): \n","    return [tok for tok in j_t.tokenize(text, wakati=True)]"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"F57J80U-zcsa","executionInfo":{"status":"ok","timestamp":1606363972427,"user_tz":-540,"elapsed":40497,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}}},"source":["# 重複のないデータセットか重複のあるデータセットを選ぶ\n","# flagがTrueの時重複のないデータを返す\n","def choose_dataset(flag = False):\n","  if flag:\n","    train, val, test = data.TabularDataset.splits(\n","        path=\"/content/dirve/My Drive/Colab Notebooks/data/\", train='one_train.tsv',\n","        validation='one_val.tsv', test='one_test.tsv', format='tsv',\n","        fields=[('SRC', SRC), ('TRG', SRC)])\n","    filename = \"/content/dirve/My Drive/Colab Notebooks/csv/one_result_transformer.csv\"\n","  else:\n","    train, val, test = data.TabularDataset.splits(\n","        path=\"/content/dirve/My Drive/Colab Notebooks/data/\", train='train.tsv',\n","        validation='val.tsv', test='test.tsv', format='tsv',\n","        fields=[('SRC', SRC), ('TRG', SRC)])\n","    filename = \"/content/dirve/My Drive/Colab Notebooks/csv/result_transformer.csv\"\n","  \n","  return train, val, test, filename"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"z_W9CJc_9bl5","executionInfo":{"status":"ok","timestamp":1606363984310,"user_tz":-540,"elapsed":52374,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}}},"source":["SRC = data.Field(sequential=True, \n","                 tokenize=tokenizer,\n","                 init_token='<sos>',\n","                 eos_token='<eos>', \n","                 lower=True)\n","train, val, test, filename = choose_dataset(True)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"OC130WaB9ixV","executionInfo":{"status":"ok","timestamp":1606363984311,"user_tz":-540,"elapsed":52370,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}}},"source":["SRC.build_vocab(train, min_freq=1)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","train_batch_size = 100\n","test_batch_size = 100\n","eval_batch_size = 100\n","train_iter, val_iter, test_iter = data.BucketIterator.splits((train, val, test), sort = False,  batch_sizes = (train_batch_size,eval_batch_size, test_batch_size), device= device)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"c3Khrj4y95-F","executionInfo":{"status":"ok","timestamp":1606363997413,"user_tz":-540,"elapsed":65467,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}}},"source":["ntokens = len(SRC.vocab.stoi) # the size of vocabulary\n","emsize = len(SRC.vocab.stoi) # embedding dimension\n","nhid = 512 # the dimension of the feedforward network model in nn.TransformerEncoder\n","nlayers = 2 # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n","nhead = 2 # the number of heads in the multiheadattention models\n","dropout = 0.3 # the dropout value\n","model = TransformerModel(ntokens, emsize, nhead, nhid, nlayers, dropout).to(device)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"i4RvbEEFv7Bs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606363997417,"user_tz":-540,"elapsed":65463,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}},"outputId":"535004d9-8fce-4d15-dc2c-79231b3a67ca"},"source":["model"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TransformerModel(\n","  (pos_encoder): PositionalEncoding(\n","    (dropout): Dropout(p=0.3, inplace=False)\n","  )\n","  (transformer_encoder): TransformerEncoder(\n","    (layers): ModuleList(\n","      (0): TransformerEncoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (out_proj): _LinearWithBias(in_features=3576, out_features=3576, bias=True)\n","        )\n","        (linear1): Linear(in_features=3576, out_features=512, bias=True)\n","        (dropout): Dropout(p=0.3, inplace=False)\n","        (linear2): Linear(in_features=512, out_features=3576, bias=True)\n","        (norm1): LayerNorm((3576,), eps=1e-05, elementwise_affine=True)\n","        (norm2): LayerNorm((3576,), eps=1e-05, elementwise_affine=True)\n","        (dropout1): Dropout(p=0.3, inplace=False)\n","        (dropout2): Dropout(p=0.3, inplace=False)\n","      )\n","      (1): TransformerEncoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (out_proj): _LinearWithBias(in_features=3576, out_features=3576, bias=True)\n","        )\n","        (linear1): Linear(in_features=3576, out_features=512, bias=True)\n","        (dropout): Dropout(p=0.3, inplace=False)\n","        (linear2): Linear(in_features=512, out_features=3576, bias=True)\n","        (norm1): LayerNorm((3576,), eps=1e-05, elementwise_affine=True)\n","        (norm2): LayerNorm((3576,), eps=1e-05, elementwise_affine=True)\n","        (dropout1): Dropout(p=0.3, inplace=False)\n","        (dropout2): Dropout(p=0.3, inplace=False)\n","      )\n","    )\n","  )\n","  (encoder): Embedding(3576, 3576)\n","  (decoder): Embedding(3576, 3576)\n","  (transformer_decoder): TransformerDecoder(\n","    (layers): ModuleList(\n","      (0): TransformerDecoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (out_proj): _LinearWithBias(in_features=3576, out_features=3576, bias=True)\n","        )\n","        (multihead_attn): MultiheadAttention(\n","          (out_proj): _LinearWithBias(in_features=3576, out_features=3576, bias=True)\n","        )\n","        (linear1): Linear(in_features=3576, out_features=512, bias=True)\n","        (dropout): Dropout(p=0.3, inplace=False)\n","        (linear2): Linear(in_features=512, out_features=3576, bias=True)\n","        (norm1): LayerNorm((3576,), eps=1e-05, elementwise_affine=True)\n","        (norm2): LayerNorm((3576,), eps=1e-05, elementwise_affine=True)\n","        (norm3): LayerNorm((3576,), eps=1e-05, elementwise_affine=True)\n","        (dropout1): Dropout(p=0.3, inplace=False)\n","        (dropout2): Dropout(p=0.3, inplace=False)\n","        (dropout3): Dropout(p=0.3, inplace=False)\n","      )\n","      (1): TransformerDecoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (out_proj): _LinearWithBias(in_features=3576, out_features=3576, bias=True)\n","        )\n","        (multihead_attn): MultiheadAttention(\n","          (out_proj): _LinearWithBias(in_features=3576, out_features=3576, bias=True)\n","        )\n","        (linear1): Linear(in_features=3576, out_features=512, bias=True)\n","        (dropout): Dropout(p=0.3, inplace=False)\n","        (linear2): Linear(in_features=512, out_features=3576, bias=True)\n","        (norm1): LayerNorm((3576,), eps=1e-05, elementwise_affine=True)\n","        (norm2): LayerNorm((3576,), eps=1e-05, elementwise_affine=True)\n","        (norm3): LayerNorm((3576,), eps=1e-05, elementwise_affine=True)\n","        (dropout1): Dropout(p=0.3, inplace=False)\n","        (dropout2): Dropout(p=0.3, inplace=False)\n","        (dropout3): Dropout(p=0.3, inplace=False)\n","      )\n","    )\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"xKasgK4M98rJ","executionInfo":{"status":"ok","timestamp":1606363997417,"user_tz":-540,"elapsed":65454,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}}},"source":["criterion = nn.CrossEntropyLoss(ignore_index=SRC.vocab.stoi[\"<pad>\"])\n","lr = 5 # learning rate\n","optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n","\n","import time\n","def train(iterator):\n","    model.train() # Turn on the train mode\n","    total_loss = 0.\n","    start_time = time.time()\n","    for i, batch in enumerate(iterator):\n","        #print(i)\n","        src = batch.SRC\n","        trg = batch.TRG\n","        optimizer.zero_grad()\n","        output = model(src, trg)\n","        output = output[:].view(-1, output.shape[-1])\n","        trg = trg[:].view(-1)\n","        loss = criterion(output, trg)\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","        \n","\n","def evaluate(eval_model, data_source):\n","    eval_model.eval() # Turn on the evaluation mode\n","    total_loss = 0.\n","    with torch.no_grad():\n","      for i, batch in enumerate(data_source):\n","        data = batch.SRC\n","        targets = batch.TRG\n","        #src_mask = model.generate_square_subsequent_mask(data.shape[0]).to(device)\n","        output = eval_model(data, targets)\n","        output_flat = output[:].view(-1, output.shape[-1])\n","        targets = targets[:].view(-1)\n","        total_loss += len(data) * criterion(output_flat, targets).item()\n","    return total_loss / (len(data_source) - 1)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"BH0OwGrB-N81","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606366119845,"user_tz":-540,"elapsed":2187876,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}},"outputId":"2d26f4ff-7c74-4b74-91f4-4a181b1864c3"},"source":["best_val_loss = float(\"inf\")\n","epochs = 20 # The number of epochs\n","best_model = None\n","model.init_weights()\n","\n","for epoch in range(1, epochs + 1):\n","    epoch_start_time = time.time()\n","    train(train_iter)\n","    val_loss = evaluate(model, val_iter)\n","    print('-' * 89)\n","    print('| epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n","          .format(epoch, (time.time() - epoch_start_time), val_loss))\n","\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        best_model = model\n","\n","    scheduler.step()"],"execution_count":15,"outputs":[{"output_type":"stream","text":["-----------------------------------------------------------------------------------------\n","| epoch   1 | time: 105.66s | valid loss 250.16 | \n","-----------------------------------------------------------------------------------------\n","| epoch   2 | time: 107.18s | valid loss 226.09 | \n","-----------------------------------------------------------------------------------------\n","| epoch   3 | time: 105.48s | valid loss 188.38 | \n","-----------------------------------------------------------------------------------------\n","| epoch   4 | time: 105.55s | valid loss 179.95 | \n","-----------------------------------------------------------------------------------------\n","| epoch   5 | time: 106.39s | valid loss 163.43 | \n","-----------------------------------------------------------------------------------------\n","| epoch   6 | time: 105.01s | valid loss 175.09 | \n","-----------------------------------------------------------------------------------------\n","| epoch   7 | time: 106.13s | valid loss 171.70 | \n","-----------------------------------------------------------------------------------------\n","| epoch   8 | time: 107.19s | valid loss 160.00 | \n","-----------------------------------------------------------------------------------------\n","| epoch   9 | time: 105.97s | valid loss 151.82 | \n","-----------------------------------------------------------------------------------------\n","| epoch  10 | time: 105.60s | valid loss 144.03 | \n","-----------------------------------------------------------------------------------------\n","| epoch  11 | time: 105.29s | valid loss 139.96 | \n","-----------------------------------------------------------------------------------------\n","| epoch  12 | time: 105.76s | valid loss 165.27 | \n","-----------------------------------------------------------------------------------------\n","| epoch  13 | time: 105.26s | valid loss 138.94 | \n","-----------------------------------------------------------------------------------------\n","| epoch  14 | time: 106.59s | valid loss 141.63 | \n","-----------------------------------------------------------------------------------------\n","| epoch  15 | time: 105.85s | valid loss 135.91 | \n","-----------------------------------------------------------------------------------------\n","| epoch  16 | time: 106.54s | valid loss 137.33 | \n","-----------------------------------------------------------------------------------------\n","| epoch  17 | time: 106.67s | valid loss 145.82 | \n","-----------------------------------------------------------------------------------------\n","| epoch  18 | time: 106.23s | valid loss 133.92 | \n","-----------------------------------------------------------------------------------------\n","| epoch  19 | time: 106.57s | valid loss 119.03 | \n","-----------------------------------------------------------------------------------------\n","| epoch  20 | time: 107.42s | valid loss 117.86 | \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6andFXy1or7x","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606366123511,"user_tz":-540,"elapsed":2191534,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}},"outputId":"548bf596-ca5d-474c-c475-50a39ad81415"},"source":["test_loss = evaluate(best_model, test_iter)\n","print('=' * 89)\n","print('| End of training | test loss {:5.2f} | test ppl {:8.2f}'.format(\n","    test_loss, math.exp(test_loss)))\n","print('=' * 89)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["=========================================================================================\n","| End of training | test loss 150.13 | test ppl 158135333334821791427179906743753761436459132050814525796503257088.00\n","=========================================================================================\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vOLgVcFE_n15","executionInfo":{"status":"ok","timestamp":1606366181517,"user_tz":-540,"elapsed":2249534,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}}},"source":["torch.save(best_model.state_dict(), \"/content/dirve/My Drive/Colab Notebooks/model/transformer.pth\")"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"m9G-YLtje1TX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606366183831,"user_tz":-540,"elapsed":2251842,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}},"outputId":"4ffd8efb-8e71-42ec-ad19-fec8bad4f45a"},"source":["model.state_dict(torch.load(\"/content/dirve/My Drive/Colab Notebooks/model/transformer.pth\"))"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["OrderedDict([('pos_encoder.pe',\n","              tensor([[[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n","                         0.0000e+00,  1.0000e+00]],\n","              \n","                      [[ 8.4147e-01,  5.4030e-01,  8.3868e-01,  ...,  1.0000e+00,\n","                         1.0052e-04,  1.0000e+00]],\n","              \n","                      [[ 9.0930e-01, -4.1615e-01,  9.1353e-01,  ...,  1.0000e+00,\n","                         2.0103e-04,  1.0000e+00]],\n","              \n","                      ...,\n","              \n","                      [[ 9.5625e-01, -2.9254e-01,  9.7021e-01,  ...,  8.7524e-01,\n","                         4.8143e-01,  8.7649e-01]],\n","              \n","                      [[ 2.7050e-01, -9.6272e-01,  7.3173e-01,  ...,  8.7519e-01,\n","                         4.8151e-01,  8.7644e-01]],\n","              \n","                      [[-6.6395e-01, -7.4778e-01, -1.7338e-01,  ...,  8.7514e-01,\n","                         4.8160e-01,  8.7639e-01]]], device='cuda:0')),\n","             ('transformer_encoder.layers.0.self_attn.in_proj_weight',\n","              tensor([[-0.0194, -0.0203,  0.0091,  ..., -0.0108, -0.0063, -0.0024],\n","                      [-0.0143, -0.0177,  0.0138,  ...,  0.0165, -0.0104, -0.0037],\n","                      [ 0.0152, -0.0181, -0.0139,  ..., -0.0173,  0.0060, -0.0033],\n","                      ...,\n","                      [-0.0089,  0.0147, -0.0061,  ...,  0.0138,  0.0131, -0.0040],\n","                      [-0.0128,  0.0172, -0.0194,  ..., -0.0188,  0.0109, -0.0092],\n","                      [-0.0171, -0.0004,  0.0148,  ...,  0.0199,  0.0197, -0.0153]],\n","                     device='cuda:0')),\n","             ('transformer_encoder.layers.0.self_attn.in_proj_bias',\n","              tensor([-1.3723e-04, -2.6244e-06, -1.6637e-07,  ..., -9.4169e-05,\n","                      -9.6902e-05, -2.0098e-04], device='cuda:0')),\n","             ('transformer_encoder.layers.0.self_attn.out_proj.weight',\n","              tensor([[-0.0156, -0.0032, -0.0081,  ...,  0.0086, -0.0016,  0.0090],\n","                      [ 0.0128, -0.0075, -0.0145,  ...,  0.0121,  0.0068,  0.0128],\n","                      [ 0.0123,  0.0107,  0.0015,  ...,  0.0051,  0.0104, -0.0068],\n","                      ...,\n","                      [-0.0022,  0.0054,  0.0065,  ..., -0.0008,  0.0072,  0.0067],\n","                      [ 0.0077,  0.0126,  0.0012,  ...,  0.0121,  0.0004, -0.0152],\n","                      [-0.0165, -0.0098, -0.0160,  ..., -0.0119, -0.0099, -0.0084]],\n","                     device='cuda:0')),\n","             ('transformer_encoder.layers.0.self_attn.out_proj.bias',\n","              tensor([-2.7336e-04,  4.5990e-04,  1.0319e-03,  ..., -1.8569e-03,\n","                      -9.4225e-05, -1.1646e-03], device='cuda:0')),\n","             ('transformer_encoder.layers.0.linear1.weight',\n","              tensor([[-4.7768e-03,  1.5403e-02, -1.0193e-02,  ...,  1.3305e-02,\n","                        1.4693e-02, -8.5852e-04],\n","                      [-1.7198e-03, -3.7831e-03, -1.4551e-03,  ..., -3.0804e-03,\n","                        2.5376e-03,  1.5471e-02],\n","                      [-5.5782e-03,  6.7618e-03, -1.6042e-02,  ...,  3.1019e-03,\n","                        9.1638e-03, -5.1879e-05],\n","                      ...,\n","                      [-1.5008e-03, -3.0114e-04, -5.7851e-03,  ...,  1.3661e-02,\n","                       -1.5950e-02, -6.6250e-03],\n","                      [ 9.4470e-03,  1.0804e-02,  4.3608e-03,  ...,  7.9669e-03,\n","                       -1.0723e-02, -2.1554e-03],\n","                      [ 3.0062e-03,  8.4439e-03,  1.3851e-02,  ..., -1.5531e-02,\n","                        1.1820e-03, -2.0992e-03]], device='cuda:0')),\n","             ('transformer_encoder.layers.0.linear1.bias',\n","              tensor([ 1.5158e-03,  3.4313e-03, -1.0982e-02, -1.4418e-02,  2.9995e-04,\n","                       1.5574e-02, -1.7044e-02,  1.0965e-02, -1.1997e-02,  2.0038e-03,\n","                       1.4617e-02, -1.0838e-02,  1.1094e-03, -1.3565e-02, -1.2652e-02,\n","                       1.0238e-02,  7.8251e-03,  4.2570e-03, -9.2842e-03,  1.2308e-04,\n","                       2.3355e-04, -1.3139e-02,  1.0436e-02, -2.6350e-03,  1.1934e-02,\n","                      -1.4819e-02, -1.1833e-02, -6.5489e-03, -4.2524e-03,  5.2519e-03,\n","                      -1.2675e-02, -6.5301e-03,  1.0531e-02,  2.9622e-03, -1.7357e-02,\n","                      -1.6561e-02, -8.4072e-03, -3.9884e-03, -1.4741e-03,  5.1555e-03,\n","                       1.4346e-02, -5.4920e-03, -8.9961e-03,  1.0956e-02,  5.1254e-04,\n","                      -1.8856e-02,  1.3347e-02, -1.4365e-02,  1.8474e-03,  1.0343e-04,\n","                      -4.9854e-03,  4.9130e-03,  2.7871e-03, -1.1007e-02,  1.2423e-02,\n","                       1.4066e-02, -2.5172e-04, -1.2236e-02, -3.2520e-03, -1.4617e-02,\n","                      -2.4856e-03,  8.2223e-03, -7.0825e-03, -1.3403e-02, -2.6813e-04,\n","                      -1.4048e-03, -9.7523e-03, -7.3715e-03,  8.7213e-03,  1.5648e-02,\n","                       7.6013e-03,  5.6696e-03,  3.3173e-03,  1.4879e-02,  1.3965e-04,\n","                       1.2310e-02,  1.1834e-02,  7.1839e-03,  4.9712e-03, -4.0801e-03,\n","                      -1.6593e-02, -1.0160e-02,  7.9180e-03, -1.3465e-02, -1.0700e-02,\n","                      -1.4843e-02,  1.0424e-02,  2.1711e-03,  4.2798e-03,  1.4497e-02,\n","                       4.8947e-03,  1.0724e-02, -1.5776e-02,  4.8532e-04,  8.7266e-03,\n","                      -1.1574e-03,  6.4606e-03, -1.1525e-02, -2.3649e-03, -6.0004e-03,\n","                       7.8327e-03,  4.9214e-03,  7.8227e-03, -5.1440e-03, -5.3365e-03,\n","                       1.0913e-02,  1.2190e-02, -3.0554e-03,  1.4593e-03,  5.1395e-03,\n","                       7.0011e-03, -2.0798e-03,  1.4619e-02, -1.0033e-02, -1.4223e-02,\n","                      -5.0341e-03,  5.7504e-03, -3.6813e-03, -1.2414e-02, -8.5623e-03,\n","                      -1.1843e-02,  3.5950e-03,  9.2439e-03,  1.1379e-02,  1.3118e-02,\n","                      -2.3144e-03, -1.3960e-02, -1.7846e-03, -1.2076e-02,  1.1845e-03,\n","                      -6.9487e-03, -6.5469e-03, -1.9894e-03, -7.8659e-04, -1.0679e-02,\n","                      -6.3063e-04, -8.5268e-03, -1.3467e-02,  7.8426e-03,  1.0560e-02,\n","                      -4.7247e-03,  1.2293e-02,  4.0151e-03, -1.1173e-03,  7.9121e-03,\n","                       7.9596e-03, -1.0882e-03,  4.2870e-03,  6.3100e-03, -2.1385e-03,\n","                       4.5401e-03,  1.3938e-02,  1.1183e-02,  4.4590e-04, -6.6137e-03,\n","                       4.5318e-03,  6.2402e-03, -7.3026e-03,  8.7222e-03, -1.1410e-03,\n","                      -8.3314e-03,  2.1143e-03, -9.9727e-03,  7.9602e-03, -7.1484e-03,\n","                      -3.1628e-04,  4.0613e-03,  1.5481e-02, -7.6912e-03, -1.4323e-02,\n","                      -1.4092e-02,  1.6299e-02, -1.6148e-03,  1.4747e-02, -7.0910e-03,\n","                       7.1901e-03,  3.3935e-03, -1.2585e-03,  3.7951e-03,  1.6409e-03,\n","                       2.0596e-03, -1.1908e-02,  3.9058e-03,  5.2941e-03, -7.1275e-03,\n","                       8.1090e-03, -1.3052e-02,  3.1788e-04, -4.5613e-03,  1.5865e-02,\n","                      -1.3866e-03,  1.3014e-02, -1.0879e-02,  1.0224e-02, -1.8879e-03,\n","                      -1.0924e-02, -1.6074e-02, -9.7659e-04, -1.6157e-03, -1.6356e-02,\n","                       1.1615e-03, -3.6154e-03, -8.1291e-03,  1.1898e-02, -9.7823e-03,\n","                      -1.0024e-02, -6.0344e-03,  1.9306e-03, -9.7457e-03, -1.3195e-02,\n","                      -1.5254e-02, -8.4559e-04, -1.5969e-02, -4.8366e-03,  1.5798e-02,\n","                      -7.1331e-03, -6.5000e-03,  1.0847e-02, -1.2514e-02, -1.1265e-02,\n","                       1.1296e-03, -1.6220e-02, -8.4092e-03, -2.5093e-03, -9.7706e-04,\n","                      -1.2999e-02,  1.3186e-02, -1.3180e-02, -1.4528e-02, -3.8659e-03,\n","                      -1.9391e-03, -1.2675e-02, -1.6316e-03, -1.0416e-02,  8.9393e-03,\n","                       2.3303e-03, -9.0341e-03, -1.4094e-03, -1.6652e-02,  1.1707e-02,\n","                      -1.7902e-02,  1.5711e-02,  4.4820e-03,  2.7119e-03,  1.5912e-02,\n","                      -2.5371e-03,  1.5060e-02, -1.1279e-02,  3.0781e-03,  1.1731e-02,\n","                       4.0408e-03,  5.6053e-03,  1.5746e-02,  8.2670e-03,  1.7040e-03,\n","                       6.6135e-05, -6.4468e-03,  2.5912e-03,  4.1338e-03, -4.9398e-03,\n","                      -1.0436e-02, -1.0037e-02,  4.3260e-03, -7.2424e-03,  1.5701e-02,\n","                       1.2204e-02, -9.2720e-03, -1.0830e-02, -5.6615e-03,  1.3126e-02,\n","                       1.5770e-02, -3.2733e-03, -2.9880e-04, -2.9659e-03,  1.2872e-02,\n","                      -1.2465e-02, -1.0897e-02,  1.3325e-02,  1.3804e-02,  4.7867e-03,\n","                      -5.8247e-03,  3.6733e-03, -3.5978e-03, -1.5941e-02, -6.1098e-04,\n","                       1.3501e-02,  5.2919e-03, -1.2432e-03,  4.9963e-03, -1.1019e-02,\n","                      -9.9843e-03, -2.2099e-03, -3.5360e-03,  1.4502e-02,  7.9243e-04,\n","                      -1.6510e-02, -1.6132e-02, -1.8067e-03, -9.9267e-03,  8.3460e-04,\n","                       1.6716e-02,  1.2167e-02, -1.5697e-02,  1.5500e-02,  2.6549e-03,\n","                       8.9594e-03, -1.1788e-02, -5.2817e-03,  1.4604e-02, -2.6489e-03,\n","                      -1.5525e-02,  1.3093e-02,  6.6909e-03, -1.3004e-02,  4.8362e-04,\n","                       1.5252e-02,  8.2369e-03, -1.4984e-03, -1.2048e-02, -9.5826e-04,\n","                       1.1764e-02,  6.7868e-03,  1.5308e-02,  1.4140e-02, -1.3634e-02,\n","                       5.9303e-04, -5.9748e-03,  1.4126e-02, -1.0939e-02, -6.3198e-03,\n","                       5.1905e-03, -3.6759e-03,  7.5936e-03, -1.1791e-02, -9.1055e-05,\n","                      -1.0445e-03, -5.6944e-03,  7.7085e-03,  1.4198e-02, -8.5142e-03,\n","                       4.4950e-03,  1.2886e-02,  1.0033e-02, -6.5394e-03, -6.9339e-03,\n","                      -1.1658e-02,  5.8423e-03, -5.4505e-03,  9.2267e-03, -1.2524e-02,\n","                      -3.5871e-03,  1.5900e-02, -5.6041e-03,  2.4454e-03,  8.4971e-03,\n","                       1.3051e-02, -3.2444e-03,  8.6707e-03, -8.1438e-03,  7.0310e-03,\n","                      -7.2857e-03,  6.1977e-03, -2.8183e-04,  2.4468e-03, -1.3460e-02,\n","                       8.5001e-03, -7.2309e-03,  2.8947e-03,  5.2050e-03, -8.8228e-03,\n","                      -8.2750e-03, -2.3120e-03, -1.2697e-02, -1.5954e-02,  1.1993e-02,\n","                       4.4043e-04,  1.3108e-02, -1.0720e-03, -1.3698e-02, -3.6156e-03,\n","                      -4.4749e-03,  2.2687e-03,  3.7647e-03,  6.2488e-03, -1.2566e-02,\n","                      -1.7968e-02, -3.1779e-03,  5.5840e-03, -9.5617e-03,  1.2768e-03,\n","                      -5.4596e-03,  1.5886e-02,  2.9877e-03, -6.7507e-03,  1.3674e-02,\n","                      -5.8084e-03,  1.1455e-02,  1.0320e-02,  1.5235e-02, -1.2521e-02,\n","                      -1.0306e-02,  1.3943e-02, -4.0776e-03,  2.0855e-03,  1.5711e-03,\n","                       5.3373e-03,  1.0225e-03, -1.0098e-02,  1.2012e-02,  8.1662e-03,\n","                      -7.9604e-03, -1.2168e-02,  1.3753e-02, -1.3355e-02,  1.7453e-02,\n","                      -2.6367e-03, -9.1580e-03, -4.3687e-03,  1.2286e-02, -1.5225e-03,\n","                       6.4334e-04,  1.5080e-02, -1.4854e-02, -1.6528e-03,  1.2762e-02,\n","                       1.1915e-02, -4.6397e-03,  8.2609e-03, -5.5149e-03,  8.8341e-03,\n","                       8.1358e-03,  1.4535e-02, -1.6448e-02, -1.1052e-02,  5.8951e-03,\n","                      -3.4648e-03, -1.4680e-02, -3.5177e-03, -7.9113e-03, -1.8333e-03,\n","                       8.6629e-03, -1.3050e-02,  6.8468e-03,  5.0234e-03,  1.3759e-02,\n","                       2.8891e-03,  8.1769e-04, -5.4784e-03,  2.9050e-03,  1.5063e-03,\n","                       4.2816e-03,  7.4943e-04, -1.6482e-02,  1.2685e-02, -6.8650e-04,\n","                      -1.3520e-02, -1.1826e-02, -4.4645e-03, -8.3784e-03, -1.3147e-02,\n","                      -6.5915e-03,  7.5451e-03, -9.8544e-04,  2.1754e-03,  1.5473e-02,\n","                      -1.0685e-02,  1.0525e-02, -2.6183e-03,  3.1291e-03,  1.0205e-02,\n","                       7.3646e-03, -3.0355e-03,  7.4450e-03, -5.2384e-03,  1.9935e-03,\n","                       1.1847e-02, -1.6176e-02,  1.4528e-02,  4.8276e-03, -6.3968e-03,\n","                       1.6324e-02,  4.7665e-03,  9.6633e-03, -5.7119e-03, -1.2066e-02,\n","                      -4.0598e-03, -1.4174e-02,  8.8471e-03,  3.9480e-03, -1.5593e-02,\n","                       7.7441e-03, -2.9240e-03,  1.0147e-02,  8.0341e-03, -1.4871e-02,\n","                       1.1435e-02,  3.1790e-03,  6.2106e-03, -1.7642e-02, -1.3238e-02,\n","                       7.0325e-03, -1.7247e-02,  8.1505e-03,  1.4342e-02, -7.3306e-03,\n","                      -4.2110e-04, -5.9345e-03,  1.7125e-02,  1.1562e-02, -1.7259e-02,\n","                      -1.2874e-02,  1.1096e-02], device='cuda:0')),\n","             ('transformer_encoder.layers.0.linear2.weight',\n","              tensor([[ 0.0403, -0.0425,  0.0144,  ...,  0.0240,  0.0437, -0.0298],\n","                      [ 0.0434,  0.0082, -0.0334,  ..., -0.0106,  0.0428,  0.0189],\n","                      [ 0.0290, -0.0138, -0.0079,  ...,  0.0025, -0.0368,  0.0348],\n","                      ...,\n","                      [ 0.0262,  0.0308,  0.0368,  ...,  0.0287,  0.0346,  0.0247],\n","                      [ 0.0163, -0.0326, -0.0319,  ..., -0.0383,  0.0364,  0.0309],\n","                      [ 0.0029,  0.0264, -0.0139,  ...,  0.0328,  0.0106, -0.0233]],\n","                     device='cuda:0')),\n","             ('transformer_encoder.layers.0.linear2.bias',\n","              tensor([ 0.0217, -0.0319,  0.0446,  ...,  0.0231,  0.0257, -0.0318],\n","                     device='cuda:0')),\n","             ('transformer_encoder.layers.0.norm1.weight',\n","              tensor([1.0005, 1.0012, 1.0015,  ..., 1.0002, 0.9997, 1.0007], device='cuda:0')),\n","             ('transformer_encoder.layers.0.norm1.bias',\n","              tensor([ 0.0002, -0.0003,  0.0002,  ..., -0.0007,  0.0005, -0.0003],\n","                     device='cuda:0')),\n","             ('transformer_encoder.layers.0.norm2.weight',\n","              tensor([1.0006, 1.0009, 1.0013,  ..., 1.0000, 0.9995, 1.0006], device='cuda:0')),\n","             ('transformer_encoder.layers.0.norm2.bias',\n","              tensor([ 0.0002, -0.0003,  0.0003,  ..., -0.0006,  0.0001, -0.0001],\n","                     device='cuda:0')),\n","             ('transformer_encoder.layers.1.self_attn.in_proj_weight',\n","              tensor([[-0.0193, -0.0203,  0.0092,  ..., -0.0107, -0.0062, -0.0023],\n","                      [-0.0143, -0.0177,  0.0140,  ...,  0.0166, -0.0105, -0.0038],\n","                      [ 0.0152, -0.0181, -0.0138,  ..., -0.0173,  0.0061, -0.0033],\n","                      ...,\n","                      [-0.0088,  0.0147, -0.0065,  ...,  0.0141,  0.0134, -0.0039],\n","                      [-0.0133,  0.0172, -0.0196,  ..., -0.0181,  0.0106, -0.0090],\n","                      [-0.0170, -0.0005,  0.0147,  ...,  0.0200,  0.0198, -0.0151]],\n","                     device='cuda:0')),\n","             ('transformer_encoder.layers.1.self_attn.in_proj_bias',\n","              tensor([-1.1535e-04, -1.7961e-05,  1.4197e-05,  ..., -1.5091e-04,\n","                       4.4252e-04, -1.3502e-04], device='cuda:0')),\n","             ('transformer_encoder.layers.1.self_attn.out_proj.weight',\n","              tensor([[-0.0155, -0.0032, -0.0081,  ...,  0.0085, -0.0013,  0.0092],\n","                      [ 0.0130, -0.0078, -0.0147,  ...,  0.0118,  0.0069,  0.0124],\n","                      [ 0.0123,  0.0104,  0.0015,  ...,  0.0056,  0.0096, -0.0073],\n","                      ...,\n","                      [-0.0020,  0.0053,  0.0059,  ...,  0.0002,  0.0080,  0.0071],\n","                      [ 0.0075,  0.0120,  0.0013,  ...,  0.0115,  0.0003, -0.0150],\n","                      [-0.0163, -0.0097, -0.0163,  ..., -0.0117, -0.0092, -0.0085]],\n","                     device='cuda:0')),\n","             ('transformer_encoder.layers.1.self_attn.out_proj.bias',\n","              tensor([ 4.7259e-05,  7.1165e-04, -6.9908e-05,  ..., -1.5554e-03,\n","                       8.1676e-04, -2.4386e-04], device='cuda:0')),\n","             ('transformer_encoder.layers.1.linear1.weight',\n","              tensor([[-0.0030,  0.0131, -0.0093,  ...,  0.0134,  0.0144, -0.0016],\n","                      [-0.0035, -0.0030,  0.0027,  ..., -0.0024, -0.0015,  0.0144],\n","                      [-0.0060,  0.0065, -0.0161,  ...,  0.0035,  0.0093,  0.0007],\n","                      ...,\n","                      [-0.0030, -0.0024, -0.0075,  ...,  0.0139, -0.0163, -0.0065],\n","                      [ 0.0088,  0.0102,  0.0082,  ..., -0.0001, -0.0081, -0.0002],\n","                      [ 0.0027,  0.0094,  0.0146,  ..., -0.0155,  0.0007, -0.0015]],\n","                     device='cuda:0')),\n","             ('transformer_encoder.layers.1.linear1.bias',\n","              tensor([-2.6642e-04,  7.1406e-03, -1.1025e-02, -1.4162e-02,  2.8734e-04,\n","                       1.3025e-02, -1.6871e-02,  1.1104e-02, -1.1566e-02,  7.0131e-03,\n","                       1.3764e-02, -1.0432e-02,  5.1646e-04, -1.4165e-02, -1.2415e-02,\n","                       9.9672e-03,  8.1878e-03,  4.2316e-03, -1.2581e-02, -1.3119e-03,\n","                       4.5146e-03, -1.2902e-02,  1.0664e-02, -1.3222e-03,  1.2581e-02,\n","                      -1.5106e-02, -1.1622e-02, -4.6138e-03, -6.7099e-03,  8.7526e-03,\n","                      -1.2840e-02, -7.6562e-03,  9.8343e-03,  1.8708e-03, -1.4859e-02,\n","                      -1.6440e-02, -4.6366e-03, -4.0525e-03, -1.2218e-03,  5.0940e-03,\n","                       1.7455e-02, -5.0477e-03, -9.3443e-03,  1.0291e-02,  1.5830e-03,\n","                      -9.9162e-03,  1.3428e-02, -1.7985e-03,  2.2307e-03,  5.9281e-04,\n","                      -5.5990e-03,  5.0734e-03,  2.6291e-03, -1.1129e-02,  1.3595e-02,\n","                       1.4232e-02,  3.6436e-03, -1.2485e-02, -1.9881e-03, -1.4549e-02,\n","                      -2.9292e-03,  1.7779e-02, -6.4390e-03, -1.3693e-02,  1.7381e-03,\n","                      -8.6771e-04, -6.2824e-03, -7.2773e-03,  9.2587e-03,  1.5816e-02,\n","                       1.1060e-02,  5.7670e-03,  2.6696e-03,  1.4839e-02,  2.9553e-04,\n","                       1.2312e-02,  1.0038e-02,  6.8211e-03,  4.5527e-03, -2.7932e-03,\n","                      -1.6314e-02, -1.0566e-02,  9.0271e-03, -1.2553e-02, -5.5904e-03,\n","                      -1.4820e-02,  1.1006e-02,  1.7390e-03,  4.0839e-03,  1.4373e-02,\n","                       5.2943e-03,  1.2536e-02, -1.6162e-02, -8.4699e-04,  1.6549e-02,\n","                      -2.1962e-03,  6.3921e-03, -1.2162e-02, -2.8829e-03, -7.6856e-03,\n","                       8.7167e-03,  3.5219e-03,  7.1586e-03, -5.6990e-03, -5.6180e-03,\n","                       1.0643e-02,  9.4596e-03, -3.0565e-03,  2.1124e-03,  4.7350e-03,\n","                       1.2530e-02,  5.0027e-03,  1.5464e-02, -1.0556e-02, -1.5804e-02,\n","                      -4.8757e-03,  5.1055e-03, -4.0832e-03, -1.2836e-02, -8.2757e-03,\n","                      -1.1516e-02,  3.8449e-03,  8.3186e-03,  1.3778e-02,  1.2404e-02,\n","                      -2.6347e-03, -1.3437e-02, -1.7565e-03, -7.1339e-03,  1.3775e-03,\n","                      -6.3857e-03, -6.3198e-03, -3.0018e-03, -1.6065e-03, -1.1065e-02,\n","                      -4.6979e-04, -8.6078e-03, -1.3534e-02,  7.6157e-03,  1.0975e-02,\n","                      -4.4653e-03,  1.1683e-02,  4.4545e-03, -1.3974e-03,  6.9206e-03,\n","                       7.4411e-03, -7.4925e-04,  7.0372e-03,  6.6045e-03,  2.3666e-03,\n","                       3.9218e-03,  1.4108e-02,  1.0729e-02,  4.6509e-03, -5.3056e-03,\n","                       5.4956e-03,  4.6859e-03, -8.1666e-03,  8.7355e-03, -1.4849e-03,\n","                      -7.6963e-03,  2.4471e-03, -1.0517e-02,  7.3855e-03, -5.8657e-03,\n","                      -1.1470e-03,  4.3697e-03,  1.5739e-02, -8.6299e-03, -1.4541e-02,\n","                      -1.4833e-02,  1.5877e-02, -1.8031e-03,  1.4169e-02, -7.4099e-03,\n","                       7.8999e-03,  3.7916e-03, -1.1201e-03,  3.5673e-03,  8.5115e-04,\n","                       5.5628e-03, -1.4981e-02,  3.9288e-03,  6.0212e-03, -7.1288e-03,\n","                       7.8923e-03, -1.4254e-02, -8.5501e-04, -4.8333e-03,  1.5436e-02,\n","                      -2.9655e-03,  1.1724e-02, -1.1278e-02,  1.0325e-02, -1.6457e-03,\n","                      -1.0692e-02, -1.5463e-02, -1.4956e-03, -1.1727e-03, -1.6424e-02,\n","                       1.2175e-03, -3.2418e-03, -4.0970e-03,  1.1405e-02, -1.0201e-02,\n","                      -1.0075e-02, -6.8752e-03,  1.0170e-03, -8.4274e-03, -7.0262e-03,\n","                      -1.4736e-02, -4.3521e-04, -1.6417e-02, -4.4825e-03,  1.5444e-02,\n","                      -7.6321e-03, -6.8741e-03,  9.7858e-03, -1.2220e-02, -1.0464e-02,\n","                       1.2189e-03, -1.6505e-02, -3.5735e-03, -4.5194e-03,  2.4765e-03,\n","                      -1.3149e-02,  1.3416e-02, -1.2982e-02, -1.3652e-02, -3.6552e-03,\n","                      -1.8958e-03, -1.2815e-02, -1.0903e-03, -9.9646e-03,  9.0592e-03,\n","                       5.1776e-04, -7.0435e-03, -8.3022e-04, -1.3510e-02,  1.1441e-02,\n","                      -1.7263e-02,  1.5683e-02,  4.3843e-03,  2.4725e-03,  1.6688e-02,\n","                      -3.0920e-03,  1.5095e-02, -1.1980e-02,  2.5125e-03,  1.1913e-02,\n","                       3.5331e-03,  5.1447e-03,  1.4490e-02,  8.5502e-03,  1.7898e-03,\n","                      -1.7101e-05, -6.2474e-03,  2.9088e-03,  3.1031e-03, -4.8357e-03,\n","                      -1.0449e-02, -1.0136e-02,  3.5778e-03, -5.4902e-03,  1.5220e-02,\n","                       1.4792e-02, -1.0044e-02, -1.1338e-02, -6.0429e-03,  1.6169e-02,\n","                       1.5698e-02,  9.0113e-04, -4.9389e-05, -3.2026e-03,  1.7343e-02,\n","                      -1.3437e-02, -1.1440e-02,  1.2888e-02,  1.4000e-02,  5.3908e-03,\n","                      -5.9233e-03,  4.5679e-03, -4.0550e-03, -1.6119e-02, -1.6123e-03,\n","                       1.3549e-02,  6.3923e-03, -1.5250e-03,  6.2756e-03, -1.1078e-02,\n","                      -1.0136e-02, -2.0886e-03, -3.5054e-03,  1.3478e-02, -1.0456e-03,\n","                      -1.4102e-02, -1.2890e-02,  8.1342e-04, -9.6639e-03,  4.1146e-04,\n","                       2.0817e-02,  1.1836e-02, -1.1100e-02,  1.4471e-02,  4.4365e-03,\n","                       9.1595e-03, -9.8427e-03, -5.1885e-03,  1.4056e-02, -2.7830e-03,\n","                      -1.2089e-02,  1.3200e-02,  6.7195e-03, -1.3198e-02,  4.3924e-04,\n","                       1.5365e-02,  8.1599e-03, -1.4108e-03, -1.2322e-02, -1.0592e-03,\n","                       1.1693e-02,  9.6906e-03,  1.5377e-02,  1.2700e-02, -1.2822e-02,\n","                       1.0043e-03, -6.5691e-03,  1.4677e-02, -1.1062e-02, -6.6531e-03,\n","                       1.0215e-02, -3.5006e-03,  7.6695e-03, -5.7192e-03,  9.4873e-05,\n","                      -9.7155e-04,  9.7998e-04,  8.6509e-03,  1.2661e-02, -9.3899e-03,\n","                       4.1339e-03,  1.3039e-02,  8.0844e-03, -8.1773e-03, -8.4535e-03,\n","                      -1.0429e-02,  5.7094e-03, -6.2931e-03,  8.9811e-03, -1.4308e-02,\n","                      -3.4853e-03,  1.7972e-02, -9.2139e-03,  2.6969e-03,  7.9916e-03,\n","                       1.2306e-02, -3.0461e-03,  8.4979e-03, -8.6012e-03,  6.9267e-03,\n","                      -6.1986e-03,  5.8669e-03, -1.5627e-04,  2.8303e-03, -1.5253e-02,\n","                       7.6470e-03, -6.3058e-03,  2.6767e-03,  5.3175e-03, -8.6882e-03,\n","                      -9.6726e-03,  5.0811e-04, -1.2400e-02, -1.6729e-02,  1.3192e-02,\n","                      -1.0142e-03,  1.5673e-02, -1.2349e-03, -1.3951e-02, -3.4083e-03,\n","                      -4.3174e-03,  8.5350e-03,  2.5123e-03,  5.7139e-03, -1.2239e-02,\n","                      -8.6474e-03,  1.7091e-03,  5.7182e-03, -1.0106e-02,  3.2811e-03,\n","                      -7.2318e-03,  1.5102e-02,  3.6945e-03, -7.1986e-03,  1.3058e-02,\n","                      -6.4377e-03,  1.1589e-02,  1.1877e-02,  1.5511e-02, -1.2352e-02,\n","                      -1.0572e-02,  1.3777e-02, -3.7539e-03,  2.0423e-03,  6.7105e-03,\n","                       4.4292e-03,  8.5774e-04, -1.0021e-02,  1.2273e-02,  8.2319e-03,\n","                      -9.8002e-03, -1.2145e-02,  2.3256e-02, -1.3850e-02,  1.5700e-02,\n","                      -2.9177e-03, -9.0932e-03, -4.1405e-03,  1.2795e-02, -2.5201e-03,\n","                       5.5701e-03,  1.4761e-02, -8.7210e-03, -2.4344e-03,  1.1586e-02,\n","                       1.1978e-02, -4.9317e-03,  7.9545e-03, -5.1338e-03,  2.3874e-02,\n","                       8.2956e-03,  1.4679e-02, -1.3515e-02, -1.0907e-02,  6.0621e-03,\n","                      -3.3636e-03, -1.5082e-02, -2.9702e-03, -8.1603e-03, -3.6564e-03,\n","                       8.6176e-03, -1.2942e-02,  5.7554e-03,  4.7242e-03,  1.0854e-02,\n","                       1.7617e-03,  9.7149e-04, -5.4751e-03,  2.5896e-03,  1.3019e-03,\n","                       4.3953e-03, -4.1389e-05, -1.6496e-02,  1.2665e-02, -2.5845e-05,\n","                      -9.9480e-03, -1.1884e-02, -6.0832e-03, -9.1437e-03, -1.2466e-02,\n","                      -6.5055e-03,  7.1160e-03, -6.2754e-04,  6.7775e-04,  1.5318e-02,\n","                      -6.7882e-03,  1.8241e-02, -2.1702e-03,  2.6926e-03,  1.0611e-02,\n","                       6.6894e-03, -4.4845e-03,  7.2845e-03, -5.6224e-03,  2.1957e-03,\n","                       9.4651e-03, -1.6231e-02,  1.3399e-02,  4.9018e-03, -1.9905e-03,\n","                       1.5498e-02,  5.2469e-03,  8.7391e-03, -5.9482e-03, -1.3664e-02,\n","                      -6.2797e-03, -1.4574e-02,  8.7615e-03,  8.5556e-03, -1.4047e-02,\n","                       7.9584e-03,  1.6635e-03,  9.6394e-03,  5.8157e-03, -1.4815e-02,\n","                       1.0116e-02,  3.5402e-03,  5.9238e-03, -1.4848e-02, -1.3111e-02,\n","                       6.6061e-03, -1.5299e-02,  6.9755e-03,  1.4915e-02, -7.5706e-03,\n","                      -2.2145e-04, -6.0893e-03,  1.4459e-02,  1.1789e-02, -1.7233e-02,\n","                      -9.7970e-03,  1.0984e-02], device='cuda:0')),\n","             ('transformer_encoder.layers.1.linear2.weight',\n","              tensor([[ 0.0404, -0.0380,  0.0143,  ...,  0.0238,  0.0464, -0.0299],\n","                      [ 0.0439,  0.0081, -0.0334,  ..., -0.0110,  0.0445,  0.0172],\n","                      [ 0.0286, -0.0204, -0.0079,  ...,  0.0023, -0.0389,  0.0353],\n","                      ...,\n","                      [ 0.0257,  0.0363,  0.0367,  ...,  0.0286,  0.0353,  0.0254],\n","                      [ 0.0177, -0.0283, -0.0320,  ..., -0.0381,  0.0368,  0.0319],\n","                      [ 0.0027,  0.0307, -0.0138,  ...,  0.0328,  0.0081, -0.0219]],\n","                     device='cuda:0')),\n","             ('transformer_encoder.layers.1.linear2.bias',\n","              tensor([ 0.0208, -0.0321,  0.0437,  ...,  0.0239,  0.0263, -0.0307],\n","                     device='cuda:0')),\n","             ('transformer_encoder.layers.1.norm1.weight',\n","              tensor([1.0005, 1.0005, 1.0003,  ..., 1.0007, 0.9994, 1.0002], device='cuda:0')),\n","             ('transformer_encoder.layers.1.norm1.bias',\n","              tensor([-3.1439e-04, -6.1857e-05,  8.7604e-06,  ..., -1.0399e-03,\n","                       9.6390e-04,  4.1484e-04], device='cuda:0')),\n","             ('transformer_encoder.layers.1.norm2.weight',\n","              tensor([0.9883, 0.9946, 0.9872,  ..., 0.9914, 0.9807, 0.9893], device='cuda:0')),\n","             ('transformer_encoder.layers.1.norm2.bias',\n","              tensor([ 0.0065, -0.0014, -0.0075,  ..., -0.0071,  0.0102,  0.0061],\n","                     device='cuda:0')),\n","             ('encoder.weight',\n","              tensor([[-0.0746,  0.0633,  0.0088,  ...,  0.0264, -0.0289, -0.0325],\n","                      [-0.0106, -0.0723, -0.0211,  ...,  0.0921,  0.0574, -0.0375],\n","                      [-0.0626, -0.0323, -0.0305,  ...,  0.0259,  0.0438,  0.0228],\n","                      ...,\n","                      [ 0.0639, -0.0497, -0.0972,  ...,  0.0780, -0.0578, -0.0534],\n","                      [ 0.0011, -0.0103, -0.0944,  ..., -0.0155,  0.0990, -0.0906],\n","                      [ 0.0081,  0.0554,  0.0120,  ..., -0.0431,  0.0307, -0.0424]],\n","                     device='cuda:0')),\n","             ('decoder.weight',\n","              tensor([[-0.0768,  0.0452, -0.0496,  ...,  0.0892, -0.0168, -0.0473],\n","                      [-0.0862, -0.0850,  0.0281,  ...,  0.0794, -0.0420,  0.0804],\n","                      [-0.1802,  0.1051,  0.1613,  ...,  0.0800, -0.0934, -0.0736],\n","                      ...,\n","                      [ 0.0325, -0.0125,  0.0565,  ..., -0.0928, -0.0688, -0.0292],\n","                      [-0.0539, -0.0682, -0.0680,  ...,  0.0072, -0.0220, -0.0283],\n","                      [ 0.0579, -0.0605,  0.0975,  ...,  0.0458,  0.0011,  0.0470]],\n","                     device='cuda:0')),\n","             ('transformer_decoder.layers.0.self_attn.in_proj_weight',\n","              tensor([[ 1.1975e-02,  1.8415e-02,  1.2208e-02,  ...,  1.9589e-02,\n","                        6.2639e-03, -6.1935e-03],\n","                      [ 1.3581e-02, -6.2526e-03,  8.1209e-03,  ...,  5.6111e-03,\n","                        2.0257e-02,  5.4895e-03],\n","                      [ 8.9722e-03, -1.3479e-02, -6.9261e-03,  ..., -1.9895e-02,\n","                        5.5403e-03, -5.3019e-03],\n","                      ...,\n","                      [ 2.8202e-02, -3.9837e-03, -3.1738e-04,  ...,  4.2476e-03,\n","                       -1.1437e-02,  2.0369e-02],\n","                      [-2.7150e-02,  2.8723e-02,  4.2792e-03,  ...,  6.5229e-03,\n","                        2.1456e-02, -9.1978e-03],\n","                      [ 5.1608e-05, -9.5999e-03,  1.8963e-02,  ..., -1.1744e-03,\n","                        9.0808e-03,  1.3042e-02]], device='cuda:0')),\n","             ('transformer_decoder.layers.0.self_attn.in_proj_bias',\n","              tensor([-0.0004,  0.0007, -0.0006,  ..., -0.0007,  0.0004, -0.0002],\n","                     device='cuda:0')),\n","             ('transformer_decoder.layers.0.self_attn.out_proj.weight',\n","              tensor([[-0.0072,  0.0143, -0.0102,  ...,  0.0006, -0.0059, -0.0013],\n","                      [ 0.0064,  0.0005,  0.0139,  ..., -0.0007, -0.0028, -0.0129],\n","                      [ 0.0023,  0.0050,  0.0250,  ..., -0.0112,  0.0132, -0.0093],\n","                      ...,\n","                      [ 0.0097, -0.0024,  0.0090,  ..., -0.0018, -0.0161, -0.0132],\n","                      [-0.0076,  0.0124,  0.0095,  ...,  0.0162, -0.0156, -0.0023],\n","                      [-0.0155, -0.0055, -0.0115,  ...,  0.0101,  0.0138, -0.0158]],\n","                     device='cuda:0')),\n","             ('transformer_decoder.layers.0.self_attn.out_proj.bias',\n","              tensor([-0.0022, -0.0076, -0.0506,  ..., -0.0071,  0.0048, -0.0045],\n","                     device='cuda:0')),\n","             ('transformer_decoder.layers.0.multihead_attn.in_proj_weight',\n","              tensor([[ 0.0149,  0.0029,  0.0302,  ..., -0.0082, -0.0043, -0.0169],\n","                      [ 0.0089,  0.0039,  0.0029,  ...,  0.0086, -0.0122, -0.0160],\n","                      [ 0.0185, -0.0054,  0.0154,  ..., -0.0004, -0.0089,  0.0177],\n","                      ...,\n","                      [ 0.0130, -0.0076, -0.0037,  ..., -0.0186, -0.0092,  0.0060],\n","                      [ 0.0003,  0.0014, -0.0076,  ..., -0.0212, -0.0104, -0.0123],\n","                      [ 0.0162, -0.0129, -0.0065,  ...,  0.0064, -0.0052,  0.0153]],\n","                     device='cuda:0')),\n","             ('transformer_decoder.layers.0.multihead_attn.in_proj_bias',\n","              tensor([ 3.2936e-05,  2.5116e-04,  4.8982e-05,  ..., -6.7502e-04,\n","                       7.2779e-05,  3.4509e-04], device='cuda:0')),\n","             ('transformer_decoder.layers.0.multihead_attn.out_proj.weight',\n","              tensor([[-0.0086,  0.0062, -0.0128,  ...,  0.0128, -0.0106, -0.0034],\n","                      [ 0.0091,  0.0032, -0.0009,  ..., -0.0064,  0.0172,  0.0158],\n","                      [-0.0022, -0.0309,  0.0074,  ..., -0.0116, -0.0077,  0.0078],\n","                      ...,\n","                      [-0.0077, -0.0155,  0.0108,  ...,  0.0111, -0.0130, -0.0035],\n","                      [-0.0006, -0.0058,  0.0041,  ..., -0.0123,  0.0148, -0.0107],\n","                      [ 0.0061, -0.0119,  0.0094,  ...,  0.0112, -0.0059, -0.0106]],\n","                     device='cuda:0')),\n","             ('transformer_decoder.layers.0.multihead_attn.out_proj.bias',\n","              tensor([-0.0060,  0.0055, -0.0078,  ..., -0.0005,  0.0042, -0.0042],\n","                     device='cuda:0')),\n","             ('transformer_decoder.layers.0.linear1.weight',\n","              tensor([[-0.0118,  0.0113, -0.0279,  ...,  0.0045,  0.0132, -0.0081],\n","                      [-0.0033,  0.0132,  0.0195,  ...,  0.0113, -0.0076, -0.0019],\n","                      [-0.0065,  0.0193, -0.0008,  ...,  0.0103, -0.0049,  0.0049],\n","                      ...,\n","                      [-0.0097,  0.0177,  0.0196,  ..., -0.0021,  0.0070, -0.0042],\n","                      [-0.0100, -0.0081,  0.0246,  ..., -0.0094, -0.0065,  0.0056],\n","                      [-0.0120,  0.0026,  0.0339,  ...,  0.0111,  0.0073,  0.0021]],\n","                     device='cuda:0')),\n","             ('transformer_decoder.layers.0.linear1.bias',\n","              tensor([-1.1030e-02,  2.6435e-03,  1.0072e-02, -1.4993e-02, -3.4089e-08,\n","                      -9.4520e-03, -1.6004e-02, -8.3111e-03,  4.4056e-03, -1.7457e-02,\n","                       1.1125e-02,  1.4316e-02,  5.6567e-04, -1.0900e-02, -6.5306e-03,\n","                       4.2949e-03, -1.5351e-02, -2.7514e-04, -6.2642e-03, -8.1327e-03,\n","                      -1.0920e-02, -4.0057e-03, -1.4704e-02,  8.2973e-04,  4.6756e-03,\n","                       1.2258e-02, -1.3321e-02,  1.0490e-02, -1.5350e-02, -1.8544e-02,\n","                       2.3886e-03, -1.3864e-02, -3.4237e-03,  9.9165e-03,  3.8331e-03,\n","                       4.0162e-03,  8.2971e-05, -1.5412e-02, -1.8959e-02, -1.8535e-02,\n","                      -8.1102e-03,  1.0688e-02,  9.7918e-03, -1.2911e-02, -2.6147e-03,\n","                       4.3432e-03,  2.3674e-03,  1.5745e-03,  7.9976e-03,  5.9699e-03,\n","                      -1.2731e-02, -1.9988e-02, -6.5236e-04, -2.2855e-02,  6.0423e-03,\n","                      -1.0878e-02,  5.0437e-03, -7.8809e-03,  3.6777e-03, -1.3751e-02,\n","                       3.4246e-03, -2.5204e-04, -1.9130e-02, -1.0498e-02, -5.5133e-03,\n","                       1.0596e-02, -9.6765e-03,  7.5550e-03, -1.4668e-02,  6.1986e-03,\n","                       9.7334e-03,  1.0339e-02, -1.8760e-02, -2.3455e-04, -1.3965e-02,\n","                      -8.7339e-03, -1.4339e-02,  5.7095e-03,  1.2102e-02, -8.1050e-03,\n","                       8.1823e-03,  4.3901e-03,  6.4200e-03,  1.4306e-02, -2.1927e-03,\n","                      -1.4923e-02, -1.8412e-02,  7.3349e-03, -1.1990e-02,  8.9241e-03,\n","                      -9.7490e-03,  8.3242e-03, -3.7801e-03, -8.4768e-03,  2.9961e-03,\n","                      -1.4654e-02, -5.5639e-03,  7.4588e-03, -1.0868e-02, -1.7138e-02,\n","                       1.0802e-02,  1.7638e-03, -3.1463e-02,  9.7492e-03, -1.1156e-02,\n","                      -5.2996e-05, -1.5560e-02,  2.9708e-03, -5.0680e-03,  1.1316e-02,\n","                      -2.0720e-02, -1.2879e-02, -4.9745e-03,  6.9380e-03,  7.9257e-03,\n","                      -1.5428e-03, -5.8594e-03, -1.5608e-02, -4.5708e-03, -1.2511e-02,\n","                      -1.1902e-02, -1.6739e-03, -5.0130e-03, -3.6134e-04, -1.4729e-02,\n","                      -1.5148e-02,  2.5773e-03,  8.9334e-03, -1.0561e-02, -1.7598e-02,\n","                      -2.3740e-03, -2.4674e-02, -4.8038e-03, -7.8997e-03, -6.5997e-04,\n","                      -1.2527e-02, -1.6290e-02,  5.3081e-03, -1.9103e-02, -1.6920e-02,\n","                      -1.7872e-02, -1.2606e-02, -1.9437e-02, -1.8403e-02, -8.0831e-04,\n","                      -4.0785e-03, -1.8850e-03,  7.2509e-04,  5.3937e-03, -1.9206e-02,\n","                       1.1218e-02,  2.6034e-03, -1.4211e-02,  2.3113e-03,  1.5436e-02,\n","                       1.0928e-02, -1.8292e-02, -1.7929e-02, -8.3847e-03,  3.4831e-03,\n","                       1.2255e-02, -8.4043e-03,  1.0793e-02, -7.4093e-03,  3.3210e-03,\n","                      -1.3826e-02, -8.8773e-03, -2.0844e-02, -1.5178e-02,  1.1789e-03,\n","                      -6.5285e-03, -1.5858e-02, -6.1348e-03, -5.7901e-03,  8.2877e-03,\n","                       1.4117e-02,  9.7956e-03,  1.2541e-02, -8.1674e-03, -1.0520e-02,\n","                       1.3312e-02, -6.1879e-04, -9.9208e-03, -7.2311e-03, -1.7671e-02,\n","                       1.2799e-02, -8.2437e-03,  2.2672e-03, -9.1799e-03, -2.7227e-02,\n","                      -1.3280e-02,  3.7749e-03, -1.0764e-03, -1.7952e-02, -8.9146e-03,\n","                       1.4840e-03,  3.8998e-03, -1.8463e-02, -1.6178e-02,  7.8326e-03,\n","                       1.0677e-03,  1.3378e-02, -1.7153e-02,  1.7040e-03,  1.1790e-02,\n","                       1.4409e-02, -1.1100e-02, -2.6782e-03, -1.8641e-02,  1.0752e-02,\n","                       6.4622e-03, -9.8420e-03,  7.2754e-03, -9.9686e-03,  1.0450e-02,\n","                       3.5097e-04,  1.4173e-02, -1.0011e-02, -1.7150e-02,  1.2317e-02,\n","                      -1.5273e-02, -1.5916e-03,  8.4409e-03,  1.2013e-02,  7.3693e-04,\n","                       1.4449e-03,  9.0270e-03, -1.8793e-02, -1.3139e-02, -1.9971e-02,\n","                      -3.3025e-03,  9.0027e-03,  5.9791e-03, -1.7282e-02, -1.5470e-03,\n","                       6.4672e-04,  1.2222e-02,  2.2993e-03,  2.8386e-04,  1.7689e-03,\n","                       7.7753e-04, -1.8597e-03, -8.3619e-03, -1.8557e-02,  1.0299e-02,\n","                       5.0864e-03, -5.7875e-03,  9.5102e-03,  3.3256e-03, -8.1078e-03,\n","                       1.3665e-02,  1.1736e-02, -2.1303e-05,  6.0433e-03, -1.2920e-02,\n","                       1.1049e-02, -3.5212e-03, -2.9077e-03, -1.8442e-03,  4.6594e-03,\n","                      -5.2637e-03, -1.9399e-02, -1.4227e-02, -2.2082e-03, -1.9096e-02,\n","                      -5.1773e-03,  2.6230e-03, -7.7094e-03,  7.6524e-03, -1.1714e-02,\n","                       4.6401e-04,  1.0640e-02,  2.7045e-03, -7.6435e-04,  9.1577e-03,\n","                      -1.8652e-02, -1.1179e-02, -8.7729e-03, -3.5049e-03, -8.2715e-03,\n","                      -1.4070e-02, -1.1459e-02, -2.7656e-03,  3.2161e-03,  7.3644e-03,\n","                      -1.6568e-02, -8.8339e-03, -3.2753e-03, -2.2352e-02,  1.3451e-03,\n","                      -1.3329e-02,  2.1231e-03, -3.7117e-03, -1.8855e-02, -1.0470e-02,\n","                      -1.2059e-02,  1.3475e-03, -1.3148e-02, -1.3669e-02, -2.1468e-02,\n","                      -3.9343e-03, -6.0945e-04, -1.6278e-02, -7.8391e-03, -5.3829e-03,\n","                      -3.0968e-03, -4.1567e-03, -1.3210e-03, -6.2747e-03, -1.1183e-02,\n","                       6.1450e-03, -2.6154e-03, -1.4996e-02, -1.0010e-02,  1.7285e-03,\n","                      -5.0803e-03, -2.8000e-03, -8.2502e-03,  5.7879e-03,  5.7068e-03,\n","                       5.6385e-03,  7.7854e-03, -6.6286e-03, -9.9853e-03, -2.1053e-02,\n","                      -1.0743e-02, -1.2415e-02, -8.4816e-03, -1.6447e-02, -5.4438e-03,\n","                      -4.3584e-03, -1.9388e-02,  9.9512e-03, -1.0974e-02, -1.4415e-02,\n","                      -1.9416e-02,  7.8764e-03,  4.2086e-03, -1.0314e-02, -9.8262e-03,\n","                       4.3332e-03,  6.4064e-03, -3.3478e-03, -1.2676e-02, -1.3785e-02,\n","                      -1.0050e-02, -3.9267e-03, -6.5445e-03, -1.1188e-02,  7.3416e-03,\n","                       8.4771e-03,  1.4687e-02, -3.9465e-04, -1.1230e-02, -1.7593e-02,\n","                      -4.2017e-03,  1.1305e-02, -3.2651e-03, -2.1722e-02, -1.3902e-02,\n","                       5.2731e-03, -3.3180e-03,  4.9907e-04,  1.4283e-02, -1.8211e-03,\n","                      -9.4478e-03,  1.3754e-02,  1.1938e-02,  4.1275e-03,  4.6126e-03,\n","                      -2.1882e-02, -5.6330e-03, -1.5413e-02, -7.1282e-03, -1.7187e-02,\n","                      -2.7697e-02, -9.8642e-03, -2.0812e-02, -2.8653e-03, -1.8874e-02,\n","                       3.0359e-03, -1.1329e-02, -1.9231e-04, -3.2898e-03,  1.1970e-02,\n","                      -2.4479e-03, -1.6299e-02, -1.8925e-02, -6.2635e-03, -2.1732e-02,\n","                       1.0945e-02, -1.1734e-02,  5.5440e-03, -4.9438e-04, -2.4473e-03,\n","                      -1.6747e-02, -1.5394e-02,  5.0378e-04,  1.0788e-02, -1.0557e-02,\n","                      -1.7093e-02,  1.7751e-03,  9.1645e-03, -1.3413e-02,  1.2960e-02,\n","                       1.7329e-03, -1.1190e-02, -1.7789e-03, -2.8859e-03,  5.9382e-03,\n","                      -1.8044e-02,  2.7259e-03,  7.7951e-03,  6.1744e-03, -1.3034e-03,\n","                       1.2303e-02, -3.0076e-03,  8.8271e-03, -1.3322e-02, -5.2907e-03,\n","                      -5.4829e-03, -1.5213e-02,  8.8540e-03,  8.1079e-03, -7.3567e-03,\n","                       9.3727e-03, -3.7120e-03, -1.5626e-02,  1.3244e-02, -8.7050e-03,\n","                      -1.4269e-02, -1.8101e-02,  1.1901e-02,  7.9384e-04,  2.5345e-03,\n","                       1.3554e-02, -2.3248e-03, -1.6258e-02,  2.2430e-03, -4.8714e-04,\n","                      -9.0820e-03,  9.4159e-03, -1.2270e-02, -2.5841e-02,  5.9621e-03,\n","                       1.0328e-02,  6.2381e-03, -9.1418e-03, -8.3389e-03,  1.4950e-02,\n","                       4.7622e-04, -1.9889e-02, -9.4859e-04,  1.0964e-02, -1.4719e-02,\n","                       6.9554e-03, -1.0067e-02, -5.6830e-04,  1.0991e-02, -1.4081e-02,\n","                       7.5505e-03,  9.9275e-04,  1.2860e-02,  2.7067e-03,  9.2585e-03,\n","                       1.3106e-02, -1.6027e-02, -8.2387e-04, -3.7260e-03,  1.2069e-02,\n","                      -1.4879e-02,  1.2796e-02, -5.9408e-03, -5.5063e-03, -1.1587e-02,\n","                      -8.5155e-03, -6.1678e-03,  1.2321e-02, -1.1962e-02, -1.6108e-02,\n","                       3.2343e-03, -1.0344e-02,  6.9129e-03, -1.4642e-02, -4.0824e-03,\n","                      -1.6735e-03, -8.1232e-03,  3.5739e-03, -2.1717e-03, -1.9187e-03,\n","                      -4.4866e-03,  2.8476e-03, -1.1980e-03, -1.7170e-02, -1.2003e-02,\n","                      -5.0963e-03,  3.7763e-03,  8.1540e-03, -4.4224e-03,  4.8821e-03,\n","                      -2.2491e-02, -6.6265e-03,  1.4436e-02,  2.7520e-03,  9.0987e-03,\n","                      -2.0462e-02, -5.4585e-03, -1.5433e-02, -1.5846e-02,  2.1011e-03,\n","                       1.3288e-02,  3.1847e-03], device='cuda:0')),\n","             ('transformer_decoder.layers.0.linear2.weight',\n","              tensor([[ 0.0142,  0.0187,  0.0196,  ...,  0.0023, -0.0352, -0.0055],\n","                      [ 0.0035,  0.0018, -0.0033,  ...,  0.0168,  0.0054, -0.0424],\n","                      [-0.0221, -0.1157,  0.0508,  ..., -0.0192, -0.0273,  0.0974],\n","                      ...,\n","                      [ 0.0385, -0.0280, -0.0018,  ..., -0.0218, -0.0178,  0.0126],\n","                      [ 0.0130, -0.0270, -0.0106,  ..., -0.0070, -0.0105,  0.0284],\n","                      [ 0.0143, -0.0068, -0.0050,  ..., -0.0297, -0.0106, -0.0443]],\n","                     device='cuda:0')),\n","             ('transformer_decoder.layers.0.linear2.bias',\n","              tensor([ 0.0042,  0.0157, -0.0812,  ...,  0.0219, -0.0059, -0.0187],\n","                     device='cuda:0')),\n","             ('transformer_decoder.layers.0.norm1.weight',\n","              tensor([1.0388, 1.0233, 1.0067,  ..., 0.9999, 0.9997, 1.0037], device='cuda:0')),\n","             ('transformer_decoder.layers.0.norm1.bias',\n","              tensor([-0.0067,  0.0041,  0.0045,  ..., -0.0018,  0.0044, -0.0052],\n","                     device='cuda:0')),\n","             ('transformer_decoder.layers.0.norm2.weight',\n","              tensor([1.0149, 1.0052, 0.6802,  ..., 0.9987, 0.9984, 1.0009], device='cuda:0')),\n","             ('transformer_decoder.layers.0.norm2.bias',\n","              tensor([-0.0056,  0.0039,  0.0036,  ..., -0.0015,  0.0039, -0.0049],\n","                     device='cuda:0')),\n","             ('transformer_decoder.layers.0.norm3.weight',\n","              tensor([0.9917, 0.9941, 1.2507,  ..., 0.9989, 0.9984, 0.9977], device='cuda:0')),\n","             ('transformer_decoder.layers.0.norm3.bias',\n","              tensor([-0.0122,  0.0062,  0.3861,  ..., -0.0016,  0.0035, -0.0046],\n","                     device='cuda:0')),\n","             ('transformer_decoder.layers.1.self_attn.in_proj_weight',\n","              tensor([[ 0.0123,  0.0183,  0.0107,  ...,  0.0191,  0.0062, -0.0060],\n","                      [ 0.0137, -0.0067, -0.0017,  ...,  0.0051,  0.0201,  0.0049],\n","                      [ 0.0100, -0.0140, -0.0087,  ..., -0.0189,  0.0056, -0.0045],\n","                      ...,\n","                      [ 0.0105,  0.0016, -0.0045,  ...,  0.0055, -0.0133,  0.0177],\n","                      [-0.0180,  0.0180, -0.0061,  ...,  0.0043,  0.0213, -0.0119],\n","                      [ 0.0030, -0.0144,  0.0279,  ..., -0.0022,  0.0078,  0.0106]],\n","                     device='cuda:0')),\n","             ('transformer_decoder.layers.1.self_attn.in_proj_bias',\n","              tensor([-2.1324e-04,  1.1848e-04, -9.3862e-04,  ..., -5.2794e-05,\n","                      -5.2321e-04, -5.2547e-04], device='cuda:0')),\n","             ('transformer_decoder.layers.1.self_attn.out_proj.weight',\n","              tensor([[-0.0087,  0.0174, -0.0082,  ..., -0.0030, -0.0036,  0.0005],\n","                      [ 0.0065, -0.0011,  0.0119,  ...,  0.0016, -0.0053, -0.0133],\n","                      [-0.0192,  0.0070, -0.0010,  ..., -0.0038,  0.0107, -0.0098],\n","                      ...,\n","                      [ 0.0110, -0.0031,  0.0089,  ..., -0.0019, -0.0151, -0.0123],\n","                      [-0.0061,  0.0125,  0.0098,  ...,  0.0154, -0.0152, -0.0019],\n","                      [-0.0157, -0.0047, -0.0098,  ...,  0.0094,  0.0126, -0.0159]],\n","                     device='cuda:0')),\n","             ('transformer_decoder.layers.1.self_attn.out_proj.bias',\n","              tensor([-0.0012, -0.0003,  0.1121,  ..., -0.0016,  0.0002, -0.0013],\n","                     device='cuda:0')),\n","             ('transformer_decoder.layers.1.multihead_attn.in_proj_weight',\n","              tensor([[ 0.0146,  0.0028,  0.0349,  ..., -0.0074, -0.0039, -0.0177],\n","                      [ 0.0080,  0.0036,  0.0015,  ...,  0.0088, -0.0123, -0.0159],\n","                      [ 0.0187, -0.0058,  0.0007,  ..., -0.0013, -0.0089,  0.0171],\n","                      ...,\n","                      [ 0.0116, -0.0067, -0.0021,  ..., -0.0188, -0.0097,  0.0049],\n","                      [ 0.0012,  0.0013, -0.0095,  ..., -0.0196, -0.0105, -0.0117],\n","                      [ 0.0168, -0.0128, -0.0063,  ...,  0.0070, -0.0062,  0.0149]],\n","                     device='cuda:0')),\n","             ('transformer_decoder.layers.1.multihead_attn.in_proj_bias',\n","              tensor([ 0.0007,  0.0003,  0.0002,  ..., -0.0017, -0.0006,  0.0002],\n","                     device='cuda:0')),\n","             ('transformer_decoder.layers.1.multihead_attn.out_proj.weight',\n","              tensor([[-9.1858e-03,  3.0756e-03, -1.3042e-02,  ...,  1.4014e-02,\n","                       -8.3072e-03, -4.5288e-03],\n","                      [ 9.9065e-03,  3.1755e-03, -2.4439e-03,  ..., -7.3873e-03,\n","                        1.4646e-02,  1.6019e-02],\n","                      [ 8.6318e-03, -1.5811e-02, -8.8703e-04,  ...,  6.7861e-05,\n","                        8.3752e-03,  7.1998e-03],\n","                      ...,\n","                      [-8.6333e-03, -1.7187e-02,  1.2045e-02,  ...,  1.3027e-02,\n","                       -1.3432e-02, -3.0828e-03],\n","                      [-2.3342e-04, -6.7985e-03,  3.6107e-03,  ..., -1.2089e-02,\n","                        1.3969e-02, -1.0095e-02],\n","                      [ 6.2024e-03, -1.4189e-02,  1.0678e-02,  ...,  1.1430e-02,\n","                       -4.8039e-03, -1.0113e-02]], device='cuda:0')),\n","             ('transformer_decoder.layers.1.multihead_attn.out_proj.bias',\n","              tensor([-0.0037, -0.0014, -0.0461,  ..., -0.0038, -0.0005, -0.0017],\n","                     device='cuda:0')),\n","             ('transformer_decoder.layers.1.linear1.weight',\n","              tensor([[-1.1413e-02,  8.8471e-03, -1.9871e-02,  ...,  4.9861e-03,\n","                        1.0774e-02, -3.6430e-03],\n","                      [-3.3468e-04, -3.0785e-03, -1.7630e-02,  ...,  9.0969e-03,\n","                       -8.9910e-05,  6.6177e-04],\n","                      [-2.2263e-03,  1.5419e-02, -1.9715e-02,  ...,  1.0480e-02,\n","                       -6.8640e-03,  6.7526e-03],\n","                      ...,\n","                      [-8.3732e-03,  1.1393e-02, -1.8413e-02,  ..., -1.6270e-03,\n","                        5.8376e-03, -3.4434e-03],\n","                      [-1.0838e-02, -1.0292e-02,  6.2546e-03,  ..., -9.6784e-03,\n","                       -7.3385e-03,  1.0101e-02],\n","                      [-8.2682e-03, -2.5048e-03, -1.0761e-02,  ...,  1.1455e-02,\n","                        4.3772e-03,  3.9053e-03]], device='cuda:0')),\n","             ('transformer_decoder.layers.1.linear1.bias',\n","              tensor([-1.1328e-02,  5.0156e-03,  8.9446e-03, -1.5888e-02, -2.3663e-03,\n","                      -1.0245e-02, -1.4484e-02, -7.6929e-03,  1.1950e-04, -2.2228e-02,\n","                       1.0851e-02,  1.3682e-02,  6.7679e-03, -1.0780e-02, -5.0920e-03,\n","                       8.1965e-03, -1.7313e-02, -3.3441e-04,  1.0146e-03, -4.6646e-04,\n","                      -1.2372e-02, -6.1492e-03, -1.2928e-02, -5.0152e-04,  1.9134e-03,\n","                       1.2652e-02, -1.3400e-02,  1.0357e-02, -1.6229e-02, -1.6194e-02,\n","                       1.9357e-03, -1.6132e-02, -6.1027e-03,  9.5581e-03,  7.8115e-03,\n","                       2.2983e-03, -1.8808e-03, -1.6478e-02, -1.8488e-02, -2.1187e-02,\n","                      -1.0480e-02,  1.0056e-02,  9.9958e-03, -1.2097e-02, -3.3512e-03,\n","                       3.1783e-03,  1.7261e-03,  9.4875e-04,  8.1222e-03,  4.8339e-03,\n","                      -1.2247e-02, -1.4737e-02,  5.0214e-03, -1.8938e-02,  8.3480e-03,\n","                      -1.1356e-02,  6.9385e-03, -6.4998e-03,  5.8037e-03, -2.4675e-03,\n","                       1.8625e-03, -1.3592e-03, -1.3973e-02, -6.7064e-03, -1.1059e-03,\n","                       8.5343e-03, -9.4793e-03,  6.9054e-03, -1.1194e-02,  4.0232e-03,\n","                       1.3038e-02,  1.0716e-02, -1.6406e-02, -3.1560e-03, -1.2059e-02,\n","                       5.9675e-03, -1.6596e-02,  4.1508e-03,  1.2975e-02, -6.0784e-03,\n","                       1.0641e-02,  1.0524e-02,  6.0359e-03,  1.0881e-02, -2.5592e-03,\n","                      -1.7927e-02, -1.6488e-02,  5.3595e-03, -1.5972e-02,  1.0779e-02,\n","                      -9.5098e-03,  8.5233e-03, -4.3921e-03, -9.7532e-03,  3.9913e-04,\n","                      -1.7367e-02, -4.2758e-03,  7.8128e-03, -9.0852e-03, -8.1240e-03,\n","                       1.1738e-02,  2.5680e-04, -1.6805e-02,  8.9272e-03, -1.1044e-02,\n","                       2.6062e-03, -1.6684e-02,  8.4111e-03, -5.8855e-03,  1.0313e-02,\n","                      -1.5955e-02, -1.3017e-02,  4.7697e-03,  8.0972e-03,  5.7201e-03,\n","                      -1.4673e-03, -5.1876e-03, -1.1333e-02, -6.9792e-03, -1.3779e-02,\n","                      -1.0409e-02, -2.5421e-03, -5.3837e-03,  6.7575e-05, -1.6802e-02,\n","                      -1.6537e-02,  3.0596e-03,  7.9743e-03, -9.2760e-03, -1.7995e-02,\n","                      -4.1793e-03, -2.1625e-02, -3.5394e-03, -7.8143e-03, -1.6887e-03,\n","                      -8.9698e-03, -1.7395e-02,  5.9113e-03, -1.3792e-02, -1.7583e-02,\n","                      -1.9544e-02, -1.0096e-02, -2.0045e-02, -1.6962e-02, -1.8685e-03,\n","                       8.5260e-04, -5.7001e-04,  1.5017e-03,  1.2630e-02, -1.7198e-02,\n","                       1.1079e-02,  7.2943e-03, -1.6412e-02,  5.2059e-04,  1.2739e-02,\n","                       9.8909e-03, -1.9339e-02, -1.8899e-02, -8.3563e-03,  1.2135e-02,\n","                       1.1519e-02, -7.1666e-03,  1.0052e-02, -5.5828e-03,  1.7223e-03,\n","                      -1.3587e-02, -9.3946e-03, -1.7540e-02, -1.6358e-02,  1.4474e-03,\n","                      -1.9672e-03, -1.0342e-02, -8.6245e-03, -5.2287e-03,  7.0115e-03,\n","                       1.5368e-02,  8.6394e-03,  1.2234e-02, -6.0022e-03, -6.8423e-03,\n","                       1.1855e-02, -1.8480e-05, -1.0154e-02, -8.3213e-03, -1.5548e-02,\n","                       1.2730e-02, -8.3505e-03,  6.6989e-03, -8.3595e-03, -1.4632e-02,\n","                      -1.4885e-02,  7.1257e-03, -1.1980e-03, -1.7690e-02, -6.9402e-03,\n","                       8.4318e-03,  4.6550e-03, -9.2655e-03, -1.7924e-02,  6.5329e-03,\n","                       2.7439e-04,  1.5957e-02, -1.7740e-02, -8.0273e-05,  1.3259e-02,\n","                       1.4129e-02, -1.1956e-02, -4.5910e-03, -1.7486e-02,  5.9489e-03,\n","                       4.9605e-03, -1.0514e-02,  9.5215e-03, -7.2329e-03,  1.2710e-02,\n","                       2.3794e-03,  1.3523e-02, -1.0145e-02, -1.9376e-02,  1.2262e-02,\n","                      -1.3930e-02,  3.9509e-03, -5.1534e-03,  1.0924e-02,  4.0043e-03,\n","                       5.0441e-03,  9.8657e-03, -1.3823e-02, -1.0239e-02, -1.0120e-02,\n","                      -3.1805e-03,  1.0948e-02,  8.4730e-03, -1.7725e-02, -2.5328e-03,\n","                       1.1291e-02,  1.0486e-02, -3.8891e-03,  4.5053e-03,  3.2516e-03,\n","                       6.4917e-04,  7.8542e-03, -9.7449e-03, -1.8220e-02,  8.9922e-03,\n","                       3.5066e-03, -6.9555e-03,  6.8328e-03,  1.3487e-03, -6.6882e-03,\n","                       1.5194e-02,  1.1194e-02, -2.4177e-03,  7.1866e-03, -1.4461e-02,\n","                       9.4325e-03, -1.0434e-02, -2.8578e-03, -2.5626e-03,  7.8937e-03,\n","                      -3.9805e-03, -1.7147e-02, -1.4942e-02, -2.4743e-03, -1.6950e-02,\n","                      -7.3937e-03,  4.4885e-03, -6.2247e-03,  6.0936e-03, -1.4032e-02,\n","                      -2.5560e-03,  9.5085e-03,  4.1454e-03, -1.8844e-03,  1.1731e-02,\n","                      -1.3239e-02, -1.0614e-02, -5.5526e-03, -6.3804e-03, -6.2415e-03,\n","                      -1.4949e-02, -1.2331e-02, -2.8605e-03,  2.8991e-03,  5.9970e-03,\n","                      -1.6665e-02, -8.6969e-03, -2.5540e-03, -2.0507e-02,  1.6301e-03,\n","                      -1.4896e-02,  4.2312e-03, -5.7945e-03, -1.5362e-02, -1.2860e-02,\n","                      -3.8719e-03,  3.9641e-03, -1.2963e-02, -1.3179e-02, -1.9014e-02,\n","                      -4.1742e-03,  4.0272e-04, -1.6524e-02,  6.4767e-03, -5.4399e-03,\n","                      -1.2250e-04,  3.6110e-03,  1.6431e-04, -4.6528e-03, -1.1475e-02,\n","                       1.2465e-02, -2.0333e-03, -1.5089e-02, -1.4255e-02,  4.0875e-03,\n","                      -4.7537e-03,  2.9591e-04, -8.3361e-03,  5.5956e-03,  5.3656e-03,\n","                       3.8941e-03,  8.0150e-03, -7.3662e-03, -1.0521e-02, -1.4202e-02,\n","                      -1.2697e-02, -1.0989e-02, -1.1754e-02, -1.5788e-02, -6.3824e-03,\n","                      -8.4341e-05, -1.8219e-02,  7.7752e-03, -1.2421e-02, -1.5319e-02,\n","                      -2.7481e-02,  9.5058e-03,  5.6356e-03, -5.1673e-03, -8.2005e-03,\n","                       8.5671e-03,  9.6864e-03, -5.8733e-03, -1.3028e-02, -1.2231e-02,\n","                      -7.5204e-03,  5.7493e-04, -3.0122e-03, -4.5176e-03,  7.6687e-03,\n","                       1.1127e-02,  1.4098e-02, -2.4480e-03, -1.2467e-02, -1.6672e-02,\n","                      -1.5304e-03,  8.2678e-03, -2.4152e-03, -1.7057e-02, -1.4948e-02,\n","                       5.8237e-03, -4.8467e-04, -9.8497e-04,  1.2913e-02, -6.1717e-04,\n","                      -1.0147e-02,  1.4765e-02,  1.0348e-02,  8.1759e-03,  7.0251e-03,\n","                      -1.7857e-02,  9.2517e-04, -1.3065e-02, -4.9096e-03, -1.7027e-02,\n","                      -1.7599e-02, -1.0961e-02, -1.5911e-02, -5.2647e-03, -1.8651e-02,\n","                       2.6964e-03, -4.8579e-03, -3.5928e-04, -4.2246e-03,  1.1706e-02,\n","                      -1.3787e-03, -9.8262e-03, -1.3976e-02, -5.0956e-03, -1.5980e-02,\n","                       1.1734e-02, -1.2980e-02,  6.5367e-03, -2.2622e-03, -2.0669e-03,\n","                      -1.5267e-02, -1.1152e-02,  3.0688e-04,  1.0842e-02, -1.2579e-02,\n","                      -8.8233e-03,  2.3107e-03,  1.2067e-02, -1.1337e-02,  1.2462e-02,\n","                       5.4936e-03, -3.9504e-03, -1.7462e-03,  2.8849e-04,  5.8672e-03,\n","                      -1.8017e-02,  3.7499e-03,  7.3787e-03,  5.0526e-03, -2.9684e-03,\n","                       1.2366e-02, -4.9212e-03,  8.3605e-03, -1.0276e-02, -5.1645e-03,\n","                      -2.5695e-03, -1.4895e-02,  1.0145e-02,  9.9486e-03, -1.3339e-03,\n","                       1.4211e-02, -1.1429e-02, -1.4826e-02,  1.2170e-02, -5.8888e-03,\n","                      -1.2757e-02, -1.7531e-02,  1.2828e-02,  4.6999e-04,  3.8027e-03,\n","                       1.2515e-02,  1.1811e-03, -8.9009e-03,  1.8536e-03,  1.4250e-02,\n","                      -2.3354e-03,  1.2459e-02, -1.3434e-02, -2.1451e-02,  4.6275e-03,\n","                       1.1007e-02,  1.2433e-02, -5.9912e-03, -8.9042e-03,  1.3426e-02,\n","                       1.2950e-03, -1.1535e-02,  1.0335e-03,  1.0528e-02, -1.4455e-02,\n","                       7.4793e-03, -7.1861e-03,  5.3977e-03,  1.2327e-02, -1.3734e-02,\n","                       1.4811e-02, -1.2118e-03,  1.3816e-02,  7.0171e-03,  1.3439e-02,\n","                       1.6049e-02, -1.3415e-02,  1.8805e-04, -5.1966e-03,  8.3603e-03,\n","                      -1.4092e-02,  1.3109e-02,  7.5506e-03, -3.5641e-03, -1.5585e-02,\n","                      -5.4585e-03, -1.9027e-03,  1.1340e-02, -1.4100e-02, -1.7652e-02,\n","                       4.2434e-03, -1.3823e-02,  6.7686e-03, -9.4285e-03, -1.0057e-03,\n","                      -2.2826e-03, -8.2919e-03,  1.6245e-03, -3.5512e-04,  1.0431e-03,\n","                       4.3575e-03,  3.2652e-03, -1.4326e-03, -1.5236e-02, -1.2374e-02,\n","                       3.7389e-03,  3.5287e-03,  9.0875e-03, -2.4392e-03,  3.2203e-03,\n","                      -1.6911e-02, -9.4822e-03,  1.3548e-02,  2.4667e-03,  7.1417e-03,\n","                      -1.7433e-02, -6.7234e-03, -1.4369e-02, -1.7183e-02,  1.1704e-03,\n","                       1.1500e-02,  3.2749e-03], device='cuda:0')),\n","             ('transformer_decoder.layers.1.linear2.weight',\n","              tensor([[ 0.0123, -0.0223,  0.0204,  ...,  0.0058, -0.0363, -0.0040],\n","                      [ 0.0021, -0.0352, -0.0021,  ...,  0.0171,  0.0061, -0.0405],\n","                      [-0.0122,  0.4457,  0.0035,  ...,  0.0013, -0.0174, -0.0163],\n","                      ...,\n","                      [ 0.0376, -0.2425, -0.0019,  ..., -0.0220, -0.0185,  0.0132],\n","                      [ 0.0130, -0.0178, -0.0101,  ..., -0.0076, -0.0100,  0.0295],\n","                      [ 0.0133, -0.0736, -0.0047,  ..., -0.0278, -0.0112, -0.0440]],\n","                     device='cuda:0')),\n","             ('transformer_decoder.layers.1.linear2.bias',\n","              tensor([ 0.0110,  0.0054,  0.1022,  ...,  0.0066, -0.0099, -0.0200],\n","                     device='cuda:0')),\n","             ('transformer_decoder.layers.1.norm1.weight',\n","              tensor([1.0007, 1.0035, 1.9837,  ..., 1.0006, 1.0005, 0.9998], device='cuda:0')),\n","             ('transformer_decoder.layers.1.norm1.bias',\n","              tensor([-0.0036, -0.0023,  0.2262,  ..., -0.0032, -0.0005, -0.0015],\n","                     device='cuda:0')),\n","             ('transformer_decoder.layers.1.norm2.weight',\n","              tensor([ 0.9999,  1.0023, -1.4727,  ...,  1.0009,  0.9995,  0.9999],\n","                     device='cuda:0')),\n","             ('transformer_decoder.layers.1.norm2.bias',\n","              tensor([-0.0049, -0.0023, -0.1312,  ..., -0.0055, -0.0030, -0.0031],\n","                     device='cuda:0')),\n","             ('transformer_decoder.layers.1.norm3.weight',\n","              tensor([ 1.0005,  1.0049, -1.9000,  ...,  1.0130,  0.8950,  1.0115],\n","                     device='cuda:0')),\n","             ('transformer_decoder.layers.1.norm3.bias',\n","              tensor([-0.0862, -0.0812,  7.5744,  ..., -0.0384, -0.1513, -0.0726],\n","                     device='cuda:0'))])"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"Up3JnDcPuqAb","executionInfo":{"status":"ok","timestamp":1606366183832,"user_tz":-540,"elapsed":2251837,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}}},"source":["def gen_sentence(sentence, src_field, trg_field, model, batch_size):\n","  model.eval()\n","  in_str, out_str, pred, tmp = [], [], [], []\n","  length = len(sentence)\n","\n","  with torch.no_grad():\n","    for _, batch in enumerate(sentence):\n","      src = batch.SRC\n","      trg = batch.TRG\n","      output = model(src, trg)\n","          \n","      for j in range(min(length, batch_size)):\n","        _, topi = output.data.topk(1)\n","        _, topi_s = output.data.topk(2) \n","        for k in range(topi.size()[1]):\n","          if topi[:, k][0] == trg_field.vocab.stoi[\"<eos>\"]:\n","            for m in range(topi_s.size()[0]):\n","              for l in range(topi_s.size()[1]):\n","                topi[m][l][0] = topi_s[m][l][1]\n","          for i in range(topi.size()[0]):\n","            if trg_field.vocab.itos[topi[:, k][i]] == \"<eos>\":\n","              break\n","            tmp.append(trg_field.vocab.itos[topi[:, k][i]])\n","          pred.append(tmp)\n","          tmp = []\n","        #print(src.size())\n","        in_str.append([src_field.vocab.itos[i.item()] for i in src[:,j] if src_field.vocab.itos[i.item()] != \"<eos>\"])\n","        out_str.append([trg_field.vocab.itos[i.item()] for i in trg[:,j] if trg_field.vocab.itos[i.item()] != \"<eos>\"])\n","      \n","  return in_str, out_str, pred"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"aoroAe8Uuq6A","executionInfo":{"status":"ok","timestamp":1606366304757,"user_tz":-540,"elapsed":2372756,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}}},"source":["# 中間発表時にはテストデータは用いない\n","test_in, test_out, test_pred = [],[],[]\n","test_in, test_out, test_pred = gen_sentence(test_iter, SRC, SRC, best_model, test_batch_size)\n","val_in, val_out, val_pred = [],[],[]\n","val_in, val_out, val_pred = gen_sentence(val_iter, SRC, SRC, model, eval_batch_size)\n","train_in, train_out, train_pred = [],[],[]\n","train_in, train_out, train_pred = gen_sentence(train_iter, SRC, SRC, model, train_batch_size)"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"mlA-NqUEIjck","executionInfo":{"status":"ok","timestamp":1606366304762,"user_tz":-540,"elapsed":2372755,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}}},"source":["import pandas as pd"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"wBlexgq5IlSW","executionInfo":{"status":"ok","timestamp":1606366304763,"user_tz":-540,"elapsed":2372742,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}}},"source":["def convert_list_to_df(in_list, out_list, pred_list):\n","  row = []\n","  for i in range(len(in_list)):\n","    batch_input = in_list[i]\n","    batch_output = out_list[i]\n","    batch_pred = pred_list[i]\n","    input = [j for j in batch_input if j != \"<pad>\" and j != \"<sos>\" and j != \"<eos>\" and j != \"<unk>\"]\n","    output = [j for j in batch_output if j != \"<pad>\" and j != \"<sos>\" and j != \"<eos>\" and j != \"<unk>\"]\n","    predict = [j for j in batch_pred if j != \"<pad>\" and j != \"<sos>\" and j != \"<eos>\" and j != \"<unk>\"]\n","    input_str = \"\".join(input)\n","    output_str =\"\".join(output)\n","    predict_str = \"\".join(predict)\n","    row.append([input_str, output_str, predict_str])\n","\n","  df = pd.DataFrame(row, columns=[\"input\",\"answer\",\"predict\"])\n","  df = df.sort_values('input')\n","  return df"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"6pVoCwc_Inol","executionInfo":{"status":"ok","timestamp":1606366304764,"user_tz":-540,"elapsed":2372735,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}}},"source":["train_df = convert_list_to_df(train_in, train_out, train_pred)\n","val_df = convert_list_to_df(val_in, val_out, val_pred)\n","test_df = convert_list_to_df(test_in, test_out, test_pred)"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"ptcsBPKZi-0t","executionInfo":{"status":"ok","timestamp":1606366304765,"user_tz":-540,"elapsed":2372725,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}}},"source":["df_s = pd.concat([train_df, test_df]).sort_values('input')"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Yd2nXK5jJKT","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1606366304766,"user_tz":-540,"elapsed":2372718,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}},"outputId":"2602353e-fe95-43fd-c457-696cf7f8e2bc"},"source":["df_s.head(10)"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>input</th>\n","      <th>answer</th>\n","      <th>predict</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>729</th>\n","      <td>15分ぐらいまで</td>\n","      <td>あっ</td>\n","      <td>うーんそーー</td>\n","    </tr>\n","    <tr>\n","      <th>84</th>\n","      <td>15分前に事務所に</td>\n","      <td>あっ</td>\n","      <td>うーん</td>\n","    </tr>\n","    <tr>\n","      <th>1049</th>\n","      <td>18歳以上でないとあのやる</td>\n","      <td>うーん</td>\n","      <td>そそーー</td>\n","    </tr>\n","    <tr>\n","      <th>1655</th>\n","      <td>1センチ5ミリぐらいの</td>\n","      <td>そうです</td>\n","      <td>うーんそー</td>\n","    </tr>\n","    <tr>\n","      <th>1147</th>\n","      <td>20代だいぶ昔の話ですけれども20代の後半に仲良し3人組で女性ですがあのまー安い宿を使って軽...</td>\n","      <td>あ</td>\n","      <td>そーーーねー</td>\n","    </tr>\n","    <tr>\n","      <th>1135</th>\n","      <td>20代だいぶ昔の話ですけれども20代の後半に仲良し3人組で女性ですがあのまー安い宿を使って軽...</td>\n","      <td>旅行</td>\n","      <td>へえー</td>\n","    </tr>\n","    <tr>\n","      <th>295</th>\n","      <td>20代だいぶ昔の話ですけれども20代の後半に仲良し3人組で女性ですがあのまー安い宿を使って軽...</td>\n","      <td>あ</td>\n","      <td>そうはーーねーねーねーねー</td>\n","    </tr>\n","    <tr>\n","      <th>1058</th>\n","      <td>20年代戦後間もない</td>\n","      <td>二十年代戦後ですね</td>\n","      <td>へえーーーねーねーねー</td>\n","    </tr>\n","    <tr>\n","      <th>2127</th>\n","      <td>2つのおはじきを</td>\n","      <td>はいうん二つの</td>\n","      <td>うーんそーーねーねー</td>\n","    </tr>\n","    <tr>\n","      <th>736</th>\n","      <td>2年で辞めましてその後文化服装学院の大学の</td>\n","      <td>あはい</td>\n","      <td>へえー</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                  input  ...        predict\n","729                                            15分ぐらいまで  ...         うーんそーー\n","84                                            15分前に事務所に  ...            うーん\n","1049                                      18歳以上でないとあのやる  ...           そそーー\n","1655                                        1センチ5ミリぐらいの  ...          うーんそー\n","1147  20代だいぶ昔の話ですけれども20代の後半に仲良し3人組で女性ですがあのまー安い宿を使って軽...  ...         そーーーねー\n","1135  20代だいぶ昔の話ですけれども20代の後半に仲良し3人組で女性ですがあのまー安い宿を使って軽...  ...            へえー\n","295   20代だいぶ昔の話ですけれども20代の後半に仲良し3人組で女性ですがあのまー安い宿を使って軽...  ...  そうはーーねーねーねーねー\n","1058                                         20年代戦後間もない  ...    へえーーーねーねーねー\n","2127                                           2つのおはじきを  ...     うーんそーーねーねー\n","736                               2年で辞めましてその後文化服装学院の大学の  ...            へえー\n","\n","[10 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"8870OnPUjK13","executionInfo":{"status":"ok","timestamp":1606366305280,"user_tz":-540,"elapsed":2373212,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}}},"source":["df_s.to_csv(filename)"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"mDs4JDh-qAf0","executionInfo":{"status":"ok","timestamp":1606366305281,"user_tz":-540,"elapsed":2373204,"user":{"displayName":"守山慧","photoUrl":"","userId":"18276650506428796801"}}},"source":[""],"execution_count":26,"outputs":[]}]}