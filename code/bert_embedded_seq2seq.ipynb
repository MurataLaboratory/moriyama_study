{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bert_embedded_seq2seq.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPNR8u5o5EciJqG3/28PzbU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Fll285jLFATl"},"source":["# 参考文献\n","\n","[Visualizing Bert Embeddings](https://krishansubudhi.github.io/deeplearning/2020/08/27/bert-embeddings-visualization.html)"]},{"cell_type":"code","metadata":{"id":"oNAKpQRGE82b"},"source":["import torchtext\n","print(torchtext.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fy2mkQTcjnSZ"},"source":["print('hello world')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GOwNLm4Ujtk2"},"source":["from google.colab import drive\n","drive.mount('/content/dirve')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CdSVnt42jveG"},"source":["!pip install transformers fugashi mecab-python3 ipadic"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UhUPukN01OSp"},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","from torchtext.data import Field, BucketIterator\n","\n","import numpy as np\n","\n","import random\n","import math\n","import time\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pKPg65651YwJ"},"source":["import torchtext\n","import torch\n","from torchtext import data\n","from torchtext import datasets\n","import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YIFi15Pxkx7-"},"source":["from transformers import BertJapaneseTokenizer, BertForPreTraining\n","tok = BertJapaneseTokenizer.from_pretrained('cl-tohoku/bert-base-japanese')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q0V-tqIM-bbC"},"source":["def tokenizer(text):\n","  return tok.tokenize(text)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4VoE6g6Wlb0F"},"source":["sent = \"今日は雨だけど、明日は晴れそう。今日は全然勝てなかった\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q5teti8t2T0_"},"source":["tokenizer(sent)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X_hhJrYExduA"},"source":["SRC = data.Field(sequential=True, tokenize = tokenizer, init_token='<sos>', eos_token='<eos>', lower = True)\n","#TRG = data.Field(sequential=True, tokenize = tokenizer, init_token='<sos>', eos_token='<eos>', lower = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m7dT_GJr31Ju"},"source":["\"\"\"\n","train, val, test = data.TabularDataset.splits(\n","        path=\"/content/dirve/My Drive/Colab Notebooks/data/\", train='train.tsv',\n","        validation='val.tsv', test='test.tsv', format='tsv',\n","        fields=[('SRC', SRC), ('TRG', SRC)])\n","\"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1x1PyyxS17_F"},"source":["train, val, test = data.TabularDataset.splits(\n","        path=\"/content/dirve/My Drive/Colab Notebooks/data/\", train='one_train.tsv',\n","        validation='one_val.tsv', test='one_test.tsv', format='tsv',\n","        fields=[('SRC', SRC), ('TRG', SRC)])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uMnpIaSa2Bkw"},"source":["SRC.build_vocab(train)\n","#TRG.build_vocab(train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vtgYhcjsBf8t"},"source":["bert_model = BertForPreTraining.from_pretrained(\n","    \"cl-tohoku/bert-base-japanese\", # 日本語Pre trainedモデルの指定\n","    num_labels = 2, # ラベル数（今回はBinayなので2、数値を増やせばマルチラベルも対応可）\n","    output_attentions = False, # アテンションベクトルを出力するか\n","    output_hidden_states = True, # 隠れ層を出力するか\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zto56U_wWHix"},"source":["bert_model.resize_token_embeddings(len(SRC.vocab))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iTt0dy00WMuC"},"source":["bert_model.get_input_embeddings()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vFRsvghIWVYR"},"source":["bert_model.get_output_embeddings()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ilTB4ZdpMCD4"},"source":["\"\"\"\n","train_batch_size = 50\n","test_batch_size = 10\n","eval_batch_size = 2\n","train_iter, val_iter, test_iter = data.BucketIterator.splits((train, val, test), sort = False,  batch_sizes = (train_batch_size,eval_batch_size, test_batch_size), device= device)]\n","\"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"guAZOeqw8S4P"},"source":["train_batch_size = 100\n","test_batch_size = 2\n","eval_batch_size = 100\n","train_iter, val_iter, test_iter = data.BucketIterator.splits((train, val, test), sort = False,  batch_sizes = (train_batch_size,eval_batch_size, test_batch_size), device= device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n5p6myVPNRoV"},"source":["class Encoder(nn.Module):\n","  def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n","    super().__init__()\n","    self.hid_dim = hid_dim\n","    self.n_layers = n_layers\n","    #self.embedding = nn.Embedding(input_dim, emb_dim)\n","    self.embedding = bert_model.get_input_embeddings()\n","    self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n","    self.dropout = nn.Dropout(dropout)\n","\n","  def forward(self, src):\n","    embedded = self.dropout(self.embedding(src))\n","    outputs, (hidden, cell) = self.rnn(embedded)\n","    return hidden, cell"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lkYqVfacNUnq"},"source":["class Decoder(nn.Module):\n","  def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n","    super().__init__()\n","    self.output_dim = output_dim\n","    self.hid_dim = hid_dim\n","    self.n_layers = n_layers\n","\n","    #self.embedding = nn.Embedding(output_dim, emb_dim)\n","    self.embedding = bert_model.get_input_embeddings()\n","    self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n","\n","    #self.fc_out = nn.Linear(hid_dim, output_dim)\n","    self.fc_out = bert_model.get_output_embeddings()\n","    self.dropout = nn.Dropout(dropout)\n","  \n","  def forward(self, input, hidden, cell):\n","    input = input.unsqueeze(0)\n","    embedded = self.dropout(self.embedding(input))\n","    output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n","    #print(output.squeeze(0).size())\n","    prediction = self.fc_out(output.squeeze(0))\n","\n","    return prediction, hidden, cell"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aDd0u67wNWXp"},"source":["class Seq2Seq(nn.Module):\n","  def __init__(self, encoder, decoder, device):\n","    super().__init__()\n","    self.encoder = encoder\n","    self.decoder = decoder\n","    self.device = device\n","\n","  def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n","    batch_size = trg.shape[1]\n","    trg_len = trg.shape[0]\n","    trg_vocab_size = self.decoder.output_dim\n","\n","    outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n","\n","    hidden, cell = self.encoder(src)\n","\n","    output = trg[0,:]\n","    #print(input)\n","\n","    for t in range(1, trg_len):\n","      output, hidden, cell = self.decoder(output, hidden, cell)\n","\n","      outputs[t] = output\n","      teacher_force = random.random() < teacher_forcing_ratio\n","      top1 = output.argmax(1)\n","      output = (trg[t] if teacher_force else top1)\n","    \n","    return outputs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"md_3rgFiNYOI"},"source":["INPUT_DIM = len(SRC.vocab)\n","# OUTPUT_DIM = 3996\n","OUTPUT_DIM = 3454\n","ENC_EMB_DIM = 768\n","DEC_EMB_DIM = 768\n","ENC_HID_DIM = 768\n","DEC_HID_DIM = 768\n","N_LAYERS = 1\n","ENC_DROPOUT = 0.5\n","DEC_DROPOUT = 0.5\n","\n","enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, N_LAYERS, ENC_DROPOUT)\n","dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, DEC_HID_DIM, N_LAYERS, DEC_DROPOUT)\n","\n","model = Seq2Seq(enc, dec, device).to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5gB1IPOOPYZ0"},"source":["def init_weights(m):\n","    for name, param in m.named_parameters():\n","        nn.init.uniform_(param.data, -0.08, 0.08)\n","\n","model.apply(init_weights)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-uPBQjfDQauC"},"source":["optimizer = optim.Adam(model.parameters())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lfbg-dTYQbK6"},"source":["TRG_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n","\n","criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lYFXEtIYTWrR"},"source":["def train(model, iterator, optimizer, criterion, clip):\n","  model.train()\n","\n","  epoch_loss = 0\n","\n","  for i, batch in enumerate(iterator):\n","    src = batch.SRC\n","    trg = batch.TRG\n","    optimizer.zero_grad()\n","\n","    output = model(src, trg)\n","\n","    output_dim = output.shape[-1]\n","    output = output[:].view(-1, output_dim)\n","    trg = trg[:].view(-1)\n","\n","    loss = criterion(output, trg)\n","    loss.backward()\n","    torch.nn.utils.clip_grad_norm(model.parameters(), clip)\n","    optimizer.step()\n","\n","    epoch_loss += loss.item()\n","\n","  return epoch_loss / len(iterator)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7wbEPozHTYtW"},"source":["def evaluate(model, iterator, criterion):\n","  model.eval()\n","\n","  epoch_loss = 0\n","\n","  with torch.no_grad():\n","\n","    for i, batch in enumerate(iterator):\n","\n","      src = batch.SRC\n","      trg = batch.TRG\n","\n","      output = model(src, trg)\n","\n","      output_dim = output.shape[-1]\n","\n","      output = output[:].view(-1, output_dim)\n","      trg = trg[:].view(-1)\n","\n","      loss = criterion(output, trg)\n","      epoch_loss += loss.item()\n","\n","    return epoch_loss / len(iterator)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b4SoIGbaTast"},"source":["def epoch_time(start_time, end_time):\n","  elapsed_time = end_time - start_time\n","  elapsed_mins = int(elapsed_time / 60)\n","  elapsed_secs = int(elapsed_time - (elapsed_mins*60))\n","  return elapsed_mins, elapsed_secs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"013GE2MATch3"},"source":["epochs = 100\n","clip = 1\n","#def  model_train(epochs, clip):\n","best_valid_loss = float('inf')\n","best_model = None\n","\n","for epoch in range(epochs):\n","    \n","    start_time = time.time()\n","    \n","    train_loss = train(model, train_iter, optimizer, criterion, clip)\n","    valid_loss = evaluate(model, val_iter, criterion)\n","    \n","    end_time = time.time()\n","    \n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","    \n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        #torch.save(model.state_dict(), '/content/dirve/My Drive/Colab Notebooks/model/bert_embedded_seq2seq.pth')\n","        best_model = model\n","    \n","    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jHH4C93kTOz9"},"source":["torch.save(best_model.state_dict(), '/content/dirve/My Drive/Colab Notebooks/model/bert_embedded_seq2seq.pth')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sFIuAq-7Rac5"},"source":["model.state_dict(torch.load(\"/content/dirve/My Drive/Colab Notebooks/model/bert_embedded_seq2seq.pth\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wE3P67dCRgQ_"},"source":["def gen_sentence(sentence, src_field, trg_field, model, batch_size):\n","  model.eval()\n","  in_str, out_str, pred, tmp = [], [], [], []\n","  length = len(sentence)\n","\n","  with torch.no_grad():\n","    for _, batch in enumerate(sentence):\n","      src = batch.SRC\n","      trg = batch.TRG\n","      output = model(src, trg)\n","          \n","      for j in range(min(length, batch_size)):\n","        _, topi = output.data.topk(1)\n","        _, topi_s = output.data.topk(2) \n","        for k in range(topi.size()[1]):\n","          if topi[:, k][0] == trg_field.vocab.stoi[\"<eos>\"]:\n","            for m in range(topi_s.size()[0]):\n","              for l in range(topi_s.size()[1]):\n","                topi[m][l][0] = topi_s[m][l][1]\n","          for i in range(topi.size()[0]):\n","            if trg_field.vocab.itos[topi[:, k][i]] == \"<eos>\":\n","              break\n","            tmp.append(trg_field.vocab.itos[topi[:, k][i]])\n","          pred.append(tmp)\n","          tmp = []\n","        #print(src.size())\n","        in_str.append([src_field.vocab.itos[i.item()] for i in src[:,j] if src_field.vocab.itos[i.item()] != \"<eos>\"])\n","        out_str.append([trg_field.vocab.itos[i.item()] for i in trg[:,j] if trg_field.vocab.itos[i.item()] != \"<eos>\"])\n","      \n","  return in_str, out_str, pred"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_pnxduKeRiYY"},"source":["# 中間発表時にはテストデータは用いない\n","test_in, test_out, test_pred = [],[],[]\n","test_in, test_out, test_pred = gen_sentence(test_iter, SRC, SRC, best_model, test_batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FTZIya_A-vtw"},"source":["val_in, val_out, val_pred = [],[],[]\n","val_in, val_out, val_pred = gen_sentence(val_iter, SRC, SRC, model, eval_batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PoFjmkYN-50K"},"source":["train_in, train_out, train_pred = [],[],[]\n","train_in, train_out, train_pred = gen_sentence(train_iter, SRC, SRC, model, train_batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aSqikvUh-7k8"},"source":["import pandas as pd\n","def convert_list_to_df(in_list, out_list, pred_list):\n","  row = []\n","  pred = \"\"\n","  for i in range(len(in_list)):\n","    batch_input = in_list[i]\n","    batch_output = out_list[i]\n","    batch_pred = pred_list[i]\n","    input = [j for j in batch_input if j != \"<pad>\" and j != \"<sos>\" and j != \"<eos>\" and j != \"<unk>\" and j != \"[unk]\"]\n","    output = [j for j in batch_output if j != \"<pad>\" and j != \"<sos>\" and j != \"<eos>\" and j != \"<unk>\" and j != \"[unk]\"]\n","    predict = [j for j in batch_pred if j != \"<pad>\" and j != \"<sos>\" and j != \"<eos>\" and j != \"<unk>\" and j != \"[unk]\"]\n","    input_str = \"\".join(input).replace(\"#\", \"\")\n","    output_str =\"\".join(output).replace(\"#\", \"\")\n","    predict_str = \"\".join(predict).replace(\"#\", \"\")\n","    row.append([input_str, output_str, predict_str])\n","    pred = \"\"\n","  df = pd.DataFrame(row, columns=[\"input\",\"answer\",\"predict\"])\n","  df = df.sort_values('input')\n","  return df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-G0cjMGG_CM9"},"source":["train_df = convert_list_to_df(train_in, train_out, train_pred)\n","val_df = convert_list_to_df(val_in, val_out, val_pred)\n","test_df = convert_list_to_df(test_in, test_out, test_pred)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n-1JgHfu_EQT"},"source":["df_s = pd.concat([train_df, test_df])\n","df_s = df_s.sort_values(\"input\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DyQlxXyx8jMy"},"source":["# df_s.to_csv(\"/content/dirve/My Drive/Colab Notebooks/csv/result_bertSeq2seq.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c0Gwd3ePCKKt"},"source":["df_s.to_csv(\"/content/dirve/My Drive/Colab Notebooks/csv/one_result_bertSeq2seq.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ACwq_bXTCZye"},"source":[""],"execution_count":null,"outputs":[]}]}