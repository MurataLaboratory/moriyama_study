{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 680,
     "status": "ok",
     "timestamp": 1606369187517,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "K1fFM0v47L6x",
    "outputId": "989001ed-48c0-4b05-84a6-712a646c92d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print('hello world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3396,
     "status": "ok",
     "timestamp": 1606369190251,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "ptAoqK139GWM",
    "outputId": "5331bf36-0c83-4f39-c6a2-62ba139f9940"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchtext==0.6.0 in c:\\users\\kei\\anaconda3\\envs\\school\\lib\\site-packages (0.6.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kei\\anaconda3\\envs\\school\\lib\\site-packages (from torchtext==0.6.0) (4.47.0)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\kei\\anaconda3\\envs\\school\\lib\\site-packages (from torchtext==0.6.0) (0.1.91)\n",
      "Requirement already satisfied: numpy in c:\\users\\kei\\anaconda3\\envs\\school\\lib\\site-packages (from torchtext==0.6.0) (1.18.5)\n",
      "Requirement already satisfied: requests in c:\\users\\kei\\anaconda3\\envs\\school\\lib\\site-packages (from torchtext==0.6.0) (2.24.0)\n",
      "Requirement already satisfied: six in c:\\users\\kei\\anaconda3\\envs\\school\\lib\\site-packages (from torchtext==0.6.0) (1.15.0)\n",
      "Requirement already satisfied: torch in c:\\users\\kei\\anaconda3\\envs\\school\\lib\\site-packages (from torchtext==0.6.0) (1.5.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\kei\\anaconda3\\envs\\school\\lib\\site-packages (from requests->torchtext==0.6.0) (1.25.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\kei\\anaconda3\\envs\\school\\lib\\site-packages (from requests->torchtext==0.6.0) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kei\\anaconda3\\envs\\school\\lib\\site-packages (from requests->torchtext==0.6.0) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\kei\\anaconda3\\envs\\school\\lib\\site-packages (from requests->torchtext==0.6.0) (2.10)\n",
      "Requirement already satisfied: future in c:\\users\\kei\\anaconda3\\envs\\school\\lib\\site-packages (from torch->torchtext==0.6.0) (0.18.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtext==0.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 3390,
     "status": "ok",
     "timestamp": 1606369190252,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "grk5TlOS7Rh4"
   },
   "outputs": [],
   "source": [
    "# 必要なモジュールのインポート\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext.data import Field, BucketIterator\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 3386,
     "status": "ok",
     "timestamp": 1606369190253,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "hV9m14jC8_As"
   },
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5601,
     "status": "ok",
     "timestamp": 1606369192473,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "RO1VkLhS9Aur",
    "outputId": "6758e965-f679-4150-da1b-ed43571f3437"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: janome in c:\\users\\kei\\anaconda3\\envs\\school\\lib\\site-packages (0.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install janome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 5595,
     "status": "ok",
     "timestamp": 1606369192474,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "LSY1Tjxk9Q5l"
   },
   "outputs": [],
   "source": [
    "import janome\n",
    "from janome.tokenizer import Tokenizer\n",
    "j_t = Tokenizer()\n",
    "\n",
    "# 日本語を単語に分割したリストを返す関数\n",
    "def tokenizer(text):\n",
    "  return [tok for tok in j_t.tokenize(text, wakati=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5590,
     "status": "ok",
     "timestamp": 1606369192475,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "tlJ-5vHV9gM0",
    "outputId": "f3741a80-5a05-4204-bc82-96af12550c93"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['今日', 'は', '曇り', 'です']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"今日は曇りです\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 5583,
     "status": "ok",
     "timestamp": 1606369192476,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "P7D0kRBz-Xcp"
   },
   "outputs": [],
   "source": [
    "import torchtext\n",
    "import torch\n",
    "from torchtext import data\n",
    "from torchtext import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 5579,
     "status": "ok",
     "timestamp": 1606369192476,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "D0U1LAH39jdW"
   },
   "outputs": [],
   "source": [
    "# pytorchのデータフィードの定義（重要！！）\n",
    "SRC = data.Field(sequential=True, tokenize = tokenizer, init_token='<sos>', eos_token='<eos>', lower=True)\n",
    "TRG = data.Field(sequential=True, tokenize = tokenizer, init_token='<sos>', eos_token='<eos>', lower=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 5576,
     "status": "ok",
     "timestamp": 1606369192477,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "ALwCMyIr4bnd"
   },
   "outputs": [],
   "source": [
    "# 重複のないデータセットか重複のあるデータセットを選ぶ\n",
    "# flagがTrueの時重複のないデータを返す\n",
    "def choose_dataset(flag = False):\n",
    "  if flag:\n",
    "    train, val, test = data.TabularDataset.splits(\n",
    "        path=\"../data/\", train='one_train.tsv',\n",
    "        validation='one_val.tsv', test='one_test.tsv', format='tsv',\n",
    "        fields=[('SRC', SRC), ('TRG', TRG)])\n",
    "    filename = \"../csv/one_result_Seq2seq.csv\"\n",
    "  else:\n",
    "    train, val, test = data.TabularDataset.splits(\n",
    "        path=\"../data/\", train='train.tsv',\n",
    "        validation='val.tsv', test='test.tsv', format='tsv',\n",
    "        fields=[('SRC', SRC), ('TRG', TRG)])\n",
    "    filename = \"../csv/result_Seq2seq.csv\"\n",
    "  \n",
    "  return train, val, test, filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 40381,
     "status": "ok",
     "timestamp": 1606369227286,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "nRnr3e9B-VXJ"
   },
   "outputs": [],
   "source": [
    "train, val, test, filename = choose_dataset(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 40380,
     "status": "ok",
     "timestamp": 1606369227289,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "AhRWZjOZ-ffs"
   },
   "outputs": [],
   "source": [
    "# 辞書の作成\n",
    "SRC.build_vocab(train)\n",
    "TRG.build_vocab(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 40376,
     "status": "ok",
     "timestamp": 1606369227289,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "yYeVn3Sr-9b-"
   },
   "outputs": [],
   "source": [
    "# 各データをバッチ化する\n",
    "# データの総数を割れる数にしないと学習時にエラーを吐く\n",
    "train_batch_size = 50\n",
    "test_batch_size = 32\n",
    "eval_batch_size = 2\n",
    "train_iter, val_iter, test_iter = data.BucketIterator.splits((train, val, test), sort = False,  batch_sizes = (train_batch_size,eval_batch_size, test_batch_size), device= device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 40373,
     "status": "ok",
     "timestamp": 1606369227290,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "PuqR4n4E_EIi"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "  # Encoder層の設定\n",
    "  def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "    super().__init__()\n",
    "    # 埋め込み層の次元数\n",
    "    self.hid_dim = hid_dim\n",
    "    # LSTMレイヤの数\n",
    "    self.n_layers = n_layers\n",
    "    # 埋め込み層の作成\n",
    "    self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "    # LSTM層の作成\n",
    "    self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "    self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "  def forward(self, src):\n",
    "    # 単語を分散表現に変換する\n",
    "    embedded = self.dropout(self.embedding(src))\n",
    "    # LSTMに単語を入力して、Encoderからの出力とする\n",
    "    outputs, (hidden, cell) = self.rnn(embedded)\n",
    "    return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 40371,
     "status": "ok",
     "timestamp": 1606369227291,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "iYMjBKWIAJa0"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "  def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "    super().__init__()\n",
    "    # 出力の次元数（単語数と同じ）\n",
    "    self.output_dim = output_dim\n",
    "    # 隠れ層の数\n",
    "    self.hid_dim = hid_dim\n",
    "    # レイヤ数\n",
    "    self.n_layers = n_layers\n",
    "    # 埋め込み層\n",
    "    self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "    # LSTM\n",
    "    self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "    # 出力をするためのやつ\n",
    "    self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "    self.dropout = nn.Dropout(dropout)\n",
    "  \n",
    "  def forward(self, input, hidden, cell):\n",
    "    # 入力を整形する\n",
    "    input = input.unsqueeze(0)\n",
    "    # 分散表現に変換\n",
    "    embedded = self.dropout(self.embedding(input))\n",
    "    # Decoderからの出力を得る\n",
    "    output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "    # 正規化する\n",
    "    prediction = self.fc_out(output.squeeze(0))\n",
    "\n",
    "    return prediction, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 40366,
     "status": "ok",
     "timestamp": 1606369227291,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "eKegU_nlDNTr"
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "  def __init__(self, encoder, decoder, device):\n",
    "    super().__init__()\n",
    "    self.encoder = encoder\n",
    "    self.decoder = decoder\n",
    "    self.device = device\n",
    "\n",
    "  def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
    "    batch_size = trg.shape[1]\n",
    "    trg_len = trg.shape[0]\n",
    "    trg_vocab_size = self.decoder.output_dim\n",
    "\n",
    "    outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "\n",
    "    hidden, cell = self.encoder(src)\n",
    "\n",
    "    output = trg[0,:]\n",
    "\n",
    "    for t in range(1, trg_len):\n",
    "      output, hidden, cell = self.decoder(output, hidden, cell)\n",
    "\n",
    "      outputs[t] = output\n",
    "      teacher_force = random.random() < teacher_forcing_ratio\n",
    "      top1 = output.argmax(1)\n",
    "      output = (trg[t] if teacher_force else top1)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 40629,
     "status": "ok",
     "timestamp": 1606369227557,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "wiQtw_R4Endo"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "ENC_HID_DIM = 1024\n",
    "DEC_HID_DIM = 1024\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.3\n",
    "DEC_DROPOUT = 0.3\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, DEC_HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40624,
     "status": "ok",
     "timestamp": 1606369227558,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "a0-nOvWpEzoW",
    "outputId": "b24162cc-c9be-4736-fbbc-788a141deb7c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(3652, 256)\n",
       "    (rnn): LSTM(256, 1024, num_layers=2, dropout=0.5)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(2349, 256)\n",
       "    (rnn): LSTM(256, 1024, num_layers=2, dropout=0.5)\n",
       "    (fc_out): Linear(in_features=1024, out_features=2349, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 40619,
     "status": "ok",
     "timestamp": 1606369227559,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "QiIkh4XVFP4y"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 40614,
     "status": "ok",
     "timestamp": 1606369227559,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "NLbky7ZvFTqh"
   },
   "outputs": [],
   "source": [
    "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = SRC_PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 40610,
     "status": "ok",
     "timestamp": 1606369227560,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "EtfRQ4RsFWaQ"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "  model.train()\n",
    "\n",
    "  epoch_loss = 0\n",
    "\n",
    "  for i, batch in enumerate(iterator):\n",
    "\n",
    "    src = batch.SRC\n",
    "    trg = batch.TRG\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    output = model(src, trg)\n",
    "\n",
    "    #print(\"output size:\", output.size())\n",
    "    #print(\"target size:\", trg.size())\n",
    "    output_dim = output.shape[-1]\n",
    "    output = output[:].view(-1, output_dim)\n",
    "    trg = trg[:].view(-1)\n",
    "    loss = criterion(output, trg)\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm(model.parameters(), clip)\n",
    "    optimizer.step()\n",
    "\n",
    "    epoch_loss += loss.item()\n",
    "\n",
    "  return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 40605,
     "status": "ok",
     "timestamp": 1606369227560,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "VC3CzZF8GVub"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "  model.eval()\n",
    "\n",
    "  epoch_loss = 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "\n",
    "      src = batch.SRC\n",
    "      trg = batch.TRG\n",
    "\n",
    "      output = model(src, trg)\n",
    "\n",
    "      output_dim = output.shape[-1]\n",
    "\n",
    "      output = output[:].view(-1, output_dim)\n",
    "      trg = trg[:].view(-1)\n",
    "\n",
    "      loss = criterion(output, trg)\n",
    "      epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 40602,
     "status": "ok",
     "timestamp": 1606369227561,
     "user": {
      "displayName": "守山慧",
      "photoUrl": "",
      "userId": "18276650506428796801"
     },
     "user_tz": -540
    },
    "id": "gJ0ljjrQJTBw"
   },
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "  elapsed_time = end_time - start_time\n",
    "  elapsed_mins = int(elapsed_time / 60)\n",
    "  elapsed_secs = int(elapsed_time - (elapsed_mins*60))\n",
    "  return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eZtBtHvgJx7D",
    "outputId": "595719f6-f67f-43c0-bfca-9509d5d533c9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KEI\\anaconda3\\envs\\school\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "Epoch: 01 | Time: 1m 53s | Train Loss: 4.050 | Val. Loss: 4.068\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 02 | Time: 1m 53s | Train Loss: 3.960 | Val. Loss: 4.034\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 03 | Time: 1m 54s | Train Loss: 3.871 | Val. Loss: 4.021\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 04 | Time: 1m 55s | Train Loss: 3.849 | Val. Loss: 4.002\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 05 | Time: 1m 55s | Train Loss: 3.807 | Val. Loss: 4.023\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 06 | Time: 1m 50s | Train Loss: 3.817 | Val. Loss: 4.033\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 07 | Time: 1m 51s | Train Loss: 3.781 | Val. Loss: 4.014\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 08 | Time: 1m 54s | Train Loss: 3.766 | Val. Loss: 4.016\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 09 | Time: 1m 55s | Train Loss: 3.744 | Val. Loss: 4.019\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 10 | Time: 1m 54s | Train Loss: 3.756 | Val. Loss: 4.009\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 11 | Time: 1m 54s | Train Loss: 3.702 | Val. Loss: 3.999\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 12 | Time: 1m 55s | Train Loss: 3.710 | Val. Loss: 4.041\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 13 | Time: 1m 55s | Train Loss: 3.668 | Val. Loss: 4.057\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 14 | Time: 1m 54s | Train Loss: 3.670 | Val. Loss: 4.061\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 15 | Time: 1m 53s | Train Loss: 3.640 | Val. Loss: 4.039\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 16 | Time: 1m 54s | Train Loss: 3.634 | Val. Loss: 4.037\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 17 | Time: 1m 55s | Train Loss: 3.588 | Val. Loss: 4.040\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 18 | Time: 1m 51s | Train Loss: 3.570 | Val. Loss: 4.024\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 19 | Time: 1m 53s | Train Loss: 3.559 | Val. Loss: 4.082\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 20 | Time: 1m 52s | Train Loss: 3.545 | Val. Loss: 4.036\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 21 | Time: 1m 52s | Train Loss: 3.514 | Val. Loss: 4.025\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 22 | Time: 1m 51s | Train Loss: 3.513 | Val. Loss: 4.081\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 23 | Time: 1m 51s | Train Loss: 3.506 | Val. Loss: 4.074\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 24 | Time: 1m 51s | Train Loss: 3.456 | Val. Loss: 4.103\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 25 | Time: 1m 54s | Train Loss: 3.460 | Val. Loss: 4.102\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 26 | Time: 1m 57s | Train Loss: 3.399 | Val. Loss: 4.116\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 27 | Time: 1m 56s | Train Loss: 3.402 | Val. Loss: 4.126\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 28 | Time: 1m 57s | Train Loss: 3.414 | Val. Loss: 4.127\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 29 | Time: 1m 56s | Train Loss: 3.353 | Val. Loss: 4.109\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 30 | Time: 1m 56s | Train Loss: 3.352 | Val. Loss: 4.133\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 31 | Time: 1m 56s | Train Loss: 3.322 | Val. Loss: 4.117\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 32 | Time: 1m 57s | Train Loss: 3.298 | Val. Loss: 4.156\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 33 | Time: 1m 55s | Train Loss: 3.296 | Val. Loss: 4.156\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 34 | Time: 1m 54s | Train Loss: 3.268 | Val. Loss: 4.133\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 35 | Time: 1m 54s | Train Loss: 3.246 | Val. Loss: 4.176\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 36 | Time: 1m 54s | Train Loss: 3.235 | Val. Loss: 4.199\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 37 | Time: 1m 55s | Train Loss: 3.210 | Val. Loss: 4.203\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 38 | Time: 1m 54s | Train Loss: 3.204 | Val. Loss: 4.213\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 39 | Time: 1m 54s | Train Loss: 3.206 | Val. Loss: 4.261\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 40 | Time: 1m 54s | Train Loss: 3.178 | Val. Loss: 4.216\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 41 | Time: 1m 54s | Train Loss: 3.118 | Val. Loss: 4.241\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 42 | Time: 1m 54s | Train Loss: 3.124 | Val. Loss: 4.235\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 43 | Time: 1m 54s | Train Loss: 3.093 | Val. Loss: 4.266\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 44 | Time: 1m 55s | Train Loss: 3.105 | Val. Loss: 4.299\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 45 | Time: 1m 55s | Train Loss: 3.058 | Val. Loss: 4.264\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 46 | Time: 1m 54s | Train Loss: 3.043 | Val. Loss: 4.337\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 47 | Time: 1m 54s | Train Loss: 3.026 | Val. Loss: 4.313\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 48 | Time: 1m 57s | Train Loss: 3.009 | Val. Loss: 4.304\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 49 | Time: 1m 57s | Train Loss: 3.017 | Val. Loss: 4.367\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 50 | Time: 1m 56s | Train Loss: 2.939 | Val. Loss: 4.323\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 51 | Time: 1m 56s | Train Loss: 2.932 | Val. Loss: 4.377\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 52 | Time: 1m 57s | Train Loss: 2.887 | Val. Loss: 4.375\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 53 | Time: 1m 56s | Train Loss: 2.900 | Val. Loss: 4.383\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 54 | Time: 1m 56s | Train Loss: 2.873 | Val. Loss: 4.429\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 55 | Time: 1m 55s | Train Loss: 2.831 | Val. Loss: 4.450\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 56 | Time: 1m 56s | Train Loss: 2.819 | Val. Loss: 4.476\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 57 | Time: 1m 56s | Train Loss: 2.801 | Val. Loss: 4.443\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 58 | Time: 1m 57s | Train Loss: 2.771 | Val. Loss: 4.480\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 59 | Time: 1m 56s | Train Loss: 2.763 | Val. Loss: 4.467\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 60 | Time: 1m 56s | Train Loss: 2.754 | Val. Loss: 4.488\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 61 | Time: 1m 57s | Train Loss: 2.728 | Val. Loss: 4.478\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 62 | Time: 1m 57s | Train Loss: 2.706 | Val. Loss: 4.525\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 63 | Time: 1m 56s | Train Loss: 2.686 | Val. Loss: 4.550\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 64 | Time: 1m 56s | Train Loss: 2.673 | Val. Loss: 4.535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "Epoch: 65 | Time: 1m 56s | Train Loss: 2.676 | Val. Loss: 4.570\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 66 | Time: 1m 57s | Train Loss: 2.657 | Val. Loss: 4.553\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 67 | Time: 1m 57s | Train Loss: 2.626 | Val. Loss: 4.566\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 68 | Time: 1m 57s | Train Loss: 2.598 | Val. Loss: 4.595\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 69 | Time: 1m 56s | Train Loss: 2.575 | Val. Loss: 4.624\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 70 | Time: 1m 56s | Train Loss: 2.564 | Val. Loss: 4.628\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 71 | Time: 1m 51s | Train Loss: 2.587 | Val. Loss: 4.626\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 72 | Time: 1m 49s | Train Loss: 2.547 | Val. Loss: 4.653\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 73 | Time: 1m 48s | Train Loss: 2.558 | Val. Loss: 4.616\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 74 | Time: 1m 49s | Train Loss: 2.526 | Val. Loss: 4.670\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 75 | Time: 1m 49s | Train Loss: 2.538 | Val. Loss: 4.688\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 76 | Time: 1m 49s | Train Loss: 2.511 | Val. Loss: 4.702\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 77 | Time: 1m 49s | Train Loss: 2.504 | Val. Loss: 4.721\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 78 | Time: 1m 49s | Train Loss: 2.473 | Val. Loss: 4.723\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 79 | Time: 1m 50s | Train Loss: 2.466 | Val. Loss: 4.760\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 80 | Time: 1m 49s | Train Loss: 2.454 | Val. Loss: 4.778\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 81 | Time: 1m 49s | Train Loss: 2.430 | Val. Loss: 4.758\n",
      "-----------------------------------------------------------------\n",
      "Epoch: 82 | Time: 1m 49s | Train Loss: 2.442 | Val. Loss: 4.792\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "clip = 1\n",
    "best_model = None\n",
    "\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "best_model = None\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_iter, optimizer, criterion, clip)\n",
    "    valid_loss = evaluate(model, val_iter, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        best_model = model\n",
    "        #torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "    \n",
    "    print(\"-\"*65)\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s | Train Loss: {train_loss:.3f} | Val. Loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kghORfY83ZRj"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '../model/seq2seq.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ckjXccGO3Z1_"
   },
   "outputs": [],
   "source": [
    "model.state_dict(torch.load(\",./model/seq2seq.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1wnxyMwrJ0uK"
   },
   "outputs": [],
   "source": [
    "def gen_sentence(sentence, src_field, trg_field, model, max_len = 50):\n",
    "  model.eval()\n",
    "\n",
    "  tokens = [src_field.init_token] + tokenizer(sentence) + [src_field.eos_token]\n",
    "  \n",
    "  src_index = [src_field.vocab.stoi[i] for i in tokens]\n",
    "  src_tensor = torch.LongTensor(src_index).unsqueeze(1).to(device)\n",
    "  src_len = torch.LongTensor([len(src_index)]).to(device)\n",
    "  with torch.no_grad():\n",
    "    hidden, cell = model.encoder(src_tensor)\n",
    "  \n",
    "  trg_index = [trg_field.vocab.stoi[trg_field.init_token]]\n",
    "  for i in range(max_len):\n",
    "    trg_tensor = torch.LongTensor([trg_index[-1]]).to(device)\n",
    "    with torch.no_grad():\n",
    "      output, hidden, cell = model.decoder(trg_tensor, hidden, cell)\n",
    "    \n",
    "    pred_token = output.argmax(1).item()\n",
    "    trg_index.append(pred_token)\n",
    "    if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
    "      break\n",
    "\n",
    "  trg_tokens = [trg_field.vocab.itos[i] for i in trg_index]\n",
    "  if len(trg_tokens) == 2:\n",
    "    print(trg_tokens)\n",
    "    trg_tokens = [\"-\"]\n",
    "    trg_tokens = [src_field.init_token] + trg_tokens + [src_field.eos_token]\n",
    "  return trg_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dgvU7NIJqDud"
   },
   "outputs": [],
   "source": [
    "def gen_sentence_list(path): \n",
    "  col, pred = [], []\n",
    "  input, output = [], []\n",
    "  with open(path, mode = 'r') as f:\n",
    "    for file_list in f:\n",
    "      col.append(file_list.split('\\t'))\n",
    "  for i in col:\n",
    "    input.append(i[0])\n",
    "    output.append(i[1])\n",
    "\n",
    "  for sentence in input:\n",
    "    pred.append(gen_sentence(sentence, SRC, TRG, model))\n",
    "  return input, output, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4altRgQ3qGJN"
   },
   "outputs": [],
   "source": [
    "path = \"./data/test.tsv\"\n",
    "test_input, test_output, test_pred = gen_sentence_list(path)\n",
    "path = \"./data/train.tsv\"\n",
    "train_input, train_output, train_pred = gen_sentence_list(path)\n",
    "path = \"./data/val.tsv\"\n",
    "val_input, val_output, val_pred = gen_sentence_list(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a_fFU1apNN8p"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZMmGXHSGNU1y"
   },
   "outputs": [],
   "source": [
    "def convert_list_to_df(in_list, out_list, pred_list):\n",
    "  row = []\n",
    "  for i in range(len(in_list)):\n",
    "    batch_input = in_list[i]\n",
    "    batch_output = out_list[i]\n",
    "    batch_pred = pred_list[i]\n",
    "    input = [j for j in batch_input if j != \"<pad>\" and j != \"<sos>\" and j != \"<eos>\" and j != \"<unk>\"]\n",
    "    output = [j for j in batch_output if j != \"<pad>\" and j != \"<sos>\" and j != \"<eos>\" and j != \"<unk>\"]\n",
    "    predict = [j for j in batch_pred if j != \"<pad>\" and j != \"<sos>\" and j != \"<eos>\" and j != \"<unk>\"]\n",
    "    input_str = \"\".join(input)\n",
    "    output_str =\"\".join(output)\n",
    "    predict_str = \"\".join(predict)\n",
    "    row.append([input_str, output_str, predict_str])\n",
    "\n",
    "  df = pd.DataFrame(row, columns=[\"input\",\"answer\",\"predict\"])\n",
    "  df = df.sort_values('input')\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bM3sSB7ZITU9"
   },
   "outputs": [],
   "source": [
    "train_df = convert_list_to_df(train_input, train_output, train_pred)\n",
    "val_df = convert_list_to_df(val_input, val_output, val_pred)\n",
    "test_df = convert_list_to_df(test_input, test_output, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cjRVwDVjjIUp"
   },
   "outputs": [],
   "source": [
    "df_s = pd.concat([train_df, test_df]).sort_values('input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oh5GU1c3qOTO"
   },
   "outputs": [],
   "source": [
    "df_s.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8dGjeZakjPpf"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMAoEYMmZIR7Swx8xgW6hQV",
   "collapsed_sections": [],
   "name": "seq2seq_with_torchtext.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
