{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DNjZHQ_iEuFL",
    "outputId": "e52fd587-726f-4033-c04e-f28206b201fe"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M4ausvJbE4g_",
    "outputId": "16d9c323-6536-42f9-8983-efed1faf0141"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\keisc\\anaconda3\\envs\\study\\lib\\site-packages (4.0.0)\n",
      "Requirement already satisfied: fugashi in c:\\users\\keisc\\anaconda3\\envs\\study\\lib\\site-packages (1.0.5)\n",
      "Requirement already satisfied: mecab-python3 in c:\\users\\keisc\\anaconda3\\envs\\study\\lib\\site-packages (1.0.3)\n",
      "Requirement already satisfied: ipadic in c:\\users\\keisc\\anaconda3\\envs\\study\\lib\\site-packages (1.0.0)\n",
      "Collecting torchtext\n",
      "  Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\keisc\\anaconda3\\envs\\study\\lib\\site-packages (from transformers) (1.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\keisc\\anaconda3\\envs\\study\\lib\\site-packages (from transformers) (4.50.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\keisc\\anaconda3\\envs\\study\\lib\\site-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\keisc\\anaconda3\\envs\\study\\lib\\site-packages (from transformers) (2020.9.27)\n",
      "Requirement already satisfied: tokenizers==0.9.4 in c:\\users\\keisc\\anaconda3\\envs\\study\\lib\\site-packages (from transformers) (0.9.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\keisc\\anaconda3\\envs\\study\\lib\\site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: requests in c:\\users\\keisc\\anaconda3\\envs\\study\\lib\\site-packages (from transformers) (2.24.0)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\keisc\\anaconda3\\envs\\study\\lib\\site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: torch in c:\\users\\keisc\\anaconda3\\envs\\study\\lib\\site-packages (from torchtext) (1.7.0)\n",
      "Requirement already satisfied: six in c:\\users\\keisc\\anaconda3\\envs\\study\\lib\\site-packages (from torchtext) (1.15.0)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.94-cp38-cp38-win_amd64.whl (1.2 MB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\keisc\\anaconda3\\envs\\study\\lib\\site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\keisc\\anaconda3\\envs\\study\\lib\\site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\keisc\\anaconda3\\envs\\study\\lib\\site-packages (from requests->transformers) (1.25.10)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\keisc\\anaconda3\\envs\\study\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\keisc\\anaconda3\\envs\\study\\lib\\site-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: joblib in c:\\users\\keisc\\anaconda3\\envs\\study\\lib\\site-packages (from sacremoses->transformers) (0.16.0)\n",
      "Requirement already satisfied: click in c:\\users\\keisc\\anaconda3\\envs\\study\\lib\\site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Collecting future\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\keisc\\anaconda3\\envs\\study\\lib\\site-packages (from torch->torchtext) (3.7.4.3)\n",
      "Collecting dataclasses\n",
      "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
      "Building wheels for collected packages: future\n",
      "  Building wheel for future (setup.py): started\n",
      "  Building wheel for future (setup.py): finished with status 'done'\n",
      "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491062 sha256=05b77fd68b6470b897f0ea49ec08838e0d6b0040a8af59cc3d4decda60387930\n",
      "  Stored in directory: c:\\users\\keisc\\appdata\\local\\pip\\cache\\wheels\\8e\\70\\28\\3d6ccd6e315f65f245da085482a2e1c7d14b90b30f239e2cf4\n",
      "Successfully built future\n",
      "Installing collected packages: sentencepiece, torchtext, future, dataclasses\n",
      "Successfully installed dataclasses-0.6 future-0.18.2 sentencepiece-0.1.94 torchtext-0.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers fugashi mecab-python3 ipadic torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Y4_ddJeRE83M"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer, TransformerDecoder, TransformerDecoderLayer\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        # self.linear = nn.Linear(32000 ,768)\n",
    "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, \n",
    "                                                      nlayers)\n",
    "                                                      # ,norm = bert_model.get_output_embeddings())\n",
    "        self.encoder = bert_model.get_input_embeddings()\n",
    "        self.ninp = ninp\n",
    "        # self.decoder = bert_model.get_input_embeddings()\n",
    "        self.decoder = nn.Embedding(ntoken, ninp)\n",
    "        decoder_layers = TransformerDecoderLayer(ninp, nhead, nhid, dropout)\n",
    "        self.transformer_decoder = TransformerDecoder(decoder_layers, \n",
    "                                                      nlayers\n",
    "                                                      ,norm= bert_model.get_output_embeddings())\n",
    "        self.init_weights()\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        #self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        src_mask = model.generate_square_subsequent_mask(src.size()[0]).to(device)\n",
    "        trg_mask = model.generate_square_subsequent_mask(trg.size()[0]).to(device)\n",
    "        # 分散表現に変換\n",
    "        src = self.encoder(src)\n",
    "        trg = self.encoder(trg)\n",
    "        # 位置情報を入れる\n",
    "        src = self.pos_encoder(src)\n",
    "        trg = self.pos_encoder(trg)\n",
    "        # モデルにデータを入れる\n",
    "        enc_output = self.transformer_encoder(src, mask=src_mask)\n",
    "        # enc_output = self.linear(enc_output)\n",
    "        # print(\"enc output size: \", enc_output.size())\n",
    "        # print(\"trg size: \", trg.size())\n",
    "        # デコーダにエンコーダの出力を入れる（ここがおかしい）\n",
    "        output = self.transformer_decoder(trg, enc_output,tgt_mask = trg_mask, memory_mask = src_mask)\n",
    "        return output\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.size())\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "0yHD5NckFKvs"
   },
   "outputs": [],
   "source": [
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from transformers import BertJapaneseTokenizer, BertForPreTraining\n",
    "import random \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Wo8yNDSdvNRb"
   },
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ph5madKkB7z"
   },
   "source": [
    "辞書はこれを使って復号する\n",
    "\n",
    "https://huggingface.co/transformers/main_classes/tokenizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "jm_UKaNiFPE0"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-ad4e27d4bd4c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtok\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBertJapaneseTokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cl-tohoku/bert-base-japanese'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\study\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001b[0m\n\u001b[0;32m   1739\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1740\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1741\u001b[1;33m                     resolved_vocab_files[file_id] = cached_path(\n\u001b[0m\u001b[0;32m   1742\u001b[0m                         \u001b[0mfile_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1743\u001b[0m                         \u001b[0mcache_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\study\\lib\\site-packages\\transformers\\file_utils.py\u001b[0m in \u001b[0;36mcached_path\u001b[1;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, local_files_only)\u001b[0m\n\u001b[0;32m    998\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_remote_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m         \u001b[1;31m# URL, so get it from the cache (downloading if necessary)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1000\u001b[1;33m         output_path = get_from_cache(\n\u001b[0m\u001b[0;32m   1001\u001b[0m             \u001b[0murl_or_filename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1002\u001b[0m             \u001b[0mcache_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\study\\lib\\site-packages\\transformers\\file_utils.py\u001b[0m in \u001b[0;36mget_from_cache\u001b[1;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, local_files_only)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s not found in cache or force_download set to True, downloading to %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m             \u001b[0mhttp_get\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl_to_download\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresume_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_agent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muser_agent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"storing %s in cache at %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\study\\lib\\site-packages\\transformers\\file_utils.py\u001b[0m in \u001b[0;36mhttp_get\u001b[1;34m(url, temp_file, proxies, resume_size, user_agent)\u001b[0m\n\u001b[0;32m   1078\u001b[0m     \u001b[0mcontent_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Content-Length\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1079\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresume_size\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent_length\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcontent_length\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1080\u001b[1;33m     progress = tqdm(\n\u001b[0m\u001b[0;32m   1081\u001b[0m         \u001b[0munit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"B\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1082\u001b[0m         \u001b[0munit_scale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\study\\lib\\site-packages\\tqdm\\notebook.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0munit_scale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munit_scale\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munit_scale\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0munit_scale\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         self.container = self.status_printer(\n\u001b[0m\u001b[0;32m    224\u001b[0m             self.fp, total, self.desc, self.ncols)\n\u001b[0;32m    225\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\study\\lib\\site-packages\\tqdm\\notebook.py\u001b[0m in \u001b[0;36mstatus_printer\u001b[1;34m(_, total, desc, ncols)\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[1;31m# Prepare IPython progress bar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mIProgress\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# #187 #451 #558 #872\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m             raise ImportError(\n\u001b[0m\u001b[0;32m     97\u001b[0m                 \u001b[1;34m\"IProgress not found. Please update jupyter and ipywidgets.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                 \u001b[1;34m\" See https://ipywidgets.readthedocs.io/en/stable\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "tok = BertJapaneseTokenizer.from_pretrained('cl-tohoku/bert-base-japanese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oS_bkY2LFP_G"
   },
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "  return tok.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eWhyCcfhj045",
    "outputId": "c74f07bb-735e-4a9c-842a-0cc066542e9d"
   },
   "outputs": [],
   "source": [
    "tok.convert_tokens_to_ids(tokenizer(\"今日は良い日です\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K1845PD8ma24"
   },
   "outputs": [],
   "source": [
    "path = \"../data/data.tsv\"\n",
    "src, trg, tmp = [], [], []\n",
    "with open(path, mode='r') as f:\n",
    "  for file in f:\n",
    "    sentence = file.split(\"\\t\")\n",
    "    tmp.append(sentence)\n",
    "\n",
    "random.shuffle(tmp)\n",
    "\n",
    "for data in tmp:\n",
    "    src.append(data[0])\n",
    "    trg.append(data[1].replace(\"\\t\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AKr2t__LwGs7"
   },
   "outputs": [],
   "source": [
    "src_tensors = tok.__call__(text = src, text_pair = trg, padding=True, return_tensors='pt', return_attention_mask=False)\n",
    "trg_tensors = tok.__call__(text = trg, text_pair = src, padding=True, return_tensors='pt', return_attention_mask=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ssXPh5DMJ-t3"
   },
   "outputs": [],
   "source": [
    "dataset = torch.utils.data.TensorDataset(src_tensors['input_ids'], trg_tensors['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UwozgovGWJsO"
   },
   "outputs": [],
   "source": [
    "train_size = int(len(dataset) * 0.8)\n",
    "valid_size = len(dataset) - train_size\n",
    "train_data, valid_data = torch.utils.data.random_split(dataset, [train_size, valid_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "QJDXuCVNNNUK",
    "outputId": "6079d82c-cb58-4b89-9063-4de06bff8d53"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_data_loader = torch.utils.data.DataLoader(train_data, batch_size, shuffle=True)\n",
    "valid_data_loader = torch.utils.data.DataLoader(valid_data, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "foNgCYhCN_oq",
    "outputId": "5eda687e-8b70-41f5-aa80-bd08339be4a0"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for x, y in train_data_loader:\n",
    "  print(\"src: \", x)\n",
    "  print(\"trg: \", y.size())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J83kvjO1FdWj"
   },
   "outputs": [],
   "source": [
    "SRC = data.Field(sequential=True, tokenize = tokenizer, init_token='<sos>', eos_token='<eos>', lower = True)\n",
    "TRG = data.Field(sequential=True, tokenize = tokenizer, init_token='<sos>', eos_token='<eos>', lower = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tdGrZST1BXNj"
   },
   "outputs": [],
   "source": [
    "# 重複のないデータセットか重複のあるデータセットを選ぶ\n",
    "# flagがTrueの時重複のないデータを返す\n",
    "def choose_dataset(flag = False):\n",
    "  if flag:\n",
    "    train, val, test = data.TabularDataset.splits(\n",
    "        path=\"../data/\", \n",
    "        train='one_train.tsv',\n",
    "        validation='one_val.tsv', \n",
    "        test='one_test.tsv', \n",
    "        format='tsv',\n",
    "        fields=[('src', SRC), ('trg', TRG)])\n",
    "    filename = \"../csv/one_result_transformer.csv\"\n",
    "  else:\n",
    "    train, val, test = data.TabularDataset.splits(\n",
    "        path=\"../data/\", \n",
    "        train='train.tsv',\n",
    "        validation='val.tsv', \n",
    "        test='test.tsv', \n",
    "        format='tsv',\n",
    "        fields=[('src', SRC), ('trg', TRG)])\n",
    "    filename = \"../csv/result_transformer.csv\"\n",
    "  \n",
    "  return train, val, test, filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8kDi0M2_Fier",
    "outputId": "a15d7e9a-b4df-42f0-d635-0795ba9caa66"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForPreTraining were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese and are newly initialized: ['cls.predictions.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "train, val, test, filename = choose_dataset(False)\n",
    "SRC.build_vocab(train)\n",
    "TRG.build_vocab(train)\n",
    "bert_model = BertForPreTraining.from_pretrained(\n",
    "    \"cl-tohoku/bert-base-japanese\", # 日本語Pre trainedモデルの指定\n",
    "    num_labels = 2, # ラベル数（今回はBinayなので2、数値を増やせばマルチラベルも対応可）\n",
    "    output_attentions = False, # アテンションベクトルを出力するか\n",
    "    output_hidden_states = True, # 隠れ層を出力するか\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "N0yTQhdEGEB7",
    "outputId": "489dc009-5f0a-4147-8749-d650d939d1dd"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\ntrain_batch_size = 32\\ntest_batch_size = 32\\neval_batch_size = 32\\ntrain_iter, val_iter, test_iter = data.BucketIterator.splits((train, val, test), sort = False,  batch_sizes = (train_batch_size,eval_batch_size, test_batch_size), device= device)\\n'"
      ]
     },
     "execution_count": 75,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\"\"\"\n",
    "train_batch_size = 32\n",
    "test_batch_size = 32\n",
    "eval_batch_size = 32\n",
    "train_iter, val_iter, test_iter = data.BucketIterator.splits((train, val, test), sort = False,  batch_sizes = (train_batch_size,eval_batch_size, test_batch_size), device= device)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1GywKJzzSqsM"
   },
   "outputs": [],
   "source": [
    "# data = next(iter(train_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dV3rBie-THkU"
   },
   "outputs": [],
   "source": [
    "# data.src.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "60fKoQ8NGGH6"
   },
   "outputs": [],
   "source": [
    "ntokens = len(TRG.vocab.itos) # the size of vocabulary\n",
    "emsize = 768 # embedding dimension\n",
    "nhid = 512 # the dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 2 # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 2 # the number of heads in the multiheadattention models\n",
    "dropout = 0.3 # the dropout value\n",
    "model = TransformerModel(ntokens, emsize, nhead, nhid, nlayers, dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZLzdBFfpuQAP",
    "outputId": "8a937526-7649-4d9f-f997-12269262e6c7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (pos_encoder): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.3, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.3, inplace=False)\n",
       "        (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.3, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.3, inplace=False)\n",
       "        (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoder): Embedding(32000, 768, padding_idx=0)\n",
       "  (decoder): Embedding(2310, 768)\n",
       "  (transformer_decoder): TransformerDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.3, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.3, inplace=False)\n",
       "        (dropout2): Dropout(p=0.3, inplace=False)\n",
       "        (dropout3): Dropout(p=0.3, inplace=False)\n",
       "      )\n",
       "      (1): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.3, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.3, inplace=False)\n",
       "        (dropout2): Dropout(p=0.3, inplace=False)\n",
       "        (dropout3): Dropout(p=0.3, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): Linear(in_features=768, out_features=32000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 79,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F_mXeTeaGG7V"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "lr = 5 # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
    "\n",
    "import time\n",
    "def train(data_loader):\n",
    "    model.train() # Turn on the train mode\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    for src, trg in data_loader:\n",
    "        src = torch.t(src).to(device)\n",
    "        trg = torch.t(trg).to(device)\n",
    "        # print(src)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg)\n",
    "        output = output[:].view(-1, output.shape[-1])\n",
    "        trg = trg[:].contiguous().view(-1)\n",
    "        # print(\"trg size :\", trg.size())\n",
    "        # print(\"output size: \", output.size())\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    return total_loss / len(data_loader)\n",
    "        \n",
    "\n",
    "def evaluate(eval_model, data_loader):\n",
    "    eval_model.eval() # Turn on the evaluation mode\n",
    "    total_loss = 0.\n",
    "    with torch.no_grad():\n",
    "      for src, trg in data_loader:\n",
    "        src = torch.t(src).to(device)\n",
    "        trg = torch.t(trg).to(device)\n",
    "        #src_mask = model.generate_square_subsequent_mask(data.shape[0]).to(device)\n",
    "        output = eval_model(src, trg)\n",
    "        output_flat = output[:].view(-1, output.shape[-1])\n",
    "        trg = trg[:].contiguous().view(-1)\n",
    "        total_loss += criterion(output_flat, trg).item()\n",
    "    return total_loss / (len(data_loader) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aoPF710mGM1u",
    "outputId": "b050b1c3-b613-46ae-8def-870fcc561d2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   1 | time: 131.11s | train loss  6.87 | valid loss  5.80 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   2 | time: 135.21s | train loss  4.23 | valid loss  2.79 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   3 | time: 136.41s | train loss  1.70 | valid loss  3.95 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   4 | time: 136.99s | train loss  0.87 | valid loss  2.44 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   5 | time: 137.46s | train loss  0.47 | valid loss  0.51 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   6 | time: 137.32s | train loss  0.24 | valid loss  0.58 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   7 | time: 137.03s | train loss  0.14 | valid loss  0.49 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   8 | time: 136.55s | train loss  0.08 | valid loss  0.27 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   9 | time: 136.06s | train loss  0.03 | valid loss  0.03 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  10 | time: 136.17s | train loss  0.02 | valid loss  0.20 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  11 | time: 136.01s | train loss  0.01 | valid loss  0.02 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  12 | time: 135.95s | train loss  0.01 | valid loss  0.01 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  13 | time: 136.14s | train loss  0.00 | valid loss  0.01 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  14 | time: 136.03s | train loss  0.00 | valid loss  0.01 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  15 | time: 135.99s | train loss  0.00 | valid loss  0.01 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  16 | time: 135.69s | train loss  0.00 | valid loss  0.01 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  17 | time: 135.69s | train loss  0.00 | valid loss  0.01 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  18 | time: 135.79s | train loss  0.00 | valid loss  0.01 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  19 | time: 135.64s | train loss  0.00 | valid loss  0.01 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  20 | time: 135.77s | train loss  0.00 | valid loss  0.01 | \n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float(\"inf\")\n",
    "epochs = 20 # The number of epochs\n",
    "best_model = None\n",
    "model.init_weights()\n",
    "train_loss_list, eval_loss_list = [], []\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    t_loss = train(train_data_loader)\n",
    "    val_loss = evaluate(model, valid_data_loader)\n",
    "    print('-' * 89)\n",
    "    print('| epoch {:3d} | time: {:5.2f}s | train loss {:5.2f} | valid loss {:5.2f} | '\n",
    "          .format(epoch, (time.time() - epoch_start_time), t_loss, val_loss))\n",
    "\n",
    "    train_loss_list.append(t_loss)\n",
    "    eval_loss_list.append(val_loss)\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = model\n",
    "\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "PtHQxigz4Wfy",
    "outputId": "f11a6ece-bbf0-4047-ec18-34fa8ae7daa1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "y = list(range(epochs))\n",
    "train_loss = plt.plot(y, train_loss_list)\n",
    "valid_loss = plt.plot(y, eval_loss_list)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend((train_loss[0], valid_loss[0]), (\"train loss\", \"valid loss\"),)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PWTpNLRGGVDC"
   },
   "outputs": [],
   "source": [
    "torch.save(best_model.state_dict(), \"/content/dirve/My Drive/Colab Notebooks/model/bert_embedded_transformer.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6FbrKm90aurT"
   },
   "outputs": [],
   "source": [
    "model.init_weights()\n",
    "model.state_dict(torch.load(\"/content/dirve/My Drive/Colab Notebooks/model/bert_embedded_transformer.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mvpBPYSczFm0"
   },
   "outputs": [],
   "source": [
    "def gen_sentence(sentence, tok, model, max_len = 50):\n",
    "  model.eval()\n",
    "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "  sentence = tok.tokenize(sentence)\n",
    "  src = [tok.convert_tokens_to_ids(\"[CLS]\")] + tok.convert_tokens_to_ids(sentence) + [tok.convert_tokens_to_ids(\"[SEP]\")]\n",
    "  src = torch.LongTensor([src])\n",
    "  # print(src)\n",
    "  src = torch.t(src)\n",
    "  src = src.to(device)\n",
    "\n",
    "  src_tensor = model.encoder(src)\n",
    "  src_tensor = model.pos_encoder(src_tensor).to(device)\n",
    "  src_mask = model.generate_square_subsequent_mask(src_tensor.size()[0]).to(device)\n",
    "  # print(src_tensor)\n",
    "  with torch.no_grad():\n",
    "    src_output = model.transformer_encoder(src_tensor, src_mask)\n",
    "  trg = tok.convert_tokens_to_ids(\"[CLS]\")\n",
    "  trg = torch.LongTensor([[trg]]).to(device)\n",
    "  output = []\n",
    "  # print(\"src sizse: \", src_output.size())\n",
    "  for i in range(max_len):\n",
    "    # print(\"trg size: \", trg.size())\n",
    "    trg_tensor = model.encoder(trg)\n",
    "    # print(trg_tensor.size())\n",
    "    trg_tensor = model.pos_encoder(trg_tensor).to(device)\n",
    "    trg_mask = model.generate_square_subsequent_mask(trg_tensor.size()[0]).to(device)\n",
    "    with torch.no_grad():\n",
    "      pred = model.transformer_decoder(trg_tensor, src_output, trg_mask)\n",
    "    # print(\"predicit sizes: \", pred.size())\n",
    "    pred_word_index = pred.argmax(2)[-1]\n",
    "    # add_word = trg_field.vocab.itos[pred_word_index.item()]\n",
    "    # print(tok.convert_ids_to_tokens(pred_word_index))\n",
    "    output.append(pred_word_index)\n",
    "    if pred_word_index == 3:\n",
    "      break\n",
    "\n",
    "    last_index = torch.LongTensor([[pred_word_index.item()]]).to(device)\n",
    "    trg = torch.cat((trg, last_index))\n",
    "    \n",
    "  # predict = \"\".join(output)\n",
    "  predict = tok.convert_ids_to_tokens(output)\n",
    "  predit = \"\".join(predict)\n",
    "\n",
    "  return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9aXDBTzfGtvi"
   },
   "outputs": [],
   "source": [
    "sentence = \"なるほど\"\n",
    "gen_sentence(sentence, tok, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5eSVY_ILGrbe"
   },
   "outputs": [],
   "source": [
    "def gen_sentence_list(path): \n",
    "  col, pred = [], []\n",
    "  input, output = [], []\n",
    "  with open(path, mode = 'r') as f:\n",
    "    for file_list in f:\n",
    "      col.append(file_list.split('\\t'))\n",
    "  for i in col:\n",
    "    input.append(i[0])\n",
    "    output.append(i[1].replace(\"\\n\", \"\"))\n",
    "\n",
    "  for sentence in input:\n",
    "    pred.append(gen_sentence(sentence, SRC, SRC, model))\n",
    "  return input, output, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U-MkG5DWMEgO"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9-x0Nb8VMOnd"
   },
   "outputs": [],
   "source": [
    "def convert_list_to_df(in_list, out_list, pred_list):\n",
    "  row = []\n",
    "  for i in range(len(in_list)):\n",
    "    batch_input = in_list[i]\n",
    "    batch_output = out_list[i]\n",
    "    batch_pred = pred_list[i]\n",
    "    input = [j for j in batch_input if j != \"<pad>\" and j != \"<sos>\" and j != \"<eos>\" and j != \"<unk>\"]\n",
    "    output = [j for j in batch_output if j != \"<pad>\" and j != \"<sos>\" and j != \"<eos>\" and j != \"<unk>\"]\n",
    "    predict = [j for j in batch_pred if j != \"<pad>\" and j != \"<sos>\" and j != \"<eos>\" and j != \"<unk>\"]\n",
    "    input_str = \"\".join(input).replace(\"#\", \"\")\n",
    "    output_str =\"\".join(output).replace(\"#\", \"\")\n",
    "    predict_str = \"\".join(predict).replace(\"#\", \"\")\n",
    "    row.append([input_str, output_str, predict_str])\n",
    "\n",
    "  df = pd.DataFrame(row, columns=[\"input\",\"answer\",\"predict\"])\n",
    "  df = df.sort_values('input')\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RzNMZFQBMYRx"
   },
   "outputs": [],
   "source": [
    "train_df = convert_list_to_df(train_in, train_out, train_pred)\n",
    "val_df = convert_list_to_df(val_in, val_out, val_pred)\n",
    "test_df = convert_list_to_df(test_in, test_out, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VpqTaFLqMZ95"
   },
   "outputs": [],
   "source": [
    "df_s = pd.concat([train_df, test_df]).sort_values('input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u-25c9orMc7q"
   },
   "outputs": [],
   "source": [
    "df_s.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "omMdo3neMa2x"
   },
   "outputs": [],
   "source": [
    "df_s.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YxEw_8ClQDI8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "bert_embedded_Transformer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
